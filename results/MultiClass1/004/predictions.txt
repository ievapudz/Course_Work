Starting epoch 1
tensor(2.7948, grad_fn=<NllLossBackward0>)
tensor(2.7709, grad_fn=<NllLossBackward0>)
tensor(2.8489, grad_fn=<NllLossBackward0>)
tensor(2.7661, grad_fn=<NllLossBackward0>)
tensor(2.8134, grad_fn=<NllLossBackward0>)
tensor(2.7835, grad_fn=<NllLossBackward0>)
tensor(2.8106, grad_fn=<NllLossBackward0>)
tensor(2.7984, grad_fn=<NllLossBackward0>)
tensor(2.8079, grad_fn=<NllLossBackward0>)
tensor(2.8217, grad_fn=<NllLossBackward0>)
tensor(2.8325, grad_fn=<NllLossBackward0>)
tensor(2.7711, grad_fn=<NllLossBackward0>)
tensor(2.8214, grad_fn=<NllLossBackward0>)
tensor(2.7147, grad_fn=<NllLossBackward0>)
tensor(2.7682, grad_fn=<NllLossBackward0>)
tensor(2.7778, grad_fn=<NllLossBackward0>)
tensor(2.8432, grad_fn=<NllLossBackward0>)
tensor(2.7450, grad_fn=<NllLossBackward0>)
tensor(2.7763, grad_fn=<NllLossBackward0>)
tensor(2.7544, grad_fn=<NllLossBackward0>)
tensor(2.7566, grad_fn=<NllLossBackward0>)
tensor(2.7927, grad_fn=<NllLossBackward0>)
tensor(2.8099, grad_fn=<NllLossBackward0>)
tensor(2.7472, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    24: 0.047
tensor(2.7541, grad_fn=<NllLossBackward0>)
tensor(2.7549, grad_fn=<NllLossBackward0>)
tensor(2.7804, grad_fn=<NllLossBackward0>)
tensor(2.7488, grad_fn=<NllLossBackward0>)
tensor(2.8490, grad_fn=<NllLossBackward0>)
tensor(2.7332, grad_fn=<NllLossBackward0>)
tensor(2.7350, grad_fn=<NllLossBackward0>)
tensor(2.8052, grad_fn=<NllLossBackward0>)
tensor(2.8379, grad_fn=<NllLossBackward0>)
tensor(2.8023, grad_fn=<NllLossBackward0>)
tensor(2.6742, grad_fn=<NllLossBackward0>)
tensor(2.7324, grad_fn=<NllLossBackward0>)
tensor(2.7443, grad_fn=<NllLossBackward0>)
tensor(2.7827, grad_fn=<NllLossBackward0>)
tensor(2.7527, grad_fn=<NllLossBackward0>)
tensor(2.7143, grad_fn=<NllLossBackward0>)
tensor(2.7674, grad_fn=<NllLossBackward0>)
tensor(2.7502, grad_fn=<NllLossBackward0>)
tensor(2.7215, grad_fn=<NllLossBackward0>)
tensor(2.7305, grad_fn=<NllLossBackward0>)
tensor(2.7586, grad_fn=<NllLossBackward0>)
tensor(2.7813, grad_fn=<NllLossBackward0>)
tensor(2.7184, grad_fn=<NllLossBackward0>)
tensor(2.7297, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    48: 0.057
tensor(2.7375, grad_fn=<NllLossBackward0>)
tensor(2.7633, grad_fn=<NllLossBackward0>)
tensor(2.7455, grad_fn=<NllLossBackward0>)
tensor(2.7967, grad_fn=<NllLossBackward0>)
tensor(2.7364, grad_fn=<NllLossBackward0>)
tensor(2.7567, grad_fn=<NllLossBackward0>)
tensor(2.7062, grad_fn=<NllLossBackward0>)
tensor(2.7649, grad_fn=<NllLossBackward0>)
tensor(2.7641, grad_fn=<NllLossBackward0>)
tensor(2.7126, grad_fn=<NllLossBackward0>)
tensor(2.7652, grad_fn=<NllLossBackward0>)
tensor(2.7281, grad_fn=<NllLossBackward0>)
tensor(2.7229, grad_fn=<NllLossBackward0>)
tensor(2.7195, grad_fn=<NllLossBackward0>)
tensor(2.7749, grad_fn=<NllLossBackward0>)
tensor(2.7156, grad_fn=<NllLossBackward0>)
tensor(2.7434, grad_fn=<NllLossBackward0>)
tensor(2.7207, grad_fn=<NllLossBackward0>)
tensor(2.7191, grad_fn=<NllLossBackward0>)
tensor(2.6818, grad_fn=<NllLossBackward0>)
tensor(2.6954, grad_fn=<NllLossBackward0>)
tensor(2.7408, grad_fn=<NllLossBackward0>)
tensor(2.7392, grad_fn=<NllLossBackward0>)
tensor(2.7067, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    72: 0.130
tensor(2.7705, grad_fn=<NllLossBackward0>)
tensor(2.7220, grad_fn=<NllLossBackward0>)
tensor(2.7292, grad_fn=<NllLossBackward0>)
tensor(2.7342, grad_fn=<NllLossBackward0>)
tensor(2.7612, grad_fn=<NllLossBackward0>)
tensor(2.7118, grad_fn=<NllLossBackward0>)
tensor(2.7283, grad_fn=<NllLossBackward0>)
tensor(2.7884, grad_fn=<NllLossBackward0>)
tensor(2.7227, grad_fn=<NllLossBackward0>)
tensor(2.7250, grad_fn=<NllLossBackward0>)
tensor(2.7122, grad_fn=<NllLossBackward0>)
tensor(2.6844, grad_fn=<NllLossBackward0>)
tensor(2.7477, grad_fn=<NllLossBackward0>)
tensor(2.7456, grad_fn=<NllLossBackward0>)
tensor(2.7366, grad_fn=<NllLossBackward0>)
tensor(2.6751, grad_fn=<NllLossBackward0>)
tensor(2.6910, grad_fn=<NllLossBackward0>)
tensor(2.6846, grad_fn=<NllLossBackward0>)
tensor(2.7362, grad_fn=<NllLossBackward0>)
tensor(2.7394, grad_fn=<NllLossBackward0>)
tensor(2.7185, grad_fn=<NllLossBackward0>)
tensor(2.6771, grad_fn=<NllLossBackward0>)
tensor(2.7246, grad_fn=<NllLossBackward0>)
tensor(2.7321, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    96: 0.122
tensor(2.7427, grad_fn=<NllLossBackward0>)
tensor(2.6665, grad_fn=<NllLossBackward0>)
tensor(2.7285, grad_fn=<NllLossBackward0>)
tensor(2.6587, grad_fn=<NllLossBackward0>)
tensor(2.7367, grad_fn=<NllLossBackward0>)
tensor(2.6801, grad_fn=<NllLossBackward0>)
tensor(2.6688, grad_fn=<NllLossBackward0>)
tensor(2.7271, grad_fn=<NllLossBackward0>)
tensor(2.7235, grad_fn=<NllLossBackward0>)
tensor(2.7448, grad_fn=<NllLossBackward0>)
tensor(2.7338, grad_fn=<NllLossBackward0>)
tensor(2.6850, grad_fn=<NllLossBackward0>)
tensor(2.7045, grad_fn=<NllLossBackward0>)
tensor(2.6930, grad_fn=<NllLossBackward0>)
tensor(2.7037, grad_fn=<NllLossBackward0>)
tensor(2.7057, grad_fn=<NllLossBackward0>)
tensor(2.7307, grad_fn=<NllLossBackward0>)
tensor(2.6727, grad_fn=<NllLossBackward0>)
tensor(2.7528, grad_fn=<NllLossBackward0>)
tensor(2.7048, grad_fn=<NllLossBackward0>)
tensor(2.6955, grad_fn=<NllLossBackward0>)
tensor(2.6853, grad_fn=<NllLossBackward0>)
tensor(2.6954, grad_fn=<NllLossBackward0>)
tensor(2.7268, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   120: 0.141
tensor(2.6787, grad_fn=<NllLossBackward0>)
tensor(2.6632, grad_fn=<NllLossBackward0>)
tensor(2.7195, grad_fn=<NllLossBackward0>)
tensor(2.6772, grad_fn=<NllLossBackward0>)
tensor(2.7351, grad_fn=<NllLossBackward0>)
tensor(2.6607, grad_fn=<NllLossBackward0>)
tensor(2.7066, grad_fn=<NllLossBackward0>)
tensor(2.6831, grad_fn=<NllLossBackward0>)
tensor(2.6699, grad_fn=<NllLossBackward0>)
tensor(2.6650, grad_fn=<NllLossBackward0>)
tensor(2.6754, grad_fn=<NllLossBackward0>)
tensor(2.7095, grad_fn=<NllLossBackward0>)
tensor(2.6609, grad_fn=<NllLossBackward0>)
tensor(2.7057, grad_fn=<NllLossBackward0>)
tensor(2.6996, grad_fn=<NllLossBackward0>)
tensor(2.6990, grad_fn=<NllLossBackward0>)
tensor(2.6472, grad_fn=<NllLossBackward0>)
tensor(2.6597, grad_fn=<NllLossBackward0>)
tensor(2.7303, grad_fn=<NllLossBackward0>)
tensor(2.7274, grad_fn=<NllLossBackward0>)
tensor(2.7012, grad_fn=<NllLossBackward0>)
tensor(2.6725, grad_fn=<NllLossBackward0>)
tensor(2.6773, grad_fn=<NllLossBackward0>)
tensor(2.6828, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   144: 0.151
tensor(2.5987, grad_fn=<NllLossBackward0>)
tensor(2.7194, grad_fn=<NllLossBackward0>)
tensor(2.5681, grad_fn=<NllLossBackward0>)
tensor(2.6338, grad_fn=<NllLossBackward0>)
tensor(2.7318, grad_fn=<NllLossBackward0>)
tensor(2.7103, grad_fn=<NllLossBackward0>)
tensor(2.6407, grad_fn=<NllLossBackward0>)
tensor(2.7126, grad_fn=<NllLossBackward0>)
tensor(2.6895, grad_fn=<NllLossBackward0>)
tensor(2.6383, grad_fn=<NllLossBackward0>)
tensor(2.6872, grad_fn=<NllLossBackward0>)
tensor(2.7074, grad_fn=<NllLossBackward0>)
tensor(2.6944, grad_fn=<NllLossBackward0>)
tensor(2.7146, grad_fn=<NllLossBackward0>)
tensor(2.7018, grad_fn=<NllLossBackward0>)
tensor(2.6724, grad_fn=<NllLossBackward0>)
tensor(2.6748, grad_fn=<NllLossBackward0>)
tensor(2.7087, grad_fn=<NllLossBackward0>)
tensor(2.6642, grad_fn=<NllLossBackward0>)
tensor(2.6887, grad_fn=<NllLossBackward0>)
tensor(2.6724, grad_fn=<NllLossBackward0>)
tensor(2.6504, grad_fn=<NllLossBackward0>)
tensor(2.6564, grad_fn=<NllLossBackward0>)
tensor(2.6741, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   168: 0.184
tensor(2.6321, grad_fn=<NllLossBackward0>)
tensor(2.6263, grad_fn=<NllLossBackward0>)
tensor(2.6358, grad_fn=<NllLossBackward0>)
tensor(2.6632, grad_fn=<NllLossBackward0>)
tensor(2.6548, grad_fn=<NllLossBackward0>)
tensor(2.6489, grad_fn=<NllLossBackward0>)
tensor(2.6397, grad_fn=<NllLossBackward0>)
tensor(2.6514, grad_fn=<NllLossBackward0>)
tensor(2.7277, grad_fn=<NllLossBackward0>)
tensor(2.6429, grad_fn=<NllLossBackward0>)
tensor(2.6138, grad_fn=<NllLossBackward0>)
tensor(2.7029, grad_fn=<NllLossBackward0>)
tensor(2.6386, grad_fn=<NllLossBackward0>)
tensor(2.5766, grad_fn=<NllLossBackward0>)
tensor(2.6327, grad_fn=<NllLossBackward0>)
tensor(2.6226, grad_fn=<NllLossBackward0>)
tensor(2.6744, grad_fn=<NllLossBackward0>)
tensor(2.6854, grad_fn=<NllLossBackward0>)
tensor(2.6231, grad_fn=<NllLossBackward0>)
tensor(2.6615, grad_fn=<NllLossBackward0>)
tensor(2.7145, grad_fn=<NllLossBackward0>)
tensor(2.6374, grad_fn=<NllLossBackward0>)
tensor(2.6396, grad_fn=<NllLossBackward0>)
tensor(2.6930, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   192: 0.179
tensor(2.6080, grad_fn=<NllLossBackward0>)
tensor(2.7302, grad_fn=<NllLossBackward0>)
tensor(2.6559, grad_fn=<NllLossBackward0>)
tensor(2.6640, grad_fn=<NllLossBackward0>)
tensor(2.6412, grad_fn=<NllLossBackward0>)
tensor(2.6202, grad_fn=<NllLossBackward0>)
tensor(2.6554, grad_fn=<NllLossBackward0>)
tensor(2.6592, grad_fn=<NllLossBackward0>)
tensor(2.6481, grad_fn=<NllLossBackward0>)
tensor(2.6727, grad_fn=<NllLossBackward0>)
tensor(2.6381, grad_fn=<NllLossBackward0>)
tensor(2.5410, grad_fn=<NllLossBackward0>)
tensor(2.6188, grad_fn=<NllLossBackward0>)
tensor(2.6951, grad_fn=<NllLossBackward0>)
tensor(2.6797, grad_fn=<NllLossBackward0>)
tensor(2.5837, grad_fn=<NllLossBackward0>)
tensor(2.6175, grad_fn=<NllLossBackward0>)
tensor(2.6175, grad_fn=<NllLossBackward0>)
tensor(2.6652, grad_fn=<NllLossBackward0>)
tensor(2.6788, grad_fn=<NllLossBackward0>)
tensor(2.5692, grad_fn=<NllLossBackward0>)
tensor(2.6763, grad_fn=<NllLossBackward0>)
tensor(2.7340, grad_fn=<NllLossBackward0>)
tensor(2.6586, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   216: 0.158
tensor(2.6347, grad_fn=<NllLossBackward0>)
tensor(2.6326, grad_fn=<NllLossBackward0>)
tensor(2.6314, grad_fn=<NllLossBackward0>)
tensor(2.6032, grad_fn=<NllLossBackward0>)
tensor(2.6688, grad_fn=<NllLossBackward0>)
tensor(2.5956, grad_fn=<NllLossBackward0>)
tensor(2.6504, grad_fn=<NllLossBackward0>)
tensor(2.5924, grad_fn=<NllLossBackward0>)
tensor(2.6763, grad_fn=<NllLossBackward0>)
tensor(2.6576, grad_fn=<NllLossBackward0>)
tensor(2.6719, grad_fn=<NllLossBackward0>)
tensor(2.6272, grad_fn=<NllLossBackward0>)
tensor(2.6767, grad_fn=<NllLossBackward0>)
tensor(2.6551, grad_fn=<NllLossBackward0>)
tensor(2.6676, grad_fn=<NllLossBackward0>)
tensor(2.6236, grad_fn=<NllLossBackward0>)
tensor(2.6045, grad_fn=<NllLossBackward0>)
tensor(2.6354, grad_fn=<NllLossBackward0>)
tensor(2.6250, grad_fn=<NllLossBackward0>)
tensor(2.6618, grad_fn=<NllLossBackward0>)
tensor(2.6942, grad_fn=<NllLossBackward0>)
tensor(2.6595, grad_fn=<NllLossBackward0>)
tensor(2.6389, grad_fn=<NllLossBackward0>)
tensor(2.5974, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   240: 0.168
tensor(2.6289, grad_fn=<NllLossBackward0>)
tensor(2.6370, grad_fn=<NllLossBackward0>)
tensor(2.6731, grad_fn=<NllLossBackward0>)
tensor(2.6337, grad_fn=<NllLossBackward0>)
tensor(2.6507, grad_fn=<NllLossBackward0>)
tensor(2.6366, grad_fn=<NllLossBackward0>)
tensor(2.5941, grad_fn=<NllLossBackward0>)
tensor(2.6195, grad_fn=<NllLossBackward0>)
tensor(2.6218, grad_fn=<NllLossBackward0>)
tensor(2.6109, grad_fn=<NllLossBackward0>)
tensor(2.6191, grad_fn=<NllLossBackward0>)
tensor(2.6296, grad_fn=<NllLossBackward0>)
tensor(2.5631, grad_fn=<NllLossBackward0>)
tensor(2.6046, grad_fn=<NllLossBackward0>)
tensor(2.6514, grad_fn=<NllLossBackward0>)
tensor(2.6252, grad_fn=<NllLossBackward0>)
tensor(2.6181, grad_fn=<NllLossBackward0>)
tensor(2.5536, grad_fn=<NllLossBackward0>)
tensor(2.6154, grad_fn=<NllLossBackward0>)
tensor(2.6187, grad_fn=<NllLossBackward0>)
tensor(2.6592, grad_fn=<NllLossBackward0>)
tensor(2.6450, grad_fn=<NllLossBackward0>)
tensor(2.6219, grad_fn=<NllLossBackward0>)
tensor(2.5980, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   264: 0.165
tensor(2.5986, grad_fn=<NllLossBackward0>)
tensor(2.5594, grad_fn=<NllLossBackward0>)
tensor(2.5257, grad_fn=<NllLossBackward0>)
tensor(2.6165, grad_fn=<NllLossBackward0>)
tensor(2.6136, grad_fn=<NllLossBackward0>)
tensor(2.6394, grad_fn=<NllLossBackward0>)
tensor(2.6435, grad_fn=<NllLossBackward0>)
tensor(2.5513, grad_fn=<NllLossBackward0>)
tensor(2.5806, grad_fn=<NllLossBackward0>)
tensor(2.5837, grad_fn=<NllLossBackward0>)
tensor(2.6224, grad_fn=<NllLossBackward0>)
tensor(2.5344, grad_fn=<NllLossBackward0>)
tensor(2.6593, grad_fn=<NllLossBackward0>)
tensor(2.5905, grad_fn=<NllLossBackward0>)
tensor(2.5242, grad_fn=<NllLossBackward0>)
tensor(2.5543, grad_fn=<NllLossBackward0>)
tensor(2.5864, grad_fn=<NllLossBackward0>)
tensor(2.6293, grad_fn=<NllLossBackward0>)
tensor(2.6044, grad_fn=<NllLossBackward0>)
tensor(2.5864, grad_fn=<NllLossBackward0>)
tensor(2.6293, grad_fn=<NllLossBackward0>)
tensor(2.5555, grad_fn=<NllLossBackward0>)
tensor(2.6196, grad_fn=<NllLossBackward0>)
tensor(2.6003, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   288: 0.191
tensor(2.5809, grad_fn=<NllLossBackward0>)
tensor(2.6550, grad_fn=<NllLossBackward0>)
tensor(2.6185, grad_fn=<NllLossBackward0>)
tensor(2.6524, grad_fn=<NllLossBackward0>)
tensor(2.6318, grad_fn=<NllLossBackward0>)
tensor(2.6187, grad_fn=<NllLossBackward0>)
tensor(2.7205, grad_fn=<NllLossBackward0>)
tensor(2.6152, grad_fn=<NllLossBackward0>)
tensor(2.6420, grad_fn=<NllLossBackward0>)
tensor(2.5563, grad_fn=<NllLossBackward0>)
tensor(2.6017, grad_fn=<NllLossBackward0>)
tensor(2.5978, grad_fn=<NllLossBackward0>)
tensor(2.6500, grad_fn=<NllLossBackward0>)
tensor(2.5774, grad_fn=<NllLossBackward0>)
tensor(2.5270, grad_fn=<NllLossBackward0>)
tensor(2.5924, grad_fn=<NllLossBackward0>)
tensor(2.5352, grad_fn=<NllLossBackward0>)
tensor(2.5512, grad_fn=<NllLossBackward0>)
tensor(2.6881, grad_fn=<NllLossBackward0>)
tensor(2.5949, grad_fn=<NllLossBackward0>)
tensor(2.6273, grad_fn=<NllLossBackward0>)
tensor(2.6841, grad_fn=<NllLossBackward0>)
tensor(2.5386, grad_fn=<NllLossBackward0>)
tensor(2.6368, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   312: 0.132
tensor(2.5940, grad_fn=<NllLossBackward0>)
tensor(2.5724, grad_fn=<NllLossBackward0>)
tensor(2.5900, grad_fn=<NllLossBackward0>)
tensor(2.6503, grad_fn=<NllLossBackward0>)
tensor(2.5635, grad_fn=<NllLossBackward0>)
tensor(2.5783, grad_fn=<NllLossBackward0>)
tensor(2.6369, grad_fn=<NllLossBackward0>)
tensor(2.5593, grad_fn=<NllLossBackward0>)
tensor(2.6378, grad_fn=<NllLossBackward0>)
tensor(2.6978, grad_fn=<NllLossBackward0>)
tensor(2.6522, grad_fn=<NllLossBackward0>)
tensor(2.6366, grad_fn=<NllLossBackward0>)
tensor(2.6051, grad_fn=<NllLossBackward0>)
tensor(2.5892, grad_fn=<NllLossBackward0>)
tensor(2.6244, grad_fn=<NllLossBackward0>)
tensor(2.5950, grad_fn=<NllLossBackward0>)
tensor(2.5550, grad_fn=<NllLossBackward0>)
tensor(2.5565, grad_fn=<NllLossBackward0>)
tensor(2.6567, grad_fn=<NllLossBackward0>)
tensor(2.6079, grad_fn=<NllLossBackward0>)
tensor(2.5472, grad_fn=<NllLossBackward0>)
tensor(2.6228, grad_fn=<NllLossBackward0>)
tensor(2.5802, grad_fn=<NllLossBackward0>)
tensor(2.6243, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   336: 0.181
tensor(2.5208, grad_fn=<NllLossBackward0>)
tensor(2.5505, grad_fn=<NllLossBackward0>)
tensor(2.5595, grad_fn=<NllLossBackward0>)
tensor(2.5771, grad_fn=<NllLossBackward0>)
tensor(2.5875, grad_fn=<NllLossBackward0>)
tensor(2.5786, grad_fn=<NllLossBackward0>)
tensor(2.6347, grad_fn=<NllLossBackward0>)
tensor(2.5609, grad_fn=<NllLossBackward0>)
tensor(2.5866, grad_fn=<NllLossBackward0>)
tensor(2.6474, grad_fn=<NllLossBackward0>)
tensor(2.6495, grad_fn=<NllLossBackward0>)
tensor(2.4740, grad_fn=<NllLossBackward0>)
tensor(2.5466, grad_fn=<NllLossBackward0>)
tensor(2.6034, grad_fn=<NllLossBackward0>)
tensor(2.5781, grad_fn=<NllLossBackward0>)
tensor(2.6196, grad_fn=<NllLossBackward0>)
tensor(2.5943, grad_fn=<NllLossBackward0>)
tensor(2.6481, grad_fn=<NllLossBackward0>)
tensor(2.6320, grad_fn=<NllLossBackward0>)
tensor(2.6257, grad_fn=<NllLossBackward0>)
tensor(2.5065, grad_fn=<NllLossBackward0>)
tensor(2.5604, grad_fn=<NllLossBackward0>)
tensor(2.5779, grad_fn=<NllLossBackward0>)
tensor(2.5076, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   360: 0.172
tensor(2.5592, grad_fn=<NllLossBackward0>)
tensor(2.5344, grad_fn=<NllLossBackward0>)
tensor(2.6273, grad_fn=<NllLossBackward0>)
tensor(2.5998, grad_fn=<NllLossBackward0>)
tensor(2.5420, grad_fn=<NllLossBackward0>)
tensor(2.6040, grad_fn=<NllLossBackward0>)
tensor(2.6574, grad_fn=<NllLossBackward0>)
tensor(2.5719, grad_fn=<NllLossBackward0>)
tensor(2.5774, grad_fn=<NllLossBackward0>)
tensor(2.5718, grad_fn=<NllLossBackward0>)
tensor(2.5836, grad_fn=<NllLossBackward0>)
tensor(2.6104, grad_fn=<NllLossBackward0>)
tensor(2.5520, grad_fn=<NllLossBackward0>)
tensor(2.5177, grad_fn=<NllLossBackward0>)
tensor(2.6171, grad_fn=<NllLossBackward0>)
tensor(2.6047, grad_fn=<NllLossBackward0>)
tensor(2.5949, grad_fn=<NllLossBackward0>)
tensor(2.6540, grad_fn=<NllLossBackward0>)
tensor(2.5517, grad_fn=<NllLossBackward0>)
tensor(2.5939, grad_fn=<NllLossBackward0>)
tensor(2.5199, grad_fn=<NllLossBackward0>)
tensor(2.5637, grad_fn=<NllLossBackward0>)
tensor(2.5866, grad_fn=<NllLossBackward0>)
tensor(2.5155, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   384: 0.193
tensor(2.5273, grad_fn=<NllLossBackward0>)
tensor(2.5962, grad_fn=<NllLossBackward0>)
tensor(2.5682, grad_fn=<NllLossBackward0>)
tensor(2.5838, grad_fn=<NllLossBackward0>)
tensor(2.5366, grad_fn=<NllLossBackward0>)
tensor(2.6257, grad_fn=<NllLossBackward0>)
tensor(2.5215, grad_fn=<NllLossBackward0>)
tensor(2.6008, grad_fn=<NllLossBackward0>)
tensor(2.5955, grad_fn=<NllLossBackward0>)
tensor(2.5561, grad_fn=<NllLossBackward0>)
tensor(2.5436, grad_fn=<NllLossBackward0>)
tensor(2.5984, grad_fn=<NllLossBackward0>)
tensor(2.5374, grad_fn=<NllLossBackward0>)
tensor(2.4892, grad_fn=<NllLossBackward0>)
tensor(2.4857, grad_fn=<NllLossBackward0>)
tensor(2.5874, grad_fn=<NllLossBackward0>)
tensor(2.6473, grad_fn=<NllLossBackward0>)
tensor(2.5475, grad_fn=<NllLossBackward0>)
tensor(2.6551, grad_fn=<NllLossBackward0>)
tensor(2.4497, grad_fn=<NllLossBackward0>)
tensor(2.5650, grad_fn=<NllLossBackward0>)
tensor(2.5526, grad_fn=<NllLossBackward0>)
tensor(2.4884, grad_fn=<NllLossBackward0>)
tensor(2.5407, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   408: 0.191
tensor(2.5559, grad_fn=<NllLossBackward0>)
tensor(2.5859, grad_fn=<NllLossBackward0>)
tensor(2.5496, grad_fn=<NllLossBackward0>)
tensor(2.5914, grad_fn=<NllLossBackward0>)
tensor(2.5296, grad_fn=<NllLossBackward0>)
tensor(2.5751, grad_fn=<NllLossBackward0>)
tensor(2.5818, grad_fn=<NllLossBackward0>)
tensor(2.5221, grad_fn=<NllLossBackward0>)
tensor(2.5410, grad_fn=<NllLossBackward0>)
tensor(2.6704, grad_fn=<NllLossBackward0>)
tensor(2.5668, grad_fn=<NllLossBackward0>)
tensor(2.5133, grad_fn=<NllLossBackward0>)
tensor(2.5383, grad_fn=<NllLossBackward0>)
tensor(2.4108, grad_fn=<NllLossBackward0>)
tensor(2.5485, grad_fn=<NllLossBackward0>)
tensor(2.5668, grad_fn=<NllLossBackward0>)
tensor(2.5241, grad_fn=<NllLossBackward0>)
tensor(2.5610, grad_fn=<NllLossBackward0>)
tensor(2.5017, grad_fn=<NllLossBackward0>)
tensor(2.5914, grad_fn=<NllLossBackward0>)
tensor(2.5186, grad_fn=<NllLossBackward0>)
tensor(2.5876, grad_fn=<NllLossBackward0>)
tensor(2.5862, grad_fn=<NllLossBackward0>)
tensor(2.6084, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   432: 0.194
tensor(2.4992, grad_fn=<NllLossBackward0>)
tensor(2.5218, grad_fn=<NllLossBackward0>)
tensor(2.5218, grad_fn=<NllLossBackward0>)
tensor(2.5588, grad_fn=<NllLossBackward0>)
tensor(2.5920, grad_fn=<NllLossBackward0>)
tensor(2.6215, grad_fn=<NllLossBackward0>)
tensor(2.6306, grad_fn=<NllLossBackward0>)
tensor(2.6200, grad_fn=<NllLossBackward0>)
tensor(2.6102, grad_fn=<NllLossBackward0>)
tensor(2.5459, grad_fn=<NllLossBackward0>)
tensor(2.5313, grad_fn=<NllLossBackward0>)
tensor(2.5205, grad_fn=<NllLossBackward0>)
tensor(2.5822, grad_fn=<NllLossBackward0>)
tensor(2.5792, grad_fn=<NllLossBackward0>)
tensor(2.5043, grad_fn=<NllLossBackward0>)
tensor(2.5220, grad_fn=<NllLossBackward0>)
tensor(2.5778, grad_fn=<NllLossBackward0>)
tensor(2.5384, grad_fn=<NllLossBackward0>)
tensor(2.6553, grad_fn=<NllLossBackward0>)
tensor(2.5389, grad_fn=<NllLossBackward0>)
tensor(2.4949, grad_fn=<NllLossBackward0>)
tensor(2.5686, grad_fn=<NllLossBackward0>)
tensor(2.5586, grad_fn=<NllLossBackward0>)
tensor(2.5307, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   456: 0.196
tensor(2.4766, grad_fn=<NllLossBackward0>)
tensor(2.5672, grad_fn=<NllLossBackward0>)
tensor(2.5893, grad_fn=<NllLossBackward0>)
tensor(2.5594, grad_fn=<NllLossBackward0>)
tensor(2.5385, grad_fn=<NllLossBackward0>)
tensor(2.5772, grad_fn=<NllLossBackward0>)
tensor(2.5853, grad_fn=<NllLossBackward0>)
tensor(2.4938, grad_fn=<NllLossBackward0>)
tensor(2.5553, grad_fn=<NllLossBackward0>)
tensor(2.5007, grad_fn=<NllLossBackward0>)
tensor(2.4901, grad_fn=<NllLossBackward0>)
tensor(2.5122, grad_fn=<NllLossBackward0>)
tensor(2.5837, grad_fn=<NllLossBackward0>)
tensor(2.5376, grad_fn=<NllLossBackward0>)
tensor(2.5793, grad_fn=<NllLossBackward0>)
tensor(2.5769, grad_fn=<NllLossBackward0>)
tensor(2.5204, grad_fn=<NllLossBackward0>)
tensor(2.4941, grad_fn=<NllLossBackward0>)
tensor(2.5276, grad_fn=<NllLossBackward0>)
tensor(2.5938, grad_fn=<NllLossBackward0>)
tensor(2.5996, grad_fn=<NllLossBackward0>)
tensor(2.4427, grad_fn=<NllLossBackward0>)
tensor(2.5559, grad_fn=<NllLossBackward0>)
tensor(2.5542, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   480: 0.222
tensor(2.4640, grad_fn=<NllLossBackward0>)
tensor(2.5276, grad_fn=<NllLossBackward0>)
tensor(2.3034, grad_fn=<NllLossBackward0>)
tensor(2.5300, grad_fn=<NllLossBackward0>)
tensor(2.5273, grad_fn=<NllLossBackward0>)
tensor(2.5213, grad_fn=<NllLossBackward0>)
tensor(2.5474, grad_fn=<NllLossBackward0>)
tensor(2.4737, grad_fn=<NllLossBackward0>)
tensor(2.5146, grad_fn=<NllLossBackward0>)
tensor(2.5125, grad_fn=<NllLossBackward0>)
tensor(2.4833, grad_fn=<NllLossBackward0>)
tensor(2.5003, grad_fn=<NllLossBackward0>)
tensor(2.5346, grad_fn=<NllLossBackward0>)
tensor(2.5209, grad_fn=<NllLossBackward0>)
tensor(2.5311, grad_fn=<NllLossBackward0>)
tensor(2.5282, grad_fn=<NllLossBackward0>)
tensor(2.5371, grad_fn=<NllLossBackward0>)
tensor(2.4841, grad_fn=<NllLossBackward0>)
tensor(2.5145, grad_fn=<NllLossBackward0>)
tensor(2.5771, grad_fn=<NllLossBackward0>)
tensor(2.5770, grad_fn=<NllLossBackward0>)
tensor(2.5654, grad_fn=<NllLossBackward0>)
tensor(2.5638, grad_fn=<NllLossBackward0>)
tensor(2.5458, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   504: 0.226
tensor(2.5961, grad_fn=<NllLossBackward0>)
tensor(2.4784, grad_fn=<NllLossBackward0>)
tensor(2.5304, grad_fn=<NllLossBackward0>)
tensor(2.4555, grad_fn=<NllLossBackward0>)
tensor(2.5712, grad_fn=<NllLossBackward0>)
tensor(2.5600, grad_fn=<NllLossBackward0>)
tensor(2.5212, grad_fn=<NllLossBackward0>)
tensor(2.4534, grad_fn=<NllLossBackward0>)
tensor(2.5431, grad_fn=<NllLossBackward0>)
tensor(2.4610, grad_fn=<NllLossBackward0>)
tensor(2.5236, grad_fn=<NllLossBackward0>)
tensor(2.5890, grad_fn=<NllLossBackward0>)
tensor(2.5897, grad_fn=<NllLossBackward0>)
tensor(2.4766, grad_fn=<NllLossBackward0>)
tensor(2.5302, grad_fn=<NllLossBackward0>)
tensor(2.5571, grad_fn=<NllLossBackward0>)
tensor(2.5471, grad_fn=<NllLossBackward0>)
tensor(2.4104, grad_fn=<NllLossBackward0>)
tensor(2.5238, grad_fn=<NllLossBackward0>)
tensor(2.5183, grad_fn=<NllLossBackward0>)
tensor(2.5645, grad_fn=<NllLossBackward0>)
tensor(2.4382, grad_fn=<NllLossBackward0>)
tensor(2.4498, grad_fn=<NllLossBackward0>)
tensor(2.4767, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   528: 0.196
tensor(2.4147, grad_fn=<NllLossBackward0>)
tensor(2.4216, grad_fn=<NllLossBackward0>)
tensor(2.4900, grad_fn=<NllLossBackward0>)
tensor(2.5480, grad_fn=<NllLossBackward0>)
tensor(2.5380, grad_fn=<NllLossBackward0>)
tensor(2.4477, grad_fn=<NllLossBackward0>)
tensor(2.5005, grad_fn=<NllLossBackward0>)
tensor(2.5429, grad_fn=<NllLossBackward0>)
tensor(2.4432, grad_fn=<NllLossBackward0>)
tensor(2.5152, grad_fn=<NllLossBackward0>)
tensor(2.5263, grad_fn=<NllLossBackward0>)
tensor(2.5196, grad_fn=<NllLossBackward0>)
tensor(2.4058, grad_fn=<NllLossBackward0>)
tensor(2.5545, grad_fn=<NllLossBackward0>)
tensor(2.4280, grad_fn=<NllLossBackward0>)
tensor(2.4473, grad_fn=<NllLossBackward0>)
tensor(2.5573, grad_fn=<NllLossBackward0>)
tensor(2.6187, grad_fn=<NllLossBackward0>)
tensor(2.5066, grad_fn=<NllLossBackward0>)
tensor(2.5437, grad_fn=<NllLossBackward0>)
tensor(2.5164, grad_fn=<NllLossBackward0>)
tensor(2.4876, grad_fn=<NllLossBackward0>)
tensor(2.5037, grad_fn=<NllLossBackward0>)
tensor(2.5746, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   552: 0.226
tensor(2.5797, grad_fn=<NllLossBackward0>)
tensor(2.4909, grad_fn=<NllLossBackward0>)
tensor(2.5175, grad_fn=<NllLossBackward0>)
tensor(2.5995, grad_fn=<NllLossBackward0>)
tensor(2.6376, grad_fn=<NllLossBackward0>)
tensor(2.4480, grad_fn=<NllLossBackward0>)
tensor(2.5499, grad_fn=<NllLossBackward0>)
tensor(2.5723, grad_fn=<NllLossBackward0>)
tensor(2.5226, grad_fn=<NllLossBackward0>)
tensor(2.4921, grad_fn=<NllLossBackward0>)
tensor(2.4125, grad_fn=<NllLossBackward0>)
tensor(2.5364, grad_fn=<NllLossBackward0>)
tensor(2.4359, grad_fn=<NllLossBackward0>)
tensor(2.4793, grad_fn=<NllLossBackward0>)
tensor(2.4224, grad_fn=<NllLossBackward0>)
tensor(2.4567, grad_fn=<NllLossBackward0>)
tensor(2.4526, grad_fn=<NllLossBackward0>)
tensor(2.5081, grad_fn=<NllLossBackward0>)
tensor(2.4978, grad_fn=<NllLossBackward0>)
tensor(2.5481, grad_fn=<NllLossBackward0>)
tensor(2.3876, grad_fn=<NllLossBackward0>)
tensor(2.5475, grad_fn=<NllLossBackward0>)
tensor(2.6060, grad_fn=<NllLossBackward0>)
tensor(2.5631, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   576: 0.196
tensor(2.5509, grad_fn=<NllLossBackward0>)
tensor(2.4931, grad_fn=<NllLossBackward0>)
tensor(2.5009, grad_fn=<NllLossBackward0>)
tensor(2.4607, grad_fn=<NllLossBackward0>)
tensor(2.4336, grad_fn=<NllLossBackward0>)
tensor(2.4875, grad_fn=<NllLossBackward0>)
tensor(2.5339, grad_fn=<NllLossBackward0>)
tensor(2.5145, grad_fn=<NllLossBackward0>)
tensor(2.4960, grad_fn=<NllLossBackward0>)
tensor(2.4294, grad_fn=<NllLossBackward0>)
tensor(2.5024, grad_fn=<NllLossBackward0>)
tensor(2.6028, grad_fn=<NllLossBackward0>)
tensor(2.5455, grad_fn=<NllLossBackward0>)
tensor(2.5339, grad_fn=<NllLossBackward0>)
tensor(2.4998, grad_fn=<NllLossBackward0>)
tensor(2.3718, grad_fn=<NllLossBackward0>)
tensor(2.4858, grad_fn=<NllLossBackward0>)
tensor(2.4518, grad_fn=<NllLossBackward0>)
tensor(2.5075, grad_fn=<NllLossBackward0>)
tensor(2.4602, grad_fn=<NllLossBackward0>)
tensor(2.4648, grad_fn=<NllLossBackward0>)
tensor(2.3970, grad_fn=<NllLossBackward0>)
tensor(2.4919, grad_fn=<NllLossBackward0>)
tensor(2.4871, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   600: 0.208
tensor(2.4969, grad_fn=<NllLossBackward0>)
tensor(2.4470, grad_fn=<NllLossBackward0>)
tensor(2.4967, grad_fn=<NllLossBackward0>)
tensor(2.5361, grad_fn=<NllLossBackward0>)
tensor(2.4614, grad_fn=<NllLossBackward0>)
tensor(2.5154, grad_fn=<NllLossBackward0>)
tensor(2.5025, grad_fn=<NllLossBackward0>)
tensor(2.4163, grad_fn=<NllLossBackward0>)
tensor(2.5514, grad_fn=<NllLossBackward0>)
tensor(2.5455, grad_fn=<NllLossBackward0>)
tensor(2.4778, grad_fn=<NllLossBackward0>)
tensor(2.4342, grad_fn=<NllLossBackward0>)
tensor(2.4454, grad_fn=<NllLossBackward0>)
tensor(2.5139, grad_fn=<NllLossBackward0>)
tensor(2.4841, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.3605, grad_fn=<NllLossBackward0>)
tensor(2.4499, grad_fn=<NllLossBackward0>)
tensor(2.4959, grad_fn=<NllLossBackward0>)
tensor(2.4543, grad_fn=<NllLossBackward0>)
tensor(2.4865, grad_fn=<NllLossBackward0>)
tensor(2.5451, grad_fn=<NllLossBackward0>)
tensor(2.4543, grad_fn=<NllLossBackward0>)
tensor(2.4725, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   624: 0.231
tensor(2.5326, grad_fn=<NllLossBackward0>)
tensor(2.5252, grad_fn=<NllLossBackward0>)
tensor(2.5242, grad_fn=<NllLossBackward0>)
tensor(2.4683, grad_fn=<NllLossBackward0>)
tensor(2.6093, grad_fn=<NllLossBackward0>)
tensor(2.5306, grad_fn=<NllLossBackward0>)
tensor(2.4746, grad_fn=<NllLossBackward0>)
tensor(2.4463, grad_fn=<NllLossBackward0>)
tensor(2.4867, grad_fn=<NllLossBackward0>)
tensor(2.5675, grad_fn=<NllLossBackward0>)
tensor(2.4280, grad_fn=<NllLossBackward0>)
tensor(2.3695, grad_fn=<NllLossBackward0>)
tensor(2.5498, grad_fn=<NllLossBackward0>)
tensor(2.5250, grad_fn=<NllLossBackward0>)
tensor(2.5954, grad_fn=<NllLossBackward0>)
tensor(2.5582, grad_fn=<NllLossBackward0>)
tensor(2.4717, grad_fn=<NllLossBackward0>)
tensor(2.5549, grad_fn=<NllLossBackward0>)
tensor(2.3314, grad_fn=<NllLossBackward0>)
tensor(2.4780, grad_fn=<NllLossBackward0>)
tensor(2.5011, grad_fn=<NllLossBackward0>)
tensor(2.5373, grad_fn=<NllLossBackward0>)
tensor(2.4557, grad_fn=<NllLossBackward0>)
tensor(2.3718, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   648: 0.189
tensor(2.5049, grad_fn=<NllLossBackward0>)
tensor(2.4005, grad_fn=<NllLossBackward0>)
tensor(2.5105, grad_fn=<NllLossBackward0>)
tensor(2.4958, grad_fn=<NllLossBackward0>)
tensor(2.5045, grad_fn=<NllLossBackward0>)
tensor(2.4319, grad_fn=<NllLossBackward0>)
tensor(2.5198, grad_fn=<NllLossBackward0>)
tensor(2.4552, grad_fn=<NllLossBackward0>)
tensor(2.5250, grad_fn=<NllLossBackward0>)
tensor(2.5886, grad_fn=<NllLossBackward0>)
tensor(2.4951, grad_fn=<NllLossBackward0>)
tensor(2.5082, grad_fn=<NllLossBackward0>)
tensor(2.4886, grad_fn=<NllLossBackward0>)
tensor(2.5078, grad_fn=<NllLossBackward0>)
tensor(2.4777, grad_fn=<NllLossBackward0>)
tensor(2.5327, grad_fn=<NllLossBackward0>)
tensor(2.4707, grad_fn=<NllLossBackward0>)
tensor(2.5482, grad_fn=<NllLossBackward0>)
tensor(2.4381, grad_fn=<NllLossBackward0>)
tensor(2.3894, grad_fn=<NllLossBackward0>)
tensor(2.4630, grad_fn=<NllLossBackward0>)
tensor(2.4449, grad_fn=<NllLossBackward0>)
tensor(2.4445, grad_fn=<NllLossBackward0>)
tensor(2.5771, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   672: 0.240
tensor(2.4334, grad_fn=<NllLossBackward0>)
tensor(2.5223, grad_fn=<NllLossBackward0>)
tensor(2.4149, grad_fn=<NllLossBackward0>)
tensor(2.4316, grad_fn=<NllLossBackward0>)
tensor(2.5270, grad_fn=<NllLossBackward0>)
tensor(2.4415, grad_fn=<NllLossBackward0>)
tensor(2.3662, grad_fn=<NllLossBackward0>)
tensor(2.4989, grad_fn=<NllLossBackward0>)
tensor(2.5313, grad_fn=<NllLossBackward0>)
tensor(2.5287, grad_fn=<NllLossBackward0>)
tensor(2.5462, grad_fn=<NllLossBackward0>)
tensor(2.3971, grad_fn=<NllLossBackward0>)
tensor(2.3887, grad_fn=<NllLossBackward0>)
tensor(2.5131, grad_fn=<NllLossBackward0>)
tensor(2.5409, grad_fn=<NllLossBackward0>)
tensor(2.3702, grad_fn=<NllLossBackward0>)
tensor(2.5734, grad_fn=<NllLossBackward0>)
tensor(2.5297, grad_fn=<NllLossBackward0>)
tensor(2.3618, grad_fn=<NllLossBackward0>)
tensor(2.6258, grad_fn=<NllLossBackward0>)
tensor(2.3661, grad_fn=<NllLossBackward0>)
tensor(2.5419, grad_fn=<NllLossBackward0>)
tensor(2.6479, grad_fn=<NllLossBackward0>)
tensor(2.4675, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   696: 0.236
tensor(2.5423, grad_fn=<NllLossBackward0>)
tensor(2.4751, grad_fn=<NllLossBackward0>)
tensor(2.3900, grad_fn=<NllLossBackward0>)
tensor(2.4501, grad_fn=<NllLossBackward0>)
tensor(2.4019, grad_fn=<NllLossBackward0>)
tensor(2.5125, grad_fn=<NllLossBackward0>)
tensor(2.4235, grad_fn=<NllLossBackward0>)
tensor(2.5611, grad_fn=<NllLossBackward0>)
tensor(2.4802, grad_fn=<NllLossBackward0>)
tensor(2.4758, grad_fn=<NllLossBackward0>)
tensor(2.4510, grad_fn=<NllLossBackward0>)
tensor(2.3699, grad_fn=<NllLossBackward0>)
tensor(2.4566, grad_fn=<NllLossBackward0>)
tensor(2.4466, grad_fn=<NllLossBackward0>)
tensor(2.4689, grad_fn=<NllLossBackward0>)
tensor(2.2931, grad_fn=<NllLossBackward0>)
tensor(2.5576, grad_fn=<NllLossBackward0>)
tensor(2.5123, grad_fn=<NllLossBackward0>)
tensor(2.4075, grad_fn=<NllLossBackward0>)
tensor(2.5022, grad_fn=<NllLossBackward0>)
tensor(2.4975, grad_fn=<NllLossBackward0>)
tensor(2.4072, grad_fn=<NllLossBackward0>)
tensor(2.5724, grad_fn=<NllLossBackward0>)
tensor(2.5389, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   720: 0.222
tensor(2.5369, grad_fn=<NllLossBackward0>)
tensor(2.5358, grad_fn=<NllLossBackward0>)
tensor(2.4616, grad_fn=<NllLossBackward0>)
tensor(2.5452, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.4718, grad_fn=<NllLossBackward0>)
tensor(2.5893, grad_fn=<NllLossBackward0>)
tensor(2.4015, grad_fn=<NllLossBackward0>)
tensor(2.4167, grad_fn=<NllLossBackward0>)
tensor(2.4845, grad_fn=<NllLossBackward0>)
tensor(2.3850, grad_fn=<NllLossBackward0>)
tensor(2.4924, grad_fn=<NllLossBackward0>)
tensor(2.5451, grad_fn=<NllLossBackward0>)
tensor(2.4966, grad_fn=<NllLossBackward0>)
tensor(2.5169, grad_fn=<NllLossBackward0>)
tensor(2.4648, grad_fn=<NllLossBackward0>)
tensor(2.4062, grad_fn=<NllLossBackward0>)
tensor(2.4920, grad_fn=<NllLossBackward0>)
tensor(2.4320, grad_fn=<NllLossBackward0>)
tensor(2.3975, grad_fn=<NllLossBackward0>)
tensor(2.5026, grad_fn=<NllLossBackward0>)
tensor(2.5323, grad_fn=<NllLossBackward0>)
tensor(2.5393, grad_fn=<NllLossBackward0>)
tensor(2.3773, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   744: 0.236
tensor(2.4404, grad_fn=<NllLossBackward0>)
tensor(2.4700, grad_fn=<NllLossBackward0>)
tensor(2.5770, grad_fn=<NllLossBackward0>)
tensor(2.4956, grad_fn=<NllLossBackward0>)
tensor(2.4728, grad_fn=<NllLossBackward0>)
tensor(2.4164, grad_fn=<NllLossBackward0>)
tensor(2.4556, grad_fn=<NllLossBackward0>)
tensor(2.4655, grad_fn=<NllLossBackward0>)
tensor(2.5308, grad_fn=<NllLossBackward0>)
tensor(2.5250, grad_fn=<NllLossBackward0>)
tensor(2.4766, grad_fn=<NllLossBackward0>)
tensor(2.5357, grad_fn=<NllLossBackward0>)
tensor(2.5108, grad_fn=<NllLossBackward0>)
tensor(2.4684, grad_fn=<NllLossBackward0>)
tensor(2.5010, grad_fn=<NllLossBackward0>)
tensor(2.4303, grad_fn=<NllLossBackward0>)
tensor(2.4934, grad_fn=<NllLossBackward0>)
tensor(2.4294, grad_fn=<NllLossBackward0>)
tensor(2.3096, grad_fn=<NllLossBackward0>)
tensor(2.4790, grad_fn=<NllLossBackward0>)
tensor(2.4597, grad_fn=<NllLossBackward0>)
tensor(2.4576, grad_fn=<NllLossBackward0>)
tensor(2.4093, grad_fn=<NllLossBackward0>)
tensor(2.5819, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   768: 0.203
tensor(2.4502, grad_fn=<NllLossBackward0>)
tensor(2.5590, grad_fn=<NllLossBackward0>)
tensor(2.4246, grad_fn=<NllLossBackward0>)
tensor(2.5029, grad_fn=<NllLossBackward0>)
tensor(2.4611, grad_fn=<NllLossBackward0>)
tensor(2.3241, grad_fn=<NllLossBackward0>)
tensor(2.4082, grad_fn=<NllLossBackward0>)
tensor(2.4573, grad_fn=<NllLossBackward0>)
tensor(2.4801, grad_fn=<NllLossBackward0>)
tensor(2.3808, grad_fn=<NllLossBackward0>)
tensor(2.4651, grad_fn=<NllLossBackward0>)
tensor(2.5095, grad_fn=<NllLossBackward0>)
tensor(2.3818, grad_fn=<NllLossBackward0>)
tensor(2.3663, grad_fn=<NllLossBackward0>)
tensor(2.4717, grad_fn=<NllLossBackward0>)
tensor(2.5778, grad_fn=<NllLossBackward0>)
tensor(2.5136, grad_fn=<NllLossBackward0>)
tensor(2.5453, grad_fn=<NllLossBackward0>)
tensor(2.2764, grad_fn=<NllLossBackward0>)
tensor(2.3350, grad_fn=<NllLossBackward0>)
tensor(2.4095, grad_fn=<NllLossBackward0>)
tensor(2.4394, grad_fn=<NllLossBackward0>)
tensor(2.3662, grad_fn=<NllLossBackward0>)
tensor(2.3364, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   792: 0.234
tensor(2.5113, grad_fn=<NllLossBackward0>)
tensor(2.4350, grad_fn=<NllLossBackward0>)
tensor(2.4556, grad_fn=<NllLossBackward0>)
tensor(2.4447, grad_fn=<NllLossBackward0>)
tensor(2.5086, grad_fn=<NllLossBackward0>)
tensor(2.4826, grad_fn=<NllLossBackward0>)
tensor(2.5145, grad_fn=<NllLossBackward0>)
tensor(2.3314, grad_fn=<NllLossBackward0>)
tensor(2.5335, grad_fn=<NllLossBackward0>)
tensor(2.4231, grad_fn=<NllLossBackward0>)
tensor(2.4643, grad_fn=<NllLossBackward0>)
tensor(2.4951, grad_fn=<NllLossBackward0>)
tensor(2.5685, grad_fn=<NllLossBackward0>)
tensor(2.4707, grad_fn=<NllLossBackward0>)
tensor(2.3975, grad_fn=<NllLossBackward0>)
tensor(2.4188, grad_fn=<NllLossBackward0>)
tensor(2.3752, grad_fn=<NllLossBackward0>)
tensor(2.4304, grad_fn=<NllLossBackward0>)
tensor(2.4552, grad_fn=<NllLossBackward0>)
tensor(2.5998, grad_fn=<NllLossBackward0>)
tensor(2.3751, grad_fn=<NllLossBackward0>)
tensor(2.2302, grad_fn=<NllLossBackward0>)
tensor(2.5047, grad_fn=<NllLossBackward0>)
tensor(2.5374, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   816: 0.250
tensor(2.3607, grad_fn=<NllLossBackward0>)
tensor(2.4915, grad_fn=<NllLossBackward0>)
tensor(2.4850, grad_fn=<NllLossBackward0>)
tensor(2.4247, grad_fn=<NllLossBackward0>)
tensor(2.4912, grad_fn=<NllLossBackward0>)
tensor(2.4929, grad_fn=<NllLossBackward0>)
tensor(2.5622, grad_fn=<NllLossBackward0>)
tensor(2.3404, grad_fn=<NllLossBackward0>)
tensor(2.3001, grad_fn=<NllLossBackward0>)
tensor(2.5252, grad_fn=<NllLossBackward0>)
tensor(2.5796, grad_fn=<NllLossBackward0>)
tensor(2.4680, grad_fn=<NllLossBackward0>)
tensor(2.3004, grad_fn=<NllLossBackward0>)
tensor(2.4277, grad_fn=<NllLossBackward0>)
tensor(2.5211, grad_fn=<NllLossBackward0>)
tensor(2.4225, grad_fn=<NllLossBackward0>)
tensor(2.4345, grad_fn=<NllLossBackward0>)
tensor(2.2826, grad_fn=<NllLossBackward0>)
tensor(2.3485, grad_fn=<NllLossBackward0>)
tensor(2.5084, grad_fn=<NllLossBackward0>)
tensor(2.5648, grad_fn=<NllLossBackward0>)
tensor(2.5365, grad_fn=<NllLossBackward0>)
tensor(2.3613, grad_fn=<NllLossBackward0>)
tensor(2.4489, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   840: 0.231
tensor(2.4298, grad_fn=<NllLossBackward0>)
tensor(2.5640, grad_fn=<NllLossBackward0>)
tensor(2.4623, grad_fn=<NllLossBackward0>)
tensor(2.4955, grad_fn=<NllLossBackward0>)
tensor(2.3798, grad_fn=<NllLossBackward0>)
tensor(2.3539, grad_fn=<NllLossBackward0>)
tensor(2.4910, grad_fn=<NllLossBackward0>)
tensor(2.3542, grad_fn=<NllLossBackward0>)
tensor(2.3058, grad_fn=<NllLossBackward0>)
tensor(2.4265, grad_fn=<NllLossBackward0>)
tensor(2.3927, grad_fn=<NllLossBackward0>)
tensor(2.4531, grad_fn=<NllLossBackward0>)
tensor(2.3930, grad_fn=<NllLossBackward0>)
tensor(2.4195, grad_fn=<NllLossBackward0>)
tensor(2.4062, grad_fn=<NllLossBackward0>)
tensor(2.4364, grad_fn=<NllLossBackward0>)
tensor(2.3888, grad_fn=<NllLossBackward0>)
tensor(2.3985, grad_fn=<NllLossBackward0>)
tensor(2.3764, grad_fn=<NllLossBackward0>)
tensor(2.4373, grad_fn=<NllLossBackward0>)
tensor(2.4496, grad_fn=<NllLossBackward0>)
tensor(2.2115, grad_fn=<NllLossBackward0>)
tensor(2.4840, grad_fn=<NllLossBackward0>)
tensor(2.2815, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   864: 0.248
tensor(2.4401, grad_fn=<NllLossBackward0>)
tensor(2.5660, grad_fn=<NllLossBackward0>)
tensor(2.4551, grad_fn=<NllLossBackward0>)
tensor(2.4089, grad_fn=<NllLossBackward0>)
tensor(2.4531, grad_fn=<NllLossBackward0>)
tensor(2.2957, grad_fn=<NllLossBackward0>)
tensor(2.3776, grad_fn=<NllLossBackward0>)
tensor(2.4758, grad_fn=<NllLossBackward0>)
tensor(2.4672, grad_fn=<NllLossBackward0>)
tensor(2.4631, grad_fn=<NllLossBackward0>)
tensor(2.4271, grad_fn=<NllLossBackward0>)
tensor(2.4264, grad_fn=<NllLossBackward0>)
tensor(2.5249, grad_fn=<NllLossBackward0>)
tensor(2.5022, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.5380, grad_fn=<NllLossBackward0>)
tensor(2.5019, grad_fn=<NllLossBackward0>)
tensor(2.3911, grad_fn=<NllLossBackward0>)
tensor(2.3350, grad_fn=<NllLossBackward0>)
tensor(2.2611, grad_fn=<NllLossBackward0>)
tensor(2.5569, grad_fn=<NllLossBackward0>)
tensor(2.4291, grad_fn=<NllLossBackward0>)
tensor(2.4561, grad_fn=<NllLossBackward0>)
tensor(2.6105, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   888: 0.196
tensor(2.3374, grad_fn=<NllLossBackward0>)
tensor(2.3743, grad_fn=<NllLossBackward0>)
tensor(2.2701, grad_fn=<NllLossBackward0>)
tensor(2.3866, grad_fn=<NllLossBackward0>)
tensor(2.5477, grad_fn=<NllLossBackward0>)
tensor(2.6476, grad_fn=<NllLossBackward0>)
tensor(2.4799, grad_fn=<NllLossBackward0>)
tensor(2.4482, grad_fn=<NllLossBackward0>)
tensor(2.3514, grad_fn=<NllLossBackward0>)
tensor(2.5134, grad_fn=<NllLossBackward0>)
tensor(2.4109, grad_fn=<NllLossBackward0>)
tensor(2.3366, grad_fn=<NllLossBackward0>)
tensor(2.3026, grad_fn=<NllLossBackward0>)
tensor(2.3056, grad_fn=<NllLossBackward0>)
tensor(2.3263, grad_fn=<NllLossBackward0>)
tensor(2.4838, grad_fn=<NllLossBackward0>)
tensor(2.4243, grad_fn=<NllLossBackward0>)
tensor(2.3996, grad_fn=<NllLossBackward0>)
tensor(2.4302, grad_fn=<NllLossBackward0>)
tensor(2.3023, grad_fn=<NllLossBackward0>)
tensor(2.4765, grad_fn=<NllLossBackward0>)
tensor(2.3276, grad_fn=<NllLossBackward0>)
tensor(2.4226, grad_fn=<NllLossBackward0>)
tensor(2.4005, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   912: 0.245
tensor(2.3090, grad_fn=<NllLossBackward0>)
tensor(2.4033, grad_fn=<NllLossBackward0>)
tensor(2.4415, grad_fn=<NllLossBackward0>)
tensor(2.5941, grad_fn=<NllLossBackward0>)
tensor(2.4325, grad_fn=<NllLossBackward0>)
tensor(2.2886, grad_fn=<NllLossBackward0>)
tensor(2.4474, grad_fn=<NllLossBackward0>)
tensor(2.3873, grad_fn=<NllLossBackward0>)
tensor(2.3831, grad_fn=<NllLossBackward0>)
tensor(2.4098, grad_fn=<NllLossBackward0>)
tensor(2.4918, grad_fn=<NllLossBackward0>)
tensor(2.4752, grad_fn=<NllLossBackward0>)
tensor(2.1380, grad_fn=<NllLossBackward0>)
tensor(2.4102, grad_fn=<NllLossBackward0>)
tensor(2.5367, grad_fn=<NllLossBackward0>)
tensor(2.4275, grad_fn=<NllLossBackward0>)
tensor(2.3010, grad_fn=<NllLossBackward0>)
tensor(2.4053, grad_fn=<NllLossBackward0>)
tensor(2.3472, grad_fn=<NllLossBackward0>)
tensor(2.2970, grad_fn=<NllLossBackward0>)
tensor(2.5055, grad_fn=<NllLossBackward0>)
tensor(2.3426, grad_fn=<NllLossBackward0>)
tensor(2.4053, grad_fn=<NllLossBackward0>)
tensor(2.4445, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   936: 0.217
tensor(2.4195, grad_fn=<NllLossBackward0>)
tensor(2.5578, grad_fn=<NllLossBackward0>)
tensor(2.4395, grad_fn=<NllLossBackward0>)
tensor(2.3385, grad_fn=<NllLossBackward0>)
tensor(2.6448, grad_fn=<NllLossBackward0>)
tensor(2.5024, grad_fn=<NllLossBackward0>)
tensor(2.4377, grad_fn=<NllLossBackward0>)
tensor(2.4855, grad_fn=<NllLossBackward0>)
tensor(2.4054, grad_fn=<NllLossBackward0>)
tensor(2.4636, grad_fn=<NllLossBackward0>)
tensor(2.3504, grad_fn=<NllLossBackward0>)
tensor(2.3114, grad_fn=<NllLossBackward0>)
tensor(2.4123, grad_fn=<NllLossBackward0>)
tensor(2.3718, grad_fn=<NllLossBackward0>)
tensor(2.4823, grad_fn=<NllLossBackward0>)
tensor(2.4027, grad_fn=<NllLossBackward0>)
tensor(2.3928, grad_fn=<NllLossBackward0>)
tensor(2.3927, grad_fn=<NllLossBackward0>)
tensor(2.4960, grad_fn=<NllLossBackward0>)
tensor(2.3215, grad_fn=<NllLossBackward0>)
tensor(2.4551, grad_fn=<NllLossBackward0>)
tensor(2.3363, grad_fn=<NllLossBackward0>)
tensor(2.3910, grad_fn=<NllLossBackward0>)
tensor(2.4201, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   960: 0.214
tensor(2.3267, grad_fn=<NllLossBackward0>)
tensor(2.3341, grad_fn=<NllLossBackward0>)
tensor(2.4881, grad_fn=<NllLossBackward0>)
tensor(2.3401, grad_fn=<NllLossBackward0>)
tensor(2.4002, grad_fn=<NllLossBackward0>)
tensor(2.3973, grad_fn=<NllLossBackward0>)
tensor(2.4794, grad_fn=<NllLossBackward0>)
tensor(2.4250, grad_fn=<NllLossBackward0>)
tensor(2.2700, grad_fn=<NllLossBackward0>)
tensor(2.3903, grad_fn=<NllLossBackward0>)
tensor(2.3353, grad_fn=<NllLossBackward0>)
tensor(2.3033, grad_fn=<NllLossBackward0>)
tensor(2.3680, grad_fn=<NllLossBackward0>)
tensor(2.3670, grad_fn=<NllLossBackward0>)
tensor(2.2498, grad_fn=<NllLossBackward0>)
tensor(2.4438, grad_fn=<NllLossBackward0>)
tensor(2.3474, grad_fn=<NllLossBackward0>)
tensor(2.3692, grad_fn=<NllLossBackward0>)
tensor(2.2190, grad_fn=<NllLossBackward0>)
tensor(2.4020, grad_fn=<NllLossBackward0>)
tensor(2.3225, grad_fn=<NllLossBackward0>)
tensor(2.3142, grad_fn=<NllLossBackward0>)
tensor(2.4740, grad_fn=<NllLossBackward0>)
tensor(2.4522, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   984: 0.248
tensor(2.3861, grad_fn=<NllLossBackward0>)
tensor(2.3374, grad_fn=<NllLossBackward0>)
tensor(2.3967, grad_fn=<NllLossBackward0>)
tensor(2.4803, grad_fn=<NllLossBackward0>)
tensor(2.5848, grad_fn=<NllLossBackward0>)
tensor(2.3650, grad_fn=<NllLossBackward0>)
tensor(2.4046, grad_fn=<NllLossBackward0>)
tensor(2.4488, grad_fn=<NllLossBackward0>)
tensor(2.5260, grad_fn=<NllLossBackward0>)
tensor(2.4779, grad_fn=<NllLossBackward0>)
tensor(2.4677, grad_fn=<NllLossBackward0>)
tensor(2.4388, grad_fn=<NllLossBackward0>)
tensor(2.4408, grad_fn=<NllLossBackward0>)
tensor(2.3979, grad_fn=<NllLossBackward0>)
tensor(2.3681, grad_fn=<NllLossBackward0>)
tensor(2.4114, grad_fn=<NllLossBackward0>)
tensor(2.3113, grad_fn=<NllLossBackward0>)
tensor(2.2430, grad_fn=<NllLossBackward0>)
tensor(2.4375, grad_fn=<NllLossBackward0>)
tensor(2.3590, grad_fn=<NllLossBackward0>)
tensor(2.3180, grad_fn=<NllLossBackward0>)
tensor(2.3429, grad_fn=<NllLossBackward0>)
tensor(2.3430, grad_fn=<NllLossBackward0>)
tensor(2.4229, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1008: 0.243
tensor(2.2371, grad_fn=<NllLossBackward0>)
tensor(2.3051, grad_fn=<NllLossBackward0>)
tensor(2.2831, grad_fn=<NllLossBackward0>)
tensor(2.4457, grad_fn=<NllLossBackward0>)
tensor(2.3559, grad_fn=<NllLossBackward0>)
tensor(2.3330, grad_fn=<NllLossBackward0>)
tensor(2.3097, grad_fn=<NllLossBackward0>)
tensor(2.4586, grad_fn=<NllLossBackward0>)
tensor(2.4303, grad_fn=<NllLossBackward0>)
tensor(2.2822, grad_fn=<NllLossBackward0>)
tensor(2.4821, grad_fn=<NllLossBackward0>)
tensor(2.4482, grad_fn=<NllLossBackward0>)
tensor(2.4635, grad_fn=<NllLossBackward0>)
tensor(2.3168, grad_fn=<NllLossBackward0>)
tensor(2.4318, grad_fn=<NllLossBackward0>)
tensor(2.5122, grad_fn=<NllLossBackward0>)
tensor(2.2810, grad_fn=<NllLossBackward0>)
tensor(2.4503, grad_fn=<NllLossBackward0>)
tensor(2.5793, grad_fn=<NllLossBackward0>)
tensor(2.3711, grad_fn=<NllLossBackward0>)
tensor(2.5102, grad_fn=<NllLossBackward0>)
tensor(2.5426, grad_fn=<NllLossBackward0>)
tensor(2.4260, grad_fn=<NllLossBackward0>)
tensor(2.4159, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1032: 0.227
tensor(2.4919, grad_fn=<NllLossBackward0>)
tensor(2.2567, grad_fn=<NllLossBackward0>)
tensor(2.2382, grad_fn=<NllLossBackward0>)
tensor(2.5225, grad_fn=<NllLossBackward0>)
tensor(2.3936, grad_fn=<NllLossBackward0>)
tensor(2.2872, grad_fn=<NllLossBackward0>)
tensor(2.3164, grad_fn=<NllLossBackward0>)
tensor(2.4787, grad_fn=<NllLossBackward0>)
tensor(2.3849, grad_fn=<NllLossBackward0>)
tensor(2.2310, grad_fn=<NllLossBackward0>)
tensor(2.3647, grad_fn=<NllLossBackward0>)
tensor(2.5001, grad_fn=<NllLossBackward0>)
tensor(2.4578, grad_fn=<NllLossBackward0>)
tensor(2.4026, grad_fn=<NllLossBackward0>)
tensor(2.4902, grad_fn=<NllLossBackward0>)
tensor(2.2654, grad_fn=<NllLossBackward0>)
tensor(2.4939, grad_fn=<NllLossBackward0>)
tensor(2.5010, grad_fn=<NllLossBackward0>)
tensor(2.3043, grad_fn=<NllLossBackward0>)
tensor(2.3677, grad_fn=<NllLossBackward0>)
tensor(2.3998, grad_fn=<NllLossBackward0>)
tensor(2.3893, grad_fn=<NllLossBackward0>)
tensor(2.3159, grad_fn=<NllLossBackward0>)
tensor(2.4570, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1056: 0.264
tensor(2.4919, grad_fn=<NllLossBackward0>)
tensor(2.4426, grad_fn=<NllLossBackward0>)
tensor(2.3428, grad_fn=<NllLossBackward0>)
tensor(2.3995, grad_fn=<NllLossBackward0>)
tensor(2.4069, grad_fn=<NllLossBackward0>)
tensor(2.4309, grad_fn=<NllLossBackward0>)
tensor(2.3064, grad_fn=<NllLossBackward0>)
tensor(2.4151, grad_fn=<NllLossBackward0>)
tensor(2.2465, grad_fn=<NllLossBackward0>)
tensor(2.5207, grad_fn=<NllLossBackward0>)
tensor(2.4536, grad_fn=<NllLossBackward0>)
tensor(2.4667, grad_fn=<NllLossBackward0>)
tensor(2.3670, grad_fn=<NllLossBackward0>)
tensor(2.4692, grad_fn=<NllLossBackward0>)
tensor(2.5193, grad_fn=<NllLossBackward0>)
tensor(2.4831, grad_fn=<NllLossBackward0>)
tensor(2.3783, grad_fn=<NllLossBackward0>)
tensor(2.3772, grad_fn=<NllLossBackward0>)
tensor(2.5144, grad_fn=<NllLossBackward0>)
tensor(2.3963, grad_fn=<NllLossBackward0>)
tensor(2.3334, grad_fn=<NllLossBackward0>)
tensor(2.2685, grad_fn=<NllLossBackward0>)
tensor(2.4119, grad_fn=<NllLossBackward0>)
tensor(2.3804, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1080: 0.233
tensor(2.4512, grad_fn=<NllLossBackward0>)
tensor(2.4506, grad_fn=<NllLossBackward0>)
tensor(2.3551, grad_fn=<NllLossBackward0>)
tensor(2.3528, grad_fn=<NllLossBackward0>)
tensor(2.3313, grad_fn=<NllLossBackward0>)
tensor(2.3521, grad_fn=<NllLossBackward0>)
tensor(2.3968, grad_fn=<NllLossBackward0>)
tensor(2.4641, grad_fn=<NllLossBackward0>)
tensor(2.4052, grad_fn=<NllLossBackward0>)
tensor(2.3574, grad_fn=<NllLossBackward0>)
tensor(2.1288, grad_fn=<NllLossBackward0>)
tensor(2.3442, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.3108, grad_fn=<NllLossBackward0>)
tensor(2.4301, grad_fn=<NllLossBackward0>)
tensor(2.5266, grad_fn=<NllLossBackward0>)
tensor(2.3521, grad_fn=<NllLossBackward0>)
tensor(2.3188, grad_fn=<NllLossBackward0>)
tensor(2.3677, grad_fn=<NllLossBackward0>)
tensor(2.2734, grad_fn=<NllLossBackward0>)
tensor(2.5271, grad_fn=<NllLossBackward0>)
tensor(2.3158, grad_fn=<NllLossBackward0>)
tensor(2.3286, grad_fn=<NllLossBackward0>)
tensor(2.3963, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1104: 0.264
tensor(2.3261, grad_fn=<NllLossBackward0>)
tensor(2.5110, grad_fn=<NllLossBackward0>)
tensor(2.5612, grad_fn=<NllLossBackward0>)
tensor(2.3655, grad_fn=<NllLossBackward0>)
tensor(2.3159, grad_fn=<NllLossBackward0>)
tensor(2.2963, grad_fn=<NllLossBackward0>)
tensor(2.3073, grad_fn=<NllLossBackward0>)
tensor(2.4860, grad_fn=<NllLossBackward0>)
tensor(2.4116, grad_fn=<NllLossBackward0>)
tensor(2.2369, grad_fn=<NllLossBackward0>)
tensor(2.3905, grad_fn=<NllLossBackward0>)
tensor(2.3158, grad_fn=<NllLossBackward0>)
tensor(2.5133, grad_fn=<NllLossBackward0>)
tensor(2.4169, grad_fn=<NllLossBackward0>)
tensor(2.3067, grad_fn=<NllLossBackward0>)
tensor(2.4755, grad_fn=<NllLossBackward0>)
tensor(2.3232, grad_fn=<NllLossBackward0>)
tensor(2.2647, grad_fn=<NllLossBackward0>)
tensor(2.3866, grad_fn=<NllLossBackward0>)
tensor(2.3848, grad_fn=<NllLossBackward0>)
tensor(2.5238, grad_fn=<NllLossBackward0>)
tensor(2.4512, grad_fn=<NllLossBackward0>)
tensor(2.2389, grad_fn=<NllLossBackward0>)
tensor(2.3933, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1128: 0.220
tensor(2.3112, grad_fn=<NllLossBackward0>)
tensor(2.4575, grad_fn=<NllLossBackward0>)
tensor(2.3666, grad_fn=<NllLossBackward0>)
tensor(2.3291, grad_fn=<NllLossBackward0>)
tensor(2.3637, grad_fn=<NllLossBackward0>)
tensor(2.5125, grad_fn=<NllLossBackward0>)
tensor(2.3632, grad_fn=<NllLossBackward0>)
tensor(2.3030, grad_fn=<NllLossBackward0>)
tensor(2.4889, grad_fn=<NllLossBackward0>)
tensor(2.3132, grad_fn=<NllLossBackward0>)
tensor(2.2236, grad_fn=<NllLossBackward0>)
tensor(2.3900, grad_fn=<NllLossBackward0>)
tensor(2.4088, grad_fn=<NllLossBackward0>)
tensor(2.3741, grad_fn=<NllLossBackward0>)
tensor(2.4750, grad_fn=<NllLossBackward0>)
tensor(2.4567, grad_fn=<NllLossBackward0>)
tensor(2.3717, grad_fn=<NllLossBackward0>)
tensor(2.4484, grad_fn=<NllLossBackward0>)
tensor(2.3556, grad_fn=<NllLossBackward0>)
tensor(2.4524, grad_fn=<NllLossBackward0>)
tensor(2.4798, grad_fn=<NllLossBackward0>)
tensor(2.3106, grad_fn=<NllLossBackward0>)
tensor(2.4577, grad_fn=<NllLossBackward0>)
tensor(2.3785, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1152: 0.203
tensor(2.3471, grad_fn=<NllLossBackward0>)
tensor(2.3227, grad_fn=<NllLossBackward0>)
tensor(2.2807, grad_fn=<NllLossBackward0>)
tensor(2.4567, grad_fn=<NllLossBackward0>)
tensor(2.5144, grad_fn=<NllLossBackward0>)
tensor(2.2261, grad_fn=<NllLossBackward0>)
tensor(2.3916, grad_fn=<NllLossBackward0>)
tensor(2.3759, grad_fn=<NllLossBackward0>)
tensor(2.3830, grad_fn=<NllLossBackward0>)
tensor(2.4130, grad_fn=<NllLossBackward0>)
tensor(2.2916, grad_fn=<NllLossBackward0>)
tensor(2.5182, grad_fn=<NllLossBackward0>)
tensor(2.5368, grad_fn=<NllLossBackward0>)
tensor(2.2707, grad_fn=<NllLossBackward0>)
tensor(2.3494, grad_fn=<NllLossBackward0>)
tensor(2.3379, grad_fn=<NllLossBackward0>)
tensor(2.5272, grad_fn=<NllLossBackward0>)
tensor(2.3713, grad_fn=<NllLossBackward0>)
tensor(2.3178, grad_fn=<NllLossBackward0>)
tensor(2.2250, grad_fn=<NllLossBackward0>)
tensor(2.3935, grad_fn=<NllLossBackward0>)
tensor(2.3753, grad_fn=<NllLossBackward0>)
tensor(2.3882, grad_fn=<NllLossBackward0>)
tensor(2.3439, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1176: 0.252
tensor(2.2764, grad_fn=<NllLossBackward0>)
tensor(2.4222, grad_fn=<NllLossBackward0>)
tensor(2.3045, grad_fn=<NllLossBackward0>)
tensor(2.2721, grad_fn=<NllLossBackward0>)
tensor(2.4474, grad_fn=<NllLossBackward0>)
tensor(2.3822, grad_fn=<NllLossBackward0>)
tensor(2.3059, grad_fn=<NllLossBackward0>)
tensor(2.3892, grad_fn=<NllLossBackward0>)
tensor(2.4344, grad_fn=<NllLossBackward0>)
tensor(2.3525, grad_fn=<NllLossBackward0>)
tensor(2.4143, grad_fn=<NllLossBackward0>)
tensor(2.5077, grad_fn=<NllLossBackward0>)
tensor(2.3308, grad_fn=<NllLossBackward0>)
tensor(2.4126, grad_fn=<NllLossBackward0>)
tensor(2.2465, grad_fn=<NllLossBackward0>)
tensor(2.4257, grad_fn=<NllLossBackward0>)
tensor(2.4628, grad_fn=<NllLossBackward0>)
tensor(2.3992, grad_fn=<NllLossBackward0>)
tensor(2.4319, grad_fn=<NllLossBackward0>)
tensor(2.2362, grad_fn=<NllLossBackward0>)
tensor(2.3211, grad_fn=<NllLossBackward0>)
tensor(2.3549, grad_fn=<NllLossBackward0>)
tensor(2.3437, grad_fn=<NllLossBackward0>)
tensor(2.5216, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1200: 0.220
tensor(2.4379, grad_fn=<NllLossBackward0>)
tensor(2.4903, grad_fn=<NllLossBackward0>)
tensor(2.3944, grad_fn=<NllLossBackward0>)
tensor(2.3549, grad_fn=<NllLossBackward0>)
tensor(2.3580, grad_fn=<NllLossBackward0>)
tensor(2.2965, grad_fn=<NllLossBackward0>)
tensor(2.4238, grad_fn=<NllLossBackward0>)
tensor(2.2513, grad_fn=<NllLossBackward0>)
tensor(2.3370, grad_fn=<NllLossBackward0>)
tensor(2.2528, grad_fn=<NllLossBackward0>)
tensor(2.2239, grad_fn=<NllLossBackward0>)
tensor(2.4585, grad_fn=<NllLossBackward0>)
tensor(2.3998, grad_fn=<NllLossBackward0>)
tensor(2.2388, grad_fn=<NllLossBackward0>)
tensor(2.3748, grad_fn=<NllLossBackward0>)
tensor(2.2673, grad_fn=<NllLossBackward0>)
tensor(2.3748, grad_fn=<NllLossBackward0>)
tensor(2.3552, grad_fn=<NllLossBackward0>)
tensor(2.3751, grad_fn=<NllLossBackward0>)
tensor(2.2857, grad_fn=<NllLossBackward0>)
tensor(2.3077, grad_fn=<NllLossBackward0>)
tensor(2.4803, grad_fn=<NllLossBackward0>)
tensor(2.3874, grad_fn=<NllLossBackward0>)
tensor(2.3662, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1224: 0.247
tensor(2.4893, grad_fn=<NllLossBackward0>)
tensor(2.4737, grad_fn=<NllLossBackward0>)
tensor(2.3424, grad_fn=<NllLossBackward0>)
tensor(2.3415, grad_fn=<NllLossBackward0>)
tensor(2.4659, grad_fn=<NllLossBackward0>)
tensor(2.3343, grad_fn=<NllLossBackward0>)
tensor(2.4661, grad_fn=<NllLossBackward0>)
tensor(2.2466, grad_fn=<NllLossBackward0>)
tensor(2.5032, grad_fn=<NllLossBackward0>)
tensor(2.4496, grad_fn=<NllLossBackward0>)
tensor(2.3426, grad_fn=<NllLossBackward0>)
tensor(2.2650, grad_fn=<NllLossBackward0>)
tensor(2.4673, grad_fn=<NllLossBackward0>)
tensor(2.3489, grad_fn=<NllLossBackward0>)
tensor(2.4691, grad_fn=<NllLossBackward0>)
tensor(2.3793, grad_fn=<NllLossBackward0>)
tensor(2.3669, grad_fn=<NllLossBackward0>)
tensor(2.2493, grad_fn=<NllLossBackward0>)
tensor(2.3817, grad_fn=<NllLossBackward0>)
tensor(2.3313, grad_fn=<NllLossBackward0>)
tensor(2.3657, grad_fn=<NllLossBackward0>)
tensor(2.4402, grad_fn=<NllLossBackward0>)
tensor(2.2151, grad_fn=<NllLossBackward0>)
tensor(2.2940, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1248: 0.260
tensor(2.4478, grad_fn=<NllLossBackward0>)
tensor(2.4010, grad_fn=<NllLossBackward0>)
tensor(2.5080, grad_fn=<NllLossBackward0>)
tensor(2.4138, grad_fn=<NllLossBackward0>)
tensor(2.2895, grad_fn=<NllLossBackward0>)
tensor(2.3252, grad_fn=<NllLossBackward0>)
tensor(2.1871, grad_fn=<NllLossBackward0>)
tensor(2.3928, grad_fn=<NllLossBackward0>)
tensor(2.3173, grad_fn=<NllLossBackward0>)
tensor(2.4143, grad_fn=<NllLossBackward0>)
tensor(2.4536, grad_fn=<NllLossBackward0>)
tensor(2.5195, grad_fn=<NllLossBackward0>)
tensor(2.2451, grad_fn=<NllLossBackward0>)
tensor(2.5114, grad_fn=<NllLossBackward0>)
tensor(2.3924, grad_fn=<NllLossBackward0>)
tensor(2.3265, grad_fn=<NllLossBackward0>)
tensor(2.4526, grad_fn=<NllLossBackward0>)
tensor(2.4179, grad_fn=<NllLossBackward0>)
tensor(2.3903, grad_fn=<NllLossBackward0>)
tensor(2.3764, grad_fn=<NllLossBackward0>)
tensor(2.2924, grad_fn=<NllLossBackward0>)
tensor(2.4603, grad_fn=<NllLossBackward0>)
tensor(2.3751, grad_fn=<NllLossBackward0>)
tensor(2.4976, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1272: 0.217
tensor(2.2533, grad_fn=<NllLossBackward0>)
tensor(2.3352, grad_fn=<NllLossBackward0>)
tensor(2.4146, grad_fn=<NllLossBackward0>)
tensor(2.4078, grad_fn=<NllLossBackward0>)
tensor(2.4147, grad_fn=<NllLossBackward0>)
tensor(2.3215, grad_fn=<NllLossBackward0>)
tensor(2.4100, grad_fn=<NllLossBackward0>)
tensor(2.1721, grad_fn=<NllLossBackward0>)
tensor(2.3779, grad_fn=<NllLossBackward0>)
tensor(2.4408, grad_fn=<NllLossBackward0>)
tensor(2.3487, grad_fn=<NllLossBackward0>)
tensor(2.4671, grad_fn=<NllLossBackward0>)
tensor(2.4826, grad_fn=<NllLossBackward0>)
tensor(2.4980, grad_fn=<NllLossBackward0>)
tensor(2.4171, grad_fn=<NllLossBackward0>)
tensor(2.2981, grad_fn=<NllLossBackward0>)
tensor(2.3648, grad_fn=<NllLossBackward0>)
tensor(2.3382, grad_fn=<NllLossBackward0>)
tensor(2.3286, grad_fn=<NllLossBackward0>)
tensor(2.3920, grad_fn=<NllLossBackward0>)
tensor(2.3298, grad_fn=<NllLossBackward0>)
tensor(2.3780, grad_fn=<NllLossBackward0>)
tensor(2.4642, grad_fn=<NllLossBackward0>)
tensor(2.3980, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1296: 0.227
tensor(2.3958, grad_fn=<NllLossBackward0>)
tensor(2.3803, grad_fn=<NllLossBackward0>)
tensor(2.3483, grad_fn=<NllLossBackward0>)
tensor(2.4656, grad_fn=<NllLossBackward0>)
tensor(2.3772, grad_fn=<NllLossBackward0>)
tensor(2.1745, grad_fn=<NllLossBackward0>)
tensor(2.2903, grad_fn=<NllLossBackward0>)
tensor(2.3631, grad_fn=<NllLossBackward0>)
tensor(2.3487, grad_fn=<NllLossBackward0>)
tensor(2.4640, grad_fn=<NllLossBackward0>)
tensor(2.4643, grad_fn=<NllLossBackward0>)
tensor(2.3778, grad_fn=<NllLossBackward0>)
tensor(2.2537, grad_fn=<NllLossBackward0>)
tensor(2.3681, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.3853, grad_fn=<NllLossBackward0>)
tensor(2.5082, grad_fn=<NllLossBackward0>)
tensor(2.4481, grad_fn=<NllLossBackward0>)
tensor(2.3848, grad_fn=<NllLossBackward0>)
tensor(2.5067, grad_fn=<NllLossBackward0>)
tensor(2.3899, grad_fn=<NllLossBackward0>)
tensor(2.4151, grad_fn=<NllLossBackward0>)
tensor(2.3714, grad_fn=<NllLossBackward0>)
tensor(2.3380, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1320: 0.214
tensor(2.4787, grad_fn=<NllLossBackward0>)
tensor(2.2663, grad_fn=<NllLossBackward0>)
tensor(2.3729, grad_fn=<NllLossBackward0>)
tensor(2.3439, grad_fn=<NllLossBackward0>)
tensor(2.4357, grad_fn=<NllLossBackward0>)
tensor(2.3929, grad_fn=<NllLossBackward0>)
tensor(2.1412, grad_fn=<NllLossBackward0>)
tensor(2.2942, grad_fn=<NllLossBackward0>)
tensor(2.4436, grad_fn=<NllLossBackward0>)
tensor(2.2314, grad_fn=<NllLossBackward0>)
tensor(2.4117, grad_fn=<NllLossBackward0>)
tensor(2.3519, grad_fn=<NllLossBackward0>)
tensor(2.4531, grad_fn=<NllLossBackward0>)
tensor(2.3455, grad_fn=<NllLossBackward0>)
tensor(2.1891, grad_fn=<NllLossBackward0>)
tensor(2.4185, grad_fn=<NllLossBackward0>)
tensor(2.3888, grad_fn=<NllLossBackward0>)
tensor(2.3328, grad_fn=<NllLossBackward0>)
tensor(2.3922, grad_fn=<NllLossBackward0>)
tensor(2.3405, grad_fn=<NllLossBackward0>)
tensor(2.3502, grad_fn=<NllLossBackward0>)
tensor(2.2054, grad_fn=<NllLossBackward0>)
tensor(2.3731, grad_fn=<NllLossBackward0>)
tensor(2.3559, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1344: 0.240
tensor(2.3396, grad_fn=<NllLossBackward0>)
tensor(2.4561, grad_fn=<NllLossBackward0>)
tensor(2.3620, grad_fn=<NllLossBackward0>)
tensor(2.1951, grad_fn=<NllLossBackward0>)
tensor(2.4737, grad_fn=<NllLossBackward0>)
tensor(2.3466, grad_fn=<NllLossBackward0>)
tensor(2.3500, grad_fn=<NllLossBackward0>)
tensor(2.4911, grad_fn=<NllLossBackward0>)
tensor(2.4405, grad_fn=<NllLossBackward0>)
tensor(2.2530, grad_fn=<NllLossBackward0>)
tensor(2.3011, grad_fn=<NllLossBackward0>)
tensor(2.4475, grad_fn=<NllLossBackward0>)
tensor(2.4562, grad_fn=<NllLossBackward0>)
tensor(2.3891, grad_fn=<NllLossBackward0>)
tensor(2.4704, grad_fn=<NllLossBackward0>)
tensor(2.4133, grad_fn=<NllLossBackward0>)
tensor(2.4689, grad_fn=<NllLossBackward0>)
tensor(2.5038, grad_fn=<NllLossBackward0>)
tensor(2.3618, grad_fn=<NllLossBackward0>)
tensor(2.2654, grad_fn=<NllLossBackward0>)
tensor(2.2010, grad_fn=<NllLossBackward0>)
tensor(2.2751, grad_fn=<NllLossBackward0>)
tensor(2.3076, grad_fn=<NllLossBackward0>)
tensor(2.3127, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1368: 0.226
tensor(2.1670, grad_fn=<NllLossBackward0>)
tensor(2.3103, grad_fn=<NllLossBackward0>)
tensor(2.1854, grad_fn=<NllLossBackward0>)
tensor(2.2708, grad_fn=<NllLossBackward0>)
tensor(2.3334, grad_fn=<NllLossBackward0>)
tensor(2.4399, grad_fn=<NllLossBackward0>)
tensor(2.2898, grad_fn=<NllLossBackward0>)
tensor(2.3930, grad_fn=<NllLossBackward0>)
tensor(2.3869, grad_fn=<NllLossBackward0>)
tensor(2.4386, grad_fn=<NllLossBackward0>)
tensor(2.2226, grad_fn=<NllLossBackward0>)
tensor(2.4596, grad_fn=<NllLossBackward0>)
tensor(2.2114, grad_fn=<NllLossBackward0>)
tensor(2.3858, grad_fn=<NllLossBackward0>)
tensor(2.3106, grad_fn=<NllLossBackward0>)
tensor(2.2743, grad_fn=<NllLossBackward0>)
tensor(2.2970, grad_fn=<NllLossBackward0>)
tensor(2.4003, grad_fn=<NllLossBackward0>)
tensor(2.2833, grad_fn=<NllLossBackward0>)
tensor(2.2063, grad_fn=<NllLossBackward0>)
tensor(2.2582, grad_fn=<NllLossBackward0>)
tensor(2.1360, grad_fn=<NllLossBackward0>)
tensor(2.2042, grad_fn=<NllLossBackward0>)
tensor(2.3056, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1392: 0.247
tensor(2.2895, grad_fn=<NllLossBackward0>)
tensor(2.3289, grad_fn=<NllLossBackward0>)
tensor(2.2222, grad_fn=<NllLossBackward0>)
tensor(2.3012, grad_fn=<NllLossBackward0>)
tensor(2.4000, grad_fn=<NllLossBackward0>)
tensor(2.2669, grad_fn=<NllLossBackward0>)
tensor(2.4024, grad_fn=<NllLossBackward0>)
tensor(2.3046, grad_fn=<NllLossBackward0>)
tensor(2.3119, grad_fn=<NllLossBackward0>)
tensor(2.4165, grad_fn=<NllLossBackward0>)
tensor(2.4581, grad_fn=<NllLossBackward0>)
tensor(2.4090, grad_fn=<NllLossBackward0>)
tensor(2.4675, grad_fn=<NllLossBackward0>)
tensor(2.3167, grad_fn=<NllLossBackward0>)
tensor(2.2902, grad_fn=<NllLossBackward0>)
tensor(2.2422, grad_fn=<NllLossBackward0>)
tensor(2.3245, grad_fn=<NllLossBackward0>)
tensor(2.2407, grad_fn=<NllLossBackward0>)
tensor(2.3957, grad_fn=<NllLossBackward0>)
tensor(2.4069, grad_fn=<NllLossBackward0>)
tensor(2.3955, grad_fn=<NllLossBackward0>)
tensor(2.2433, grad_fn=<NllLossBackward0>)
tensor(2.3090, grad_fn=<NllLossBackward0>)
tensor(2.4756, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1416: 0.240
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.3035, grad_fn=<NllLossBackward0>)
tensor(2.4056, grad_fn=<NllLossBackward0>)
tensor(2.4450, grad_fn=<NllLossBackward0>)
tensor(2.1557, grad_fn=<NllLossBackward0>)
tensor(2.2458, grad_fn=<NllLossBackward0>)
tensor(2.3974, grad_fn=<NllLossBackward0>)
tensor(2.4178, grad_fn=<NllLossBackward0>)
tensor(2.2291, grad_fn=<NllLossBackward0>)
tensor(2.3577, grad_fn=<NllLossBackward0>)
tensor(2.3293, grad_fn=<NllLossBackward0>)
tensor(2.2607, grad_fn=<NllLossBackward0>)
tensor(2.3898, grad_fn=<NllLossBackward0>)
tensor(2.2801, grad_fn=<NllLossBackward0>)
tensor(2.3040, grad_fn=<NllLossBackward0>)
tensor(2.3264, grad_fn=<NllLossBackward0>)
tensor(2.4930, grad_fn=<NllLossBackward0>)
tensor(2.3726, grad_fn=<NllLossBackward0>)
tensor(2.2072, grad_fn=<NllLossBackward0>)
tensor(2.3010, grad_fn=<NllLossBackward0>)
tensor(2.2596, grad_fn=<NllLossBackward0>)
tensor(2.4080, grad_fn=<NllLossBackward0>)
tensor(2.4219, grad_fn=<NllLossBackward0>)
tensor(2.3499, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1440: 0.248
tensor(2.2991, grad_fn=<NllLossBackward0>)
tensor(2.2270, grad_fn=<NllLossBackward0>)
tensor(2.3780, grad_fn=<NllLossBackward0>)
tensor(2.3156, grad_fn=<NllLossBackward0>)
tensor(2.4416, grad_fn=<NllLossBackward0>)
tensor(2.4273, grad_fn=<NllLossBackward0>)
tensor(2.3549, grad_fn=<NllLossBackward0>)
tensor(2.2044, grad_fn=<NllLossBackward0>)
tensor(2.2906, grad_fn=<NllLossBackward0>)
tensor(2.3520, grad_fn=<NllLossBackward0>)
tensor(2.3255, grad_fn=<NllLossBackward0>)
tensor(2.3876, grad_fn=<NllLossBackward0>)
tensor(2.4486, grad_fn=<NllLossBackward0>)
tensor(2.1393, grad_fn=<NllLossBackward0>)
tensor(2.4523, grad_fn=<NllLossBackward0>)
tensor(2.3314, grad_fn=<NllLossBackward0>)
tensor(2.3447, grad_fn=<NllLossBackward0>)
tensor(2.1374, grad_fn=<NllLossBackward0>)
tensor(2.2838, grad_fn=<NllLossBackward0>)
tensor(2.4332, grad_fn=<NllLossBackward0>)
tensor(2.2921, grad_fn=<NllLossBackward0>)
tensor(2.4778, grad_fn=<NllLossBackward0>)
tensor(2.3531, grad_fn=<NllLossBackward0>)
tensor(2.4002, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1464: 0.234
tensor(2.3066, grad_fn=<NllLossBackward0>)
tensor(2.4019, grad_fn=<NllLossBackward0>)
tensor(2.3708, grad_fn=<NllLossBackward0>)
tensor(2.4320, grad_fn=<NllLossBackward0>)
tensor(2.1890, grad_fn=<NllLossBackward0>)
tensor(2.1881, grad_fn=<NllLossBackward0>)
tensor(2.3680, grad_fn=<NllLossBackward0>)
tensor(2.4152, grad_fn=<NllLossBackward0>)
tensor(2.6442, grad_fn=<NllLossBackward0>)
tensor(2.1815, grad_fn=<NllLossBackward0>)
tensor(2.2823, grad_fn=<NllLossBackward0>)
tensor(2.3672, grad_fn=<NllLossBackward0>)
tensor(2.2549, grad_fn=<NllLossBackward0>)
tensor(2.1737, grad_fn=<NllLossBackward0>)
tensor(2.4157, grad_fn=<NllLossBackward0>)
tensor(2.4267, grad_fn=<NllLossBackward0>)
tensor(2.2899, grad_fn=<NllLossBackward0>)
tensor(2.3182, grad_fn=<NllLossBackward0>)
tensor(2.2780, grad_fn=<NllLossBackward0>)
tensor(2.3482, grad_fn=<NllLossBackward0>)
tensor(2.4033, grad_fn=<NllLossBackward0>)
tensor(2.3078, grad_fn=<NllLossBackward0>)
tensor(2.2642, grad_fn=<NllLossBackward0>)
tensor(2.4896, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1488: 0.255
tensor(2.2844, grad_fn=<NllLossBackward0>)
tensor(2.3689, grad_fn=<NllLossBackward0>)
tensor(2.3232, grad_fn=<NllLossBackward0>)
tensor(2.4387, grad_fn=<NllLossBackward0>)
tensor(2.5006, grad_fn=<NllLossBackward0>)
tensor(2.3579, grad_fn=<NllLossBackward0>)
tensor(2.4111, grad_fn=<NllLossBackward0>)
tensor(2.4462, grad_fn=<NllLossBackward0>)
tensor(2.3210, grad_fn=<NllLossBackward0>)
tensor(2.2746, grad_fn=<NllLossBackward0>)
tensor(2.4067, grad_fn=<NllLossBackward0>)
tensor(2.2458, grad_fn=<NllLossBackward0>)
tensor(2.2073, grad_fn=<NllLossBackward0>)
tensor(2.3560, grad_fn=<NllLossBackward0>)
tensor(2.3810, grad_fn=<NllLossBackward0>)
tensor(2.3211, grad_fn=<NllLossBackward0>)
tensor(2.1725, grad_fn=<NllLossBackward0>)
tensor(2.2393, grad_fn=<NllLossBackward0>)
tensor(2.2277, grad_fn=<NllLossBackward0>)
tensor(2.2731, grad_fn=<NllLossBackward0>)
tensor(2.4089, grad_fn=<NllLossBackward0>)
tensor(2.3870, grad_fn=<NllLossBackward0>)
tensor(2.3994, grad_fn=<NllLossBackward0>)
tensor(2.3206, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1512: 0.250
tensor(2.3221, grad_fn=<NllLossBackward0>)
tensor(2.4280, grad_fn=<NllLossBackward0>)
tensor(2.3926, grad_fn=<NllLossBackward0>)
tensor(2.3903, grad_fn=<NllLossBackward0>)
tensor(2.4889, grad_fn=<NllLossBackward0>)
tensor(2.2288, grad_fn=<NllLossBackward0>)
tensor(2.2442, grad_fn=<NllLossBackward0>)
tensor(2.0308, grad_fn=<NllLossBackward0>)
tensor(2.2365, grad_fn=<NllLossBackward0>)
tensor(2.2403, grad_fn=<NllLossBackward0>)
tensor(2.3442, grad_fn=<NllLossBackward0>)
tensor(2.3246, grad_fn=<NllLossBackward0>)
tensor(2.2995, grad_fn=<NllLossBackward0>)
tensor(2.3015, grad_fn=<NllLossBackward0>)
tensor(2.4151, grad_fn=<NllLossBackward0>)
tensor(2.4087, grad_fn=<NllLossBackward0>)
tensor(2.4021, grad_fn=<NllLossBackward0>)
tensor(2.4765, grad_fn=<NllLossBackward0>)
tensor(2.1065, grad_fn=<NllLossBackward0>)
tensor(2.3130, grad_fn=<NllLossBackward0>)
tensor(2.3499, grad_fn=<NllLossBackward0>)
tensor(2.3245, grad_fn=<NllLossBackward0>)
tensor(2.2950, grad_fn=<NllLossBackward0>)
tensor(2.2411, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1536: 0.214
tensor(2.2348, grad_fn=<NllLossBackward0>)
tensor(2.3835, grad_fn=<NllLossBackward0>)
tensor(2.4397, grad_fn=<NllLossBackward0>)
tensor(2.4869, grad_fn=<NllLossBackward0>)
tensor(2.1784, grad_fn=<NllLossBackward0>)
tensor(2.3724, grad_fn=<NllLossBackward0>)
tensor(2.3837, grad_fn=<NllLossBackward0>)
tensor(2.3387, grad_fn=<NllLossBackward0>)
tensor(2.1546, grad_fn=<NllLossBackward0>)
tensor(2.3529, grad_fn=<NllLossBackward0>)
tensor(2.3002, grad_fn=<NllLossBackward0>)
tensor(2.2669, grad_fn=<NllLossBackward0>)
tensor(2.4474, grad_fn=<NllLossBackward0>)
tensor(2.3318, grad_fn=<NllLossBackward0>)
tensor(2.3916, grad_fn=<NllLossBackward0>)
tensor(2.3013, grad_fn=<NllLossBackward0>)
tensor(2.3351, grad_fn=<NllLossBackward0>)
tensor(2.4288, grad_fn=<NllLossBackward0>)
tensor(2.2484, grad_fn=<NllLossBackward0>)
tensor(2.2992, grad_fn=<NllLossBackward0>)
tensor(2.4348, grad_fn=<NllLossBackward0>)
tensor(2.1254, grad_fn=<NllLossBackward0>)
tensor(2.2413, grad_fn=<NllLossBackward0>)
tensor(2.3016, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1560: 0.233
tensor(2.3110, grad_fn=<NllLossBackward0>)
tensor(2.1652, grad_fn=<NllLossBackward0>)
tensor(2.3665, grad_fn=<NllLossBackward0>)
tensor(2.3477, grad_fn=<NllLossBackward0>)
tensor(2.3694, grad_fn=<NllLossBackward0>)
tensor(2.3481, grad_fn=<NllLossBackward0>)
tensor(2.3678, grad_fn=<NllLossBackward0>)
tensor(2.3414, grad_fn=<NllLossBackward0>)
tensor(2.2881, grad_fn=<NllLossBackward0>)
tensor(2.1483, grad_fn=<NllLossBackward0>)
tensor(2.3340, grad_fn=<NllLossBackward0>)
tensor(2.3729, grad_fn=<NllLossBackward0>)
tensor(2.3149, grad_fn=<NllLossBackward0>)
tensor(2.2485, grad_fn=<NllLossBackward0>)
tensor(2.3609, grad_fn=<NllLossBackward0>)
tensor(2.3772, grad_fn=<NllLossBackward0>)
tensor(2.3388, grad_fn=<NllLossBackward0>)
tensor(2.3360, grad_fn=<NllLossBackward0>)
tensor(2.2970, grad_fn=<NllLossBackward0>)
tensor(2.3087, grad_fn=<NllLossBackward0>)
tensor(2.4320, grad_fn=<NllLossBackward0>)
tensor(2.2518, grad_fn=<NllLossBackward0>)
tensor(2.3888, grad_fn=<NllLossBackward0>)
tensor(2.3620, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1584: 0.243
tensor(2.3756, grad_fn=<NllLossBackward0>)
tensor(2.4765, grad_fn=<NllLossBackward0>)
tensor(2.3141, grad_fn=<NllLossBackward0>)
tensor(2.3754, grad_fn=<NllLossBackward0>)
tensor(2.2551, grad_fn=<NllLossBackward0>)
tensor(2.2086, grad_fn=<NllLossBackward0>)
tensor(2.2248, grad_fn=<NllLossBackward0>)
tensor(2.3158, grad_fn=<NllLossBackward0>)
tensor(2.3056, grad_fn=<NllLossBackward0>)
tensor(2.1759, grad_fn=<NllLossBackward0>)
tensor(2.3379, grad_fn=<NllLossBackward0>)
tensor(2.3210, grad_fn=<NllLossBackward0>)
tensor(2.2939, grad_fn=<NllLossBackward0>)
tensor(2.3796, grad_fn=<NllLossBackward0>)
tensor(2.1625, grad_fn=<NllLossBackward0>)
tensor(2.4626, grad_fn=<NllLossBackward0>)
tensor(2.4267, grad_fn=<NllLossBackward0>)
tensor(2.2715, grad_fn=<NllLossBackward0>)
tensor(2.3361, grad_fn=<NllLossBackward0>)
tensor(2.3495, grad_fn=<NllLossBackward0>)
tensor(2.4055, grad_fn=<NllLossBackward0>)
tensor(2.2407, grad_fn=<NllLossBackward0>)
tensor(2.4580, grad_fn=<NllLossBackward0>)
tensor(2.3115, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1608: 0.259
tensor(2.3786, grad_fn=<NllLossBackward0>)
tensor(2.4276, grad_fn=<NllLossBackward0>)
tensor(2.2494, grad_fn=<NllLossBackward0>)
tensor(2.4557, grad_fn=<NllLossBackward0>)
tensor(2.2198, grad_fn=<NllLossBackward0>)
tensor(2.3915, grad_fn=<NllLossBackward0>)
tensor(2.3107, grad_fn=<NllLossBackward0>)
tensor(2.3661, grad_fn=<NllLossBackward0>)
tensor(2.2970, grad_fn=<NllLossBackward0>)
tensor(2.3610, grad_fn=<NllLossBackward0>)
tensor(2.2114, grad_fn=<NllLossBackward0>)
tensor(2.3650, grad_fn=<NllLossBackward0>)
tensor(2.3760, grad_fn=<NllLossBackward0>)
tensor(2.2678, grad_fn=<NllLossBackward0>)
tensor(2.3426, grad_fn=<NllLossBackward0>)
tensor(2.4427, grad_fn=<NllLossBackward0>)
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.3308, grad_fn=<NllLossBackward0>)
tensor(2.1531, grad_fn=<NllLossBackward0>)
tensor(2.4305, grad_fn=<NllLossBackward0>)
tensor(2.3712, grad_fn=<NllLossBackward0>)
tensor(2.3710, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.3019, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1632: 0.234
tensor(2.1697, grad_fn=<NllLossBackward0>)
tensor(2.1365, grad_fn=<NllLossBackward0>)
tensor(2.3456, grad_fn=<NllLossBackward0>)
tensor(2.3859, grad_fn=<NllLossBackward0>)
tensor(2.3095, grad_fn=<NllLossBackward0>)
tensor(2.3834, grad_fn=<NllLossBackward0>)
tensor(2.3145, grad_fn=<NllLossBackward0>)
tensor(2.3761, grad_fn=<NllLossBackward0>)
tensor(2.3451, grad_fn=<NllLossBackward0>)
tensor(2.2953, grad_fn=<NllLossBackward0>)
tensor(2.4135, grad_fn=<NllLossBackward0>)
tensor(2.4701, grad_fn=<NllLossBackward0>)
tensor(2.2669, grad_fn=<NllLossBackward0>)
tensor(2.4514, grad_fn=<NllLossBackward0>)
tensor(2.3373, grad_fn=<NllLossBackward0>)
tensor(2.3281, grad_fn=<NllLossBackward0>)
tensor(2.3411, grad_fn=<NllLossBackward0>)
tensor(2.3205, grad_fn=<NllLossBackward0>)
tensor(2.3022, grad_fn=<NllLossBackward0>)
tensor(2.1283, grad_fn=<NllLossBackward0>)
tensor(2.3166, grad_fn=<NllLossBackward0>)
tensor(2.1292, grad_fn=<NllLossBackward0>)
tensor(2.3782, grad_fn=<NllLossBackward0>)
tensor(2.3632, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1656: 0.231
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.3119, grad_fn=<NllLossBackward0>)
tensor(2.2190, grad_fn=<NllLossBackward0>)
tensor(2.3678, grad_fn=<NllLossBackward0>)
tensor(2.1901, grad_fn=<NllLossBackward0>)
tensor(2.3363, grad_fn=<NllLossBackward0>)
tensor(2.2061, grad_fn=<NllLossBackward0>)
tensor(2.3603, grad_fn=<NllLossBackward0>)
tensor(2.3182, grad_fn=<NllLossBackward0>)
tensor(2.4285, grad_fn=<NllLossBackward0>)
tensor(2.3255, grad_fn=<NllLossBackward0>)
tensor(2.4767, grad_fn=<NllLossBackward0>)
tensor(2.1758, grad_fn=<NllLossBackward0>)
tensor(2.3798, grad_fn=<NllLossBackward0>)
tensor(2.2008, grad_fn=<NllLossBackward0>)
tensor(2.2878, grad_fn=<NllLossBackward0>)
tensor(2.3138, grad_fn=<NllLossBackward0>)
tensor(2.4722, grad_fn=<NllLossBackward0>)
tensor(2.2893, grad_fn=<NllLossBackward0>)
tensor(2.1786, grad_fn=<NllLossBackward0>)
tensor(2.1982, grad_fn=<NllLossBackward0>)
tensor(2.2777, grad_fn=<NllLossBackward0>)
tensor(2.2017, grad_fn=<NllLossBackward0>)
tensor(2.4603, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1680: 0.243
tensor(2.3566, grad_fn=<NllLossBackward0>)
tensor(1.9775, grad_fn=<NllLossBackward0>)
tensor(2.2467, grad_fn=<NllLossBackward0>)
tensor(2.2915, grad_fn=<NllLossBackward0>)
tensor(2.1576, grad_fn=<NllLossBackward0>)
tensor(2.3642, grad_fn=<NllLossBackward0>)
tensor(2.2588, grad_fn=<NllLossBackward0>)
tensor(2.3497, grad_fn=<NllLossBackward0>)
tensor(2.2745, grad_fn=<NllLossBackward0>)
tensor(2.2981, grad_fn=<NllLossBackward0>)
tensor(2.4129, grad_fn=<NllLossBackward0>)
tensor(2.2751, grad_fn=<NllLossBackward0>)
tensor(2.3994, grad_fn=<NllLossBackward0>)
tensor(2.2421, grad_fn=<NllLossBackward0>)
tensor(2.4888, grad_fn=<NllLossBackward0>)
tensor(2.2790, grad_fn=<NllLossBackward0>)
tensor(2.1649, grad_fn=<NllLossBackward0>)
tensor(2.3946, grad_fn=<NllLossBackward0>)
tensor(2.2707, grad_fn=<NllLossBackward0>)
tensor(2.3973, grad_fn=<NllLossBackward0>)
tensor(2.3398, grad_fn=<NllLossBackward0>)
tensor(2.3366, grad_fn=<NllLossBackward0>)
tensor(2.3998, grad_fn=<NllLossBackward0>)
tensor(2.3189, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1704: 0.247
tensor(2.1312, grad_fn=<NllLossBackward0>)
tensor(2.3744, grad_fn=<NllLossBackward0>)
tensor(2.2594, grad_fn=<NllLossBackward0>)
tensor(2.4249, grad_fn=<NllLossBackward0>)
tensor(2.2956, grad_fn=<NllLossBackward0>)
tensor(2.1177, grad_fn=<NllLossBackward0>)
tensor(2.2640, grad_fn=<NllLossBackward0>)
tensor(2.3530, grad_fn=<NllLossBackward0>)
tensor(2.3097, grad_fn=<NllLossBackward0>)
tensor(2.3256, grad_fn=<NllLossBackward0>)
tensor(2.2372, grad_fn=<NllLossBackward0>)
tensor(2.4836, grad_fn=<NllLossBackward0>)
tensor(2.2979, grad_fn=<NllLossBackward0>)
tensor(2.3810, grad_fn=<NllLossBackward0>)
tensor(2.2941, grad_fn=<NllLossBackward0>)
tensor(2.3977, grad_fn=<NllLossBackward0>)
tensor(2.4412, grad_fn=<NllLossBackward0>)
tensor(2.1633, grad_fn=<NllLossBackward0>)
tensor(2.1354, grad_fn=<NllLossBackward0>)
tensor(2.4561, grad_fn=<NllLossBackward0>)
tensor(2.2455, grad_fn=<NllLossBackward0>)
tensor(2.2088, grad_fn=<NllLossBackward0>)
tensor(2.1946, grad_fn=<NllLossBackward0>)
tensor(2.3325, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1728: 0.245
tensor(2.3467, grad_fn=<NllLossBackward0>)
tensor(2.2483, grad_fn=<NllLossBackward0>)
tensor(2.4265, grad_fn=<NllLossBackward0>)
tensor(2.3490, grad_fn=<NllLossBackward0>)
tensor(2.1820, grad_fn=<NllLossBackward0>)
tensor(2.1484, grad_fn=<NllLossBackward0>)
tensor(2.4234, grad_fn=<NllLossBackward0>)
tensor(2.0793, grad_fn=<NllLossBackward0>)
tensor(2.2733, grad_fn=<NllLossBackward0>)
tensor(2.3253, grad_fn=<NllLossBackward0>)
tensor(2.3746, grad_fn=<NllLossBackward0>)
tensor(2.3273, grad_fn=<NllLossBackward0>)
tensor(2.2067, grad_fn=<NllLossBackward0>)
tensor(2.3181, grad_fn=<NllLossBackward0>)
tensor(2.3687, grad_fn=<NllLossBackward0>)
tensor(2.2864, grad_fn=<NllLossBackward0>)
tensor(2.2038, grad_fn=<NllLossBackward0>)
tensor(2.3095, grad_fn=<NllLossBackward0>)
tensor(2.2427, grad_fn=<NllLossBackward0>)
tensor(2.3684, grad_fn=<NllLossBackward0>)
tensor(2.3574, grad_fn=<NllLossBackward0>)
tensor(2.4058, grad_fn=<NllLossBackward0>)
tensor(2.3322, grad_fn=<NllLossBackward0>)
tensor(2.3105, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1752: 0.248
tensor(2.3380, grad_fn=<NllLossBackward0>)
tensor(2.3105, grad_fn=<NllLossBackward0>)
tensor(2.3036, grad_fn=<NllLossBackward0>)
tensor(2.2887, grad_fn=<NllLossBackward0>)
tensor(2.3226, grad_fn=<NllLossBackward0>)
tensor(2.3303, grad_fn=<NllLossBackward0>)
tensor(2.3701, grad_fn=<NllLossBackward0>)
tensor(2.2915, grad_fn=<NllLossBackward0>)
tensor(2.2785, grad_fn=<NllLossBackward0>)
tensor(2.3959, grad_fn=<NllLossBackward0>)
tensor(2.2676, grad_fn=<NllLossBackward0>)
tensor(2.3492, grad_fn=<NllLossBackward0>)
tensor(2.3290, grad_fn=<NllLossBackward0>)
tensor(2.3452, grad_fn=<NllLossBackward0>)
tensor(2.3396, grad_fn=<NllLossBackward0>)
tensor(2.2537, grad_fn=<NllLossBackward0>)
tensor(2.3777, grad_fn=<NllLossBackward0>)
tensor(2.3508, grad_fn=<NllLossBackward0>)
tensor(2.3663, grad_fn=<NllLossBackward0>)
tensor(2.2805, grad_fn=<NllLossBackward0>)
tensor(2.3488, grad_fn=<NllLossBackward0>)
tensor(2.2883, grad_fn=<NllLossBackward0>)
tensor(2.4793, grad_fn=<NllLossBackward0>)
tensor(2.3228, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1776: 0.226
tensor(2.3228, grad_fn=<NllLossBackward0>)
tensor(2.2455, grad_fn=<NllLossBackward0>)
tensor(2.2308, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(2.2064, grad_fn=<NllLossBackward0>)
tensor(2.2732, grad_fn=<NllLossBackward0>)
tensor(2.0918, grad_fn=<NllLossBackward0>)
tensor(2.3319, grad_fn=<NllLossBackward0>)
tensor(2.2504, grad_fn=<NllLossBackward0>)
tensor(2.4778, grad_fn=<NllLossBackward0>)
tensor(2.2133, grad_fn=<NllLossBackward0>)
tensor(2.2785, grad_fn=<NllLossBackward0>)
tensor(2.2263, grad_fn=<NllLossBackward0>)
tensor(2.2316, grad_fn=<NllLossBackward0>)
tensor(2.2596, grad_fn=<NllLossBackward0>)
tensor(2.2530, grad_fn=<NllLossBackward0>)
tensor(2.2998, grad_fn=<NllLossBackward0>)
tensor(2.3761, grad_fn=<NllLossBackward0>)
tensor(2.2164, grad_fn=<NllLossBackward0>)
tensor(2.1266, grad_fn=<NllLossBackward0>)
tensor(2.3863, grad_fn=<NllLossBackward0>)
tensor(2.4400, grad_fn=<NllLossBackward0>)
tensor(2.2126, grad_fn=<NllLossBackward0>)
tensor(2.3813, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1800: 0.266
tensor(2.3460, grad_fn=<NllLossBackward0>)
tensor(2.2523, grad_fn=<NllLossBackward0>)
tensor(2.2176, grad_fn=<NllLossBackward0>)
tensor(2.3635, grad_fn=<NllLossBackward0>)
tensor(2.4730, grad_fn=<NllLossBackward0>)
tensor(2.3507, grad_fn=<NllLossBackward0>)
tensor(2.2424, grad_fn=<NllLossBackward0>)
tensor(2.2957, grad_fn=<NllLossBackward0>)
tensor(2.3624, grad_fn=<NllLossBackward0>)
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.3825, grad_fn=<NllLossBackward0>)
tensor(2.2359, grad_fn=<NllLossBackward0>)
tensor(2.4279, grad_fn=<NllLossBackward0>)
tensor(2.3870, grad_fn=<NllLossBackward0>)
tensor(2.3921, grad_fn=<NllLossBackward0>)
tensor(2.2412, grad_fn=<NllLossBackward0>)
tensor(2.3710, grad_fn=<NllLossBackward0>)
tensor(2.3547, grad_fn=<NllLossBackward0>)
tensor(2.3194, grad_fn=<NllLossBackward0>)
tensor(2.3165, grad_fn=<NllLossBackward0>)
tensor(2.2502, grad_fn=<NllLossBackward0>)
tensor(2.2665, grad_fn=<NllLossBackward0>)
tensor(2.2114, grad_fn=<NllLossBackward0>)
tensor(2.2086, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1824: 0.226
tensor(2.2942, grad_fn=<NllLossBackward0>)
tensor(2.2863, grad_fn=<NllLossBackward0>)
tensor(2.3634, grad_fn=<NllLossBackward0>)
tensor(2.2195, grad_fn=<NllLossBackward0>)
tensor(2.2021, grad_fn=<NllLossBackward0>)
tensor(2.2009, grad_fn=<NllLossBackward0>)
tensor(2.2933, grad_fn=<NllLossBackward0>)
tensor(2.3294, grad_fn=<NllLossBackward0>)
tensor(2.1189, grad_fn=<NllLossBackward0>)
tensor(2.1417, grad_fn=<NllLossBackward0>)
tensor(2.2554, grad_fn=<NllLossBackward0>)
tensor(2.2800, grad_fn=<NllLossBackward0>)
tensor(2.4319, grad_fn=<NllLossBackward0>)
tensor(2.2960, grad_fn=<NllLossBackward0>)
tensor(2.2977, grad_fn=<NllLossBackward0>)
tensor(2.3181, grad_fn=<NllLossBackward0>)
tensor(2.3677, grad_fn=<NllLossBackward0>)
tensor(2.3344, grad_fn=<NllLossBackward0>)
tensor(2.2227, grad_fn=<NllLossBackward0>)
tensor(2.4660, grad_fn=<NllLossBackward0>)
tensor(2.4238, grad_fn=<NllLossBackward0>)
tensor(2.3672, grad_fn=<NllLossBackward0>)
tensor(2.3064, grad_fn=<NllLossBackward0>)
tensor(2.3014, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1848: 0.233
tensor(2.1649, grad_fn=<NllLossBackward0>)
tensor(2.2459, grad_fn=<NllLossBackward0>)
tensor(2.3739, grad_fn=<NllLossBackward0>)
tensor(2.2835, grad_fn=<NllLossBackward0>)
tensor(2.2120, grad_fn=<NllLossBackward0>)
tensor(2.3718, grad_fn=<NllLossBackward0>)
tensor(2.0877, grad_fn=<NllLossBackward0>)
tensor(2.1886, grad_fn=<NllLossBackward0>)
tensor(2.0773, grad_fn=<NllLossBackward0>)
tensor(2.2894, grad_fn=<NllLossBackward0>)
tensor(2.1861, grad_fn=<NllLossBackward0>)
tensor(2.3468, grad_fn=<NllLossBackward0>)
tensor(2.3506, grad_fn=<NllLossBackward0>)
tensor(2.3582, grad_fn=<NllLossBackward0>)
tensor(2.3837, grad_fn=<NllLossBackward0>)
tensor(2.3578, grad_fn=<NllLossBackward0>)
tensor(2.1914, grad_fn=<NllLossBackward0>)
tensor(2.2609, grad_fn=<NllLossBackward0>)
tensor(2.1434, grad_fn=<NllLossBackward0>)
tensor(2.2073, grad_fn=<NllLossBackward0>)
tensor(2.1205, grad_fn=<NllLossBackward0>)
tensor(2.2845, grad_fn=<NllLossBackward0>)
tensor(2.2683, grad_fn=<NllLossBackward0>)
tensor(2.1912, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1872: 0.240
tensor(2.2520, grad_fn=<NllLossBackward0>)
tensor(2.2576, grad_fn=<NllLossBackward0>)
tensor(2.3030, grad_fn=<NllLossBackward0>)
tensor(2.3323, grad_fn=<NllLossBackward0>)
tensor(2.2180, grad_fn=<NllLossBackward0>)
tensor(2.3266, grad_fn=<NllLossBackward0>)
tensor(2.4153, grad_fn=<NllLossBackward0>)
tensor(2.5010, grad_fn=<NllLossBackward0>)
tensor(2.2719, grad_fn=<NllLossBackward0>)
tensor(2.4127, grad_fn=<NllLossBackward0>)
tensor(2.0985, grad_fn=<NllLossBackward0>)
tensor(2.3120, grad_fn=<NllLossBackward0>)
tensor(2.3903, grad_fn=<NllLossBackward0>)
tensor(2.4801, grad_fn=<NllLossBackward0>)
tensor(2.2985, grad_fn=<NllLossBackward0>)
tensor(2.4475, grad_fn=<NllLossBackward0>)
tensor(2.2438, grad_fn=<NllLossBackward0>)
tensor(2.3984, grad_fn=<NllLossBackward0>)
tensor(2.2809, grad_fn=<NllLossBackward0>)
tensor(2.2907, grad_fn=<NllLossBackward0>)
tensor(2.1605, grad_fn=<NllLossBackward0>)
tensor(2.2275, grad_fn=<NllLossBackward0>)
tensor(2.2701, grad_fn=<NllLossBackward0>)
tensor(2.4549, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1896: 0.214
tensor(2.3092, grad_fn=<NllLossBackward0>)
tensor(2.3596, grad_fn=<NllLossBackward0>)
tensor(2.4442, grad_fn=<NllLossBackward0>)
tensor(2.2698, grad_fn=<NllLossBackward0>)
tensor(2.4113, grad_fn=<NllLossBackward0>)
tensor(2.1893, grad_fn=<NllLossBackward0>)
tensor(2.3301, grad_fn=<NllLossBackward0>)
tensor(2.2957, grad_fn=<NllLossBackward0>)
tensor(2.2469, grad_fn=<NllLossBackward0>)
tensor(2.2196, grad_fn=<NllLossBackward0>)
tensor(2.3418, grad_fn=<NllLossBackward0>)
tensor(2.2504, grad_fn=<NllLossBackward0>)
tensor(2.1140, grad_fn=<NllLossBackward0>)
tensor(2.3063, grad_fn=<NllLossBackward0>)
tensor(2.2203, grad_fn=<NllLossBackward0>)
tensor(2.3383, grad_fn=<NllLossBackward0>)
tensor(2.3522, grad_fn=<NllLossBackward0>)
tensor(2.2973, grad_fn=<NllLossBackward0>)
tensor(2.1661, grad_fn=<NllLossBackward0>)
tensor(2.3176, grad_fn=<NllLossBackward0>)
tensor(2.1758, grad_fn=<NllLossBackward0>)
tensor(2.2292, grad_fn=<NllLossBackward0>)
tensor(2.3840, grad_fn=<NllLossBackward0>)
tensor(2.3032, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1920: 0.252
tensor(2.4289, grad_fn=<NllLossBackward0>)
tensor(2.3727, grad_fn=<NllLossBackward0>)
tensor(2.2607, grad_fn=<NllLossBackward0>)
tensor(2.4057, grad_fn=<NllLossBackward0>)
tensor(2.3427, grad_fn=<NllLossBackward0>)
tensor(2.2951, grad_fn=<NllLossBackward0>)
tensor(2.4015, grad_fn=<NllLossBackward0>)
tensor(2.2744, grad_fn=<NllLossBackward0>)
tensor(2.3756, grad_fn=<NllLossBackward0>)
tensor(2.4356, grad_fn=<NllLossBackward0>)
tensor(2.1008, grad_fn=<NllLossBackward0>)
tensor(2.3002, grad_fn=<NllLossBackward0>)
tensor(2.3052, grad_fn=<NllLossBackward0>)
tensor(2.3682, grad_fn=<NllLossBackward0>)
tensor(2.1289, grad_fn=<NllLossBackward0>)
tensor(2.3636, grad_fn=<NllLossBackward0>)
tensor(2.3827, grad_fn=<NllLossBackward0>)
tensor(2.2592, grad_fn=<NllLossBackward0>)
tensor(2.4331, grad_fn=<NllLossBackward0>)
tensor(2.3307, grad_fn=<NllLossBackward0>)
tensor(2.4173, grad_fn=<NllLossBackward0>)
tensor(2.1754, grad_fn=<NllLossBackward0>)
tensor(2.5101, grad_fn=<NllLossBackward0>)
tensor(2.3989, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1944: 0.210
tensor(2.4271, grad_fn=<NllLossBackward0>)
tensor(2.3094, grad_fn=<NllLossBackward0>)
tensor(2.2692, grad_fn=<NllLossBackward0>)
tensor(2.3149, grad_fn=<NllLossBackward0>)
tensor(2.1359, grad_fn=<NllLossBackward0>)
tensor(2.3950, grad_fn=<NllLossBackward0>)
tensor(2.4233, grad_fn=<NllLossBackward0>)
tensor(2.2447, grad_fn=<NllLossBackward0>)
tensor(2.2216, grad_fn=<NllLossBackward0>)
tensor(2.2209, grad_fn=<NllLossBackward0>)
tensor(2.2529, grad_fn=<NllLossBackward0>)
tensor(2.3768, grad_fn=<NllLossBackward0>)
tensor(2.2464, grad_fn=<NllLossBackward0>)
tensor(2.2067, grad_fn=<NllLossBackward0>)
tensor(2.2935, grad_fn=<NllLossBackward0>)
tensor(2.3576, grad_fn=<NllLossBackward0>)
tensor(2.4257, grad_fn=<NllLossBackward0>)
tensor(2.3179, grad_fn=<NllLossBackward0>)
tensor(2.4416, grad_fn=<NllLossBackward0>)
tensor(2.2680, grad_fn=<NllLossBackward0>)
tensor(2.2683, grad_fn=<NllLossBackward0>)
tensor(2.2067, grad_fn=<NllLossBackward0>)
tensor(2.3027, grad_fn=<NllLossBackward0>)
tensor(2.4069, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1968: 0.217
tensor(2.4298, grad_fn=<NllLossBackward0>)
tensor(2.3839, grad_fn=<NllLossBackward0>)
tensor(2.3180, grad_fn=<NllLossBackward0>)
tensor(2.0762, grad_fn=<NllLossBackward0>)
tensor(2.1838, grad_fn=<NllLossBackward0>)
tensor(2.2477, grad_fn=<NllLossBackward0>)
tensor(2.2406, grad_fn=<NllLossBackward0>)
tensor(2.1440, grad_fn=<NllLossBackward0>)
tensor(2.2720, grad_fn=<NllLossBackward0>)
tensor(2.3263, grad_fn=<NllLossBackward0>)
tensor(2.3503, grad_fn=<NllLossBackward0>)
tensor(2.3379, grad_fn=<NllLossBackward0>)
tensor(2.2984, grad_fn=<NllLossBackward0>)
tensor(2.2849, grad_fn=<NllLossBackward0>)
tensor(2.3702, grad_fn=<NllLossBackward0>)
tensor(2.1168, grad_fn=<NllLossBackward0>)
tensor(2.3498, grad_fn=<NllLossBackward0>)
tensor(2.2286, grad_fn=<NllLossBackward0>)
tensor(2.4102, grad_fn=<NllLossBackward0>)
tensor(2.3471, grad_fn=<NllLossBackward0>)
tensor(2.2860, grad_fn=<NllLossBackward0>)
tensor(2.2685, grad_fn=<NllLossBackward0>)
tensor(2.1368, grad_fn=<NllLossBackward0>)
tensor(2.2581, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1992: 0.280
tensor(2.3056, grad_fn=<NllLossBackward0>)
tensor(2.2944, grad_fn=<NllLossBackward0>)
tensor(2.2564, grad_fn=<NllLossBackward0>)
tensor(2.4011, grad_fn=<NllLossBackward0>)
tensor(2.2247, grad_fn=<NllLossBackward0>)
tensor(2.2466, grad_fn=<NllLossBackward0>)
tensor(2.2063, grad_fn=<NllLossBackward0>)
tensor(2.4407, grad_fn=<NllLossBackward0>)
tensor(2.1828, grad_fn=<NllLossBackward0>)
tensor(2.3647, grad_fn=<NllLossBackward0>)
tensor(2.2736, grad_fn=<NllLossBackward0>)
tensor(2.3205, grad_fn=<NllLossBackward0>)
tensor(2.2519, grad_fn=<NllLossBackward0>)
tensor(2.2841, grad_fn=<NllLossBackward0>)
tensor(2.2133, grad_fn=<NllLossBackward0>)
tensor(2.3689, grad_fn=<NllLossBackward0>)
tensor(2.4982, grad_fn=<NllLossBackward0>)
tensor(2.1908, grad_fn=<NllLossBackward0>)
tensor(2.2162, grad_fn=<NllLossBackward0>)
tensor(2.2596, grad_fn=<NllLossBackward0>)
tensor(2.4021, grad_fn=<NllLossBackward0>)
tensor(2.2763, grad_fn=<NllLossBackward0>)
tensor(2.2828, grad_fn=<NllLossBackward0>)
tensor(2.1864, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2016: 0.241
tensor(2.3909, grad_fn=<NllLossBackward0>)
tensor(2.2581, grad_fn=<NllLossBackward0>)
tensor(2.4363, grad_fn=<NllLossBackward0>)
tensor(2.2812, grad_fn=<NllLossBackward0>)
tensor(2.1786, grad_fn=<NllLossBackward0>)
tensor(2.2999, grad_fn=<NllLossBackward0>)
tensor(2.1514, grad_fn=<NllLossBackward0>)
tensor(2.4397, grad_fn=<NllLossBackward0>)
tensor(2.4147, grad_fn=<NllLossBackward0>)
tensor(2.2935, grad_fn=<NllLossBackward0>)
tensor(2.1683, grad_fn=<NllLossBackward0>)
tensor(2.3901, grad_fn=<NllLossBackward0>)
tensor(2.3643, grad_fn=<NllLossBackward0>)
tensor(2.4670, grad_fn=<NllLossBackward0>)
tensor(2.2856, grad_fn=<NllLossBackward0>)
tensor(2.3245, grad_fn=<NllLossBackward0>)
tensor(2.2681, grad_fn=<NllLossBackward0>)
tensor(2.1665, grad_fn=<NllLossBackward0>)
tensor(2.3984, grad_fn=<NllLossBackward0>)
tensor(2.3936, grad_fn=<NllLossBackward0>)
tensor(2.2916, grad_fn=<NllLossBackward0>)
tensor(2.2503, grad_fn=<NllLossBackward0>)
tensor(2.4076, grad_fn=<NllLossBackward0>)
tensor(2.3020, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2040: 0.220
tensor(2.3400, grad_fn=<NllLossBackward0>)
tensor(2.0994, grad_fn=<NllLossBackward0>)
tensor(2.3312, grad_fn=<NllLossBackward0>)
tensor(2.4197, grad_fn=<NllLossBackward0>)
tensor(2.2544, grad_fn=<NllLossBackward0>)
tensor(2.2268, grad_fn=<NllLossBackward0>)
tensor(2.4961, grad_fn=<NllLossBackward0>)
tensor(2.3254, grad_fn=<NllLossBackward0>)
tensor(2.2061, grad_fn=<NllLossBackward0>)
tensor(2.3690, grad_fn=<NllLossBackward0>)
tensor(2.4277, grad_fn=<NllLossBackward0>)
tensor(2.2855, grad_fn=<NllLossBackward0>)
tensor(2.4155, grad_fn=<NllLossBackward0>)
tensor(2.2564, grad_fn=<NllLossBackward0>)
tensor(2.3906, grad_fn=<NllLossBackward0>)
tensor(2.3285, grad_fn=<NllLossBackward0>)
tensor(2.1682, grad_fn=<NllLossBackward0>)
tensor(2.2103, grad_fn=<NllLossBackward0>)
tensor(2.2230, grad_fn=<NllLossBackward0>)
tensor(2.2198, grad_fn=<NllLossBackward0>)
tensor(2.2163, grad_fn=<NllLossBackward0>)
tensor(2.3623, grad_fn=<NllLossBackward0>)
tensor(2.1652, grad_fn=<NllLossBackward0>)
tensor(2.1781, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2064: 0.226
tensor(2.0816, grad_fn=<NllLossBackward0>)
tensor(2.1701, grad_fn=<NllLossBackward0>)
tensor(2.3730, grad_fn=<NllLossBackward0>)
tensor(2.4210, grad_fn=<NllLossBackward0>)
tensor(2.2803, grad_fn=<NllLossBackward0>)
tensor(2.2812, grad_fn=<NllLossBackward0>)
tensor(2.1866, grad_fn=<NllLossBackward0>)
tensor(2.3131, grad_fn=<NllLossBackward0>)
tensor(2.1918, grad_fn=<NllLossBackward0>)
tensor(2.2981, grad_fn=<NllLossBackward0>)
tensor(2.1310, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
tensor(2.1595, grad_fn=<NllLossBackward0>)
tensor(2.3507, grad_fn=<NllLossBackward0>)
tensor(2.1639, grad_fn=<NllLossBackward0>)
tensor(2.3092, grad_fn=<NllLossBackward0>)
tensor(2.5697, grad_fn=<NllLossBackward0>)
tensor(2.4566, grad_fn=<NllLossBackward0>)
tensor(2.2254, grad_fn=<NllLossBackward0>)
tensor(2.2864, grad_fn=<NllLossBackward0>)
tensor(2.2150, grad_fn=<NllLossBackward0>)
tensor(2.0934, grad_fn=<NllLossBackward0>)
tensor(2.2501, grad_fn=<NllLossBackward0>)
tensor(2.3197, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2088: 0.260
tensor(2.1642, grad_fn=<NllLossBackward0>)
tensor(2.2975, grad_fn=<NllLossBackward0>)
tensor(2.2745, grad_fn=<NllLossBackward0>)
tensor(2.1585, grad_fn=<NllLossBackward0>)
tensor(2.1609, grad_fn=<NllLossBackward0>)
tensor(2.2894, grad_fn=<NllLossBackward0>)
tensor(2.3189, grad_fn=<NllLossBackward0>)
tensor(2.2798, grad_fn=<NllLossBackward0>)
tensor(2.3717, grad_fn=<NllLossBackward0>)
tensor(2.2853, grad_fn=<NllLossBackward0>)
tensor(2.2544, grad_fn=<NllLossBackward0>)
tensor(2.3388, grad_fn=<NllLossBackward0>)
tensor(2.2847, grad_fn=<NllLossBackward0>)
tensor(2.3704, grad_fn=<NllLossBackward0>)
tensor(2.2045, grad_fn=<NllLossBackward0>)
tensor(2.3954, grad_fn=<NllLossBackward0>)
tensor(2.3573, grad_fn=<NllLossBackward0>)
tensor(2.2949, grad_fn=<NllLossBackward0>)
tensor(2.1864, grad_fn=<NllLossBackward0>)
tensor(2.2854, grad_fn=<NllLossBackward0>)
tensor(2.3273, grad_fn=<NllLossBackward0>)
tensor(2.3532, grad_fn=<NllLossBackward0>)
tensor(2.1121, grad_fn=<NllLossBackward0>)
tensor(2.2491, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2112: 0.245
tensor(2.2745, grad_fn=<NllLossBackward0>)
tensor(2.2211, grad_fn=<NllLossBackward0>)
tensor(2.5328, grad_fn=<NllLossBackward0>)
tensor(2.3494, grad_fn=<NllLossBackward0>)
tensor(2.3926, grad_fn=<NllLossBackward0>)
tensor(2.3876, grad_fn=<NllLossBackward0>)
tensor(2.1898, grad_fn=<NllLossBackward0>)
tensor(2.2505, grad_fn=<NllLossBackward0>)
tensor(2.3893, grad_fn=<NllLossBackward0>)
tensor(2.4969, grad_fn=<NllLossBackward0>)
tensor(2.3992, grad_fn=<NllLossBackward0>)
tensor(2.2106, grad_fn=<NllLossBackward0>)
tensor(2.3324, grad_fn=<NllLossBackward0>)
tensor(2.5334, grad_fn=<NllLossBackward0>)
tensor(2.3561, grad_fn=<NllLossBackward0>)
tensor(2.1718, grad_fn=<NllLossBackward0>)
tensor(2.3560, grad_fn=<NllLossBackward0>)
tensor(2.3750, grad_fn=<NllLossBackward0>)
tensor(2.1266, grad_fn=<NllLossBackward0>)
tensor(2.3451, grad_fn=<NllLossBackward0>)
tensor(2.4286, grad_fn=<NllLossBackward0>)
tensor(2.3033, grad_fn=<NllLossBackward0>)
tensor(2.0783, grad_fn=<NllLossBackward0>)
tensor(2.2103, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2136: 0.253
tensor(2.4386, grad_fn=<NllLossBackward0>)
tensor(2.2614, grad_fn=<NllLossBackward0>)
tensor(2.1405, grad_fn=<NllLossBackward0>)
tensor(2.1396, grad_fn=<NllLossBackward0>)
tensor(2.2026, grad_fn=<NllLossBackward0>)
tensor(2.2947, grad_fn=<NllLossBackward0>)
tensor(2.3026, grad_fn=<NllLossBackward0>)
tensor(2.3498, grad_fn=<NllLossBackward0>)
tensor(2.3205, grad_fn=<NllLossBackward0>)
tensor(2.3129, grad_fn=<NllLossBackward0>)
tensor(2.2061, grad_fn=<NllLossBackward0>)
tensor(2.2548, grad_fn=<NllLossBackward0>)
tensor(2.1721, grad_fn=<NllLossBackward0>)
tensor(2.0604, grad_fn=<NllLossBackward0>)
tensor(2.1364, grad_fn=<NllLossBackward0>)
tensor(2.2321, grad_fn=<NllLossBackward0>)
tensor(2.2372, grad_fn=<NllLossBackward0>)
tensor(2.3047, grad_fn=<NllLossBackward0>)
tensor(2.3723, grad_fn=<NllLossBackward0>)
tensor(2.1446, grad_fn=<NllLossBackward0>)
tensor(2.2134, grad_fn=<NllLossBackward0>)
tensor(2.3259, grad_fn=<NllLossBackward0>)
tensor(2.3103, grad_fn=<NllLossBackward0>)
tensor(2.1605, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2160: 0.257
tensor(2.2537, grad_fn=<NllLossBackward0>)
tensor(2.1869, grad_fn=<NllLossBackward0>)
tensor(2.1973, grad_fn=<NllLossBackward0>)
tensor(2.2171, grad_fn=<NllLossBackward0>)
tensor(2.3142, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.2143, grad_fn=<NllLossBackward0>)
tensor(2.2227, grad_fn=<NllLossBackward0>)
tensor(2.1011, grad_fn=<NllLossBackward0>)
tensor(2.3238, grad_fn=<NllLossBackward0>)
tensor(2.5043, grad_fn=<NllLossBackward0>)
tensor(2.1856, grad_fn=<NllLossBackward0>)
tensor(2.2654, grad_fn=<NllLossBackward0>)
tensor(2.2871, grad_fn=<NllLossBackward0>)
tensor(2.2859, grad_fn=<NllLossBackward0>)
tensor(2.3003, grad_fn=<NllLossBackward0>)
tensor(2.1995, grad_fn=<NllLossBackward0>)
tensor(2.3103, grad_fn=<NllLossBackward0>)
tensor(2.1463, grad_fn=<NllLossBackward0>)
tensor(2.2442, grad_fn=<NllLossBackward0>)
tensor(2.3105, grad_fn=<NllLossBackward0>)
tensor(2.3297, grad_fn=<NllLossBackward0>)
tensor(2.3700, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2184: 0.226
tensor(2.2481, grad_fn=<NllLossBackward0>)
tensor(2.2770, grad_fn=<NllLossBackward0>)
tensor(2.3238, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.2961, grad_fn=<NllLossBackward0>)
tensor(2.2420, grad_fn=<NllLossBackward0>)
tensor(2.1387, grad_fn=<NllLossBackward0>)
tensor(2.2401, grad_fn=<NllLossBackward0>)
tensor(2.3554, grad_fn=<NllLossBackward0>)
tensor(2.0593, grad_fn=<NllLossBackward0>)
tensor(2.4061, grad_fn=<NllLossBackward0>)
tensor(2.2570, grad_fn=<NllLossBackward0>)
tensor(2.1848, grad_fn=<NllLossBackward0>)
tensor(2.2335, grad_fn=<NllLossBackward0>)
tensor(2.2809, grad_fn=<NllLossBackward0>)
tensor(2.2131, grad_fn=<NllLossBackward0>)
tensor(2.1819, grad_fn=<NllLossBackward0>)
tensor(2.3324, grad_fn=<NllLossBackward0>)
tensor(2.1433, grad_fn=<NllLossBackward0>)
tensor(2.1474, grad_fn=<NllLossBackward0>)
tensor(2.3111, grad_fn=<NllLossBackward0>)
tensor(2.3769, grad_fn=<NllLossBackward0>)
tensor(2.1063, grad_fn=<NllLossBackward0>)
tensor(2.3111, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2208: 0.255
tensor(2.1951, grad_fn=<NllLossBackward0>)
tensor(2.2588, grad_fn=<NllLossBackward0>)
tensor(2.1776, grad_fn=<NllLossBackward0>)
tensor(2.2358, grad_fn=<NllLossBackward0>)
tensor(2.3793, grad_fn=<NllLossBackward0>)
tensor(2.2901, grad_fn=<NllLossBackward0>)
tensor(2.2401, grad_fn=<NllLossBackward0>)
tensor(2.2566, grad_fn=<NllLossBackward0>)
tensor(2.3851, grad_fn=<NllLossBackward0>)
tensor(2.3033, grad_fn=<NllLossBackward0>)
tensor(2.3451, grad_fn=<NllLossBackward0>)
tensor(2.3487, grad_fn=<NllLossBackward0>)
tensor(2.2070, grad_fn=<NllLossBackward0>)
tensor(2.2684, grad_fn=<NllLossBackward0>)
tensor(2.2870, grad_fn=<NllLossBackward0>)
tensor(2.3693, grad_fn=<NllLossBackward0>)
tensor(2.3746, grad_fn=<NllLossBackward0>)
tensor(2.1370, grad_fn=<NllLossBackward0>)
tensor(2.3082, grad_fn=<NllLossBackward0>)
tensor(2.1780, grad_fn=<NllLossBackward0>)
tensor(2.2438, grad_fn=<NllLossBackward0>)
tensor(2.2712, grad_fn=<NllLossBackward0>)
tensor(2.1614, grad_fn=<NllLossBackward0>)
tensor(2.2641, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2232: 0.247
tensor(2.2587, grad_fn=<NllLossBackward0>)
tensor(2.2900, grad_fn=<NllLossBackward0>)
tensor(2.4600, grad_fn=<NllLossBackward0>)
tensor(2.1422, grad_fn=<NllLossBackward0>)
tensor(2.1491, grad_fn=<NllLossBackward0>)
tensor(2.5588, grad_fn=<NllLossBackward0>)
tensor(2.3824, grad_fn=<NllLossBackward0>)
tensor(2.2393, grad_fn=<NllLossBackward0>)
tensor(2.2277, grad_fn=<NllLossBackward0>)
tensor(2.1119, grad_fn=<NllLossBackward0>)
tensor(2.2852, grad_fn=<NllLossBackward0>)
tensor(2.0375, grad_fn=<NllLossBackward0>)
tensor(2.2220, grad_fn=<NllLossBackward0>)
tensor(2.2676, grad_fn=<NllLossBackward0>)
tensor(2.4119, grad_fn=<NllLossBackward0>)
tensor(2.4319, grad_fn=<NllLossBackward0>)
tensor(2.1663, grad_fn=<NllLossBackward0>)
tensor(2.2934, grad_fn=<NllLossBackward0>)
tensor(2.4003, grad_fn=<NllLossBackward0>)
tensor(2.3290, grad_fn=<NllLossBackward0>)
tensor(2.4316, grad_fn=<NllLossBackward0>)
tensor(2.2114, grad_fn=<NllLossBackward0>)
tensor(2.2045, grad_fn=<NllLossBackward0>)
tensor(2.0745, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2256: 0.252
tensor(2.3448, grad_fn=<NllLossBackward0>)
tensor(2.2312, grad_fn=<NllLossBackward0>)
tensor(2.2338, grad_fn=<NllLossBackward0>)
tensor(2.3573, grad_fn=<NllLossBackward0>)
tensor(2.2644, grad_fn=<NllLossBackward0>)
tensor(2.2533, grad_fn=<NllLossBackward0>)
tensor(2.0994, grad_fn=<NllLossBackward0>)
tensor(2.1781, grad_fn=<NllLossBackward0>)
tensor(2.3639, grad_fn=<NllLossBackward0>)
tensor(2.2548, grad_fn=<NllLossBackward0>)
tensor(2.3459, grad_fn=<NllLossBackward0>)
tensor(2.3009, grad_fn=<NllLossBackward0>)
tensor(2.2587, grad_fn=<NllLossBackward0>)
tensor(2.2822, grad_fn=<NllLossBackward0>)
tensor(2.1548, grad_fn=<NllLossBackward0>)
tensor(2.2769, grad_fn=<NllLossBackward0>)
tensor(2.1506, grad_fn=<NllLossBackward0>)
tensor(2.2235, grad_fn=<NllLossBackward0>)
tensor(2.1838, grad_fn=<NllLossBackward0>)
tensor(2.2791, grad_fn=<NllLossBackward0>)
tensor(2.3621, grad_fn=<NllLossBackward0>)
tensor(2.3095, grad_fn=<NllLossBackward0>)
tensor(2.1676, grad_fn=<NllLossBackward0>)
tensor(2.2900, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2280: 0.229
tensor(2.2260, grad_fn=<NllLossBackward0>)
tensor(2.2317, grad_fn=<NllLossBackward0>)
tensor(2.3221, grad_fn=<NllLossBackward0>)
tensor(2.2398, grad_fn=<NllLossBackward0>)
tensor(2.1405, grad_fn=<NllLossBackward0>)
tensor(2.3325, grad_fn=<NllLossBackward0>)
tensor(2.1781, grad_fn=<NllLossBackward0>)
tensor(2.4318, grad_fn=<NllLossBackward0>)
tensor(2.3249, grad_fn=<NllLossBackward0>)
tensor(2.2050, grad_fn=<NllLossBackward0>)
tensor(1.9428, grad_fn=<NllLossBackward0>)
tensor(2.3089, grad_fn=<NllLossBackward0>)
tensor(2.4909, grad_fn=<NllLossBackward0>)
tensor(2.2891, grad_fn=<NllLossBackward0>)
tensor(2.2288, grad_fn=<NllLossBackward0>)
tensor(2.1997, grad_fn=<NllLossBackward0>)
tensor(2.1815, grad_fn=<NllLossBackward0>)
tensor(2.0485, grad_fn=<NllLossBackward0>)
tensor(2.2260, grad_fn=<NllLossBackward0>)
tensor(2.3829, grad_fn=<NllLossBackward0>)
tensor(2.1666, grad_fn=<NllLossBackward0>)
tensor(2.3593, grad_fn=<NllLossBackward0>)
tensor(2.3604, grad_fn=<NllLossBackward0>)
tensor(2.3074, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2304: 0.236
tensor(2.1376, grad_fn=<NllLossBackward0>)
tensor(2.2310, grad_fn=<NllLossBackward0>)
tensor(2.2025, grad_fn=<NllLossBackward0>)
tensor(2.3579, grad_fn=<NllLossBackward0>)
tensor(2.3144, grad_fn=<NllLossBackward0>)
tensor(2.2786, grad_fn=<NllLossBackward0>)
tensor(2.2823, grad_fn=<NllLossBackward0>)
tensor(2.3070, grad_fn=<NllLossBackward0>)
tensor(2.0256, grad_fn=<NllLossBackward0>)
tensor(2.1204, grad_fn=<NllLossBackward0>)
tensor(2.2397, grad_fn=<NllLossBackward0>)
tensor(2.2340, grad_fn=<NllLossBackward0>)
tensor(2.0392, grad_fn=<NllLossBackward0>)
tensor(2.3481, grad_fn=<NllLossBackward0>)
tensor(2.2444, grad_fn=<NllLossBackward0>)
tensor(2.4086, grad_fn=<NllLossBackward0>)
tensor(2.1723, grad_fn=<NllLossBackward0>)
tensor(2.1479, grad_fn=<NllLossBackward0>)
tensor(2.0398, grad_fn=<NllLossBackward0>)
tensor(2.3516, grad_fn=<NllLossBackward0>)
tensor(2.1553, grad_fn=<NllLossBackward0>)
tensor(2.2673, grad_fn=<NllLossBackward0>)
tensor(2.2430, grad_fn=<NllLossBackward0>)
tensor(2.2699, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2328: 0.243
tensor(2.1949, grad_fn=<NllLossBackward0>)
tensor(2.3391, grad_fn=<NllLossBackward0>)
tensor(2.1811, grad_fn=<NllLossBackward0>)
tensor(2.3615, grad_fn=<NllLossBackward0>)
tensor(2.2403, grad_fn=<NllLossBackward0>)
tensor(2.2224, grad_fn=<NllLossBackward0>)
tensor(2.1748, grad_fn=<NllLossBackward0>)
tensor(2.2631, grad_fn=<NllLossBackward0>)
tensor(2.2443, grad_fn=<NllLossBackward0>)
tensor(2.2527, grad_fn=<NllLossBackward0>)
tensor(2.4476, grad_fn=<NllLossBackward0>)
tensor(2.4063, grad_fn=<NllLossBackward0>)
tensor(2.1340, grad_fn=<NllLossBackward0>)
tensor(2.3043, grad_fn=<NllLossBackward0>)
tensor(2.2056, grad_fn=<NllLossBackward0>)
tensor(2.1655, grad_fn=<NllLossBackward0>)
tensor(2.1819, grad_fn=<NllLossBackward0>)
tensor(2.2741, grad_fn=<NllLossBackward0>)
tensor(2.1795, grad_fn=<NllLossBackward0>)
tensor(2.0536, grad_fn=<NllLossBackward0>)
tensor(2.2439, grad_fn=<NllLossBackward0>)
tensor(2.0864, grad_fn=<NllLossBackward0>)
tensor(2.3287, grad_fn=<NllLossBackward0>)
tensor(2.3706, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2352: 0.241
tensor(2.2368, grad_fn=<NllLossBackward0>)
tensor(2.0253, grad_fn=<NllLossBackward0>)
tensor(2.1932, grad_fn=<NllLossBackward0>)
tensor(2.2851, grad_fn=<NllLossBackward0>)
tensor(2.2774, grad_fn=<NllLossBackward0>)
tensor(2.3479, grad_fn=<NllLossBackward0>)
tensor(2.3160, grad_fn=<NllLossBackward0>)
tensor(2.4821, grad_fn=<NllLossBackward0>)
tensor(2.2955, grad_fn=<NllLossBackward0>)
tensor(2.2564, grad_fn=<NllLossBackward0>)
tensor(2.1169, grad_fn=<NllLossBackward0>)
tensor(2.1524, grad_fn=<NllLossBackward0>)
tensor(2.2333, grad_fn=<NllLossBackward0>)
tensor(2.2963, grad_fn=<NllLossBackward0>)
tensor(2.3398, grad_fn=<NllLossBackward0>)
tensor(2.2120, grad_fn=<NllLossBackward0>)
tensor(2.1764, grad_fn=<NllLossBackward0>)
tensor(2.3218, grad_fn=<NllLossBackward0>)
tensor(2.3146, grad_fn=<NllLossBackward0>)
tensor(2.2678, grad_fn=<NllLossBackward0>)
tensor(2.2491, grad_fn=<NllLossBackward0>)
tensor(2.3766, grad_fn=<NllLossBackward0>)
tensor(2.4298, grad_fn=<NllLossBackward0>)
tensor(2.2174, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2376: 0.222
tensor(2.1178, grad_fn=<NllLossBackward0>)
tensor(2.2720, grad_fn=<NllLossBackward0>)
tensor(2.3140, grad_fn=<NllLossBackward0>)
tensor(2.3231, grad_fn=<NllLossBackward0>)
tensor(1.9841, grad_fn=<NllLossBackward0>)
tensor(2.2932, grad_fn=<NllLossBackward0>)
tensor(2.3989, grad_fn=<NllLossBackward0>)
tensor(2.2437, grad_fn=<NllLossBackward0>)
tensor(2.0443, grad_fn=<NllLossBackward0>)
tensor(2.3564, grad_fn=<NllLossBackward0>)
tensor(2.4055, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.2800, grad_fn=<NllLossBackward0>)
tensor(2.2965, grad_fn=<NllLossBackward0>)
tensor(2.3148, grad_fn=<NllLossBackward0>)
tensor(2.1798, grad_fn=<NllLossBackward0>)
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.1161, grad_fn=<NllLossBackward0>)
tensor(2.2477, grad_fn=<NllLossBackward0>)
tensor(2.4507, grad_fn=<NllLossBackward0>)
tensor(2.3037, grad_fn=<NllLossBackward0>)
tensor(2.3856, grad_fn=<NllLossBackward0>)
tensor(2.2273, grad_fn=<NllLossBackward0>)
tensor(2.2107, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2400: 0.255
tensor(2.2489, grad_fn=<NllLossBackward0>)
tensor(2.2330, grad_fn=<NllLossBackward0>)
tensor(2.0687, grad_fn=<NllLossBackward0>)
tensor(2.1451, grad_fn=<NllLossBackward0>)
tensor(2.3363, grad_fn=<NllLossBackward0>)
tensor(2.2305, grad_fn=<NllLossBackward0>)
tensor(2.3429, grad_fn=<NllLossBackward0>)
tensor(2.1130, grad_fn=<NllLossBackward0>)
tensor(2.1839, grad_fn=<NllLossBackward0>)
tensor(2.2710, grad_fn=<NllLossBackward0>)
tensor(2.3033, grad_fn=<NllLossBackward0>)
tensor(2.1559, grad_fn=<NllLossBackward0>)
tensor(2.1263, grad_fn=<NllLossBackward0>)
tensor(2.2457, grad_fn=<NllLossBackward0>)
tensor(2.3758, grad_fn=<NllLossBackward0>)
tensor(2.1704, grad_fn=<NllLossBackward0>)
tensor(2.2415, grad_fn=<NllLossBackward0>)
tensor(2.2060, grad_fn=<NllLossBackward0>)
tensor(2.2229, grad_fn=<NllLossBackward0>)
tensor(2.1777, grad_fn=<NllLossBackward0>)
tensor(2.2196, grad_fn=<NllLossBackward0>)
tensor(2.2966, grad_fn=<NllLossBackward0>)
tensor(2.1805, grad_fn=<NllLossBackward0>)
tensor(2.1921, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2424: 0.285
tensor(2.2873, grad_fn=<NllLossBackward0>)
tensor(2.2555, grad_fn=<NllLossBackward0>)
tensor(2.2657, grad_fn=<NllLossBackward0>)
tensor(2.2242, grad_fn=<NllLossBackward0>)
tensor(2.3226, grad_fn=<NllLossBackward0>)
tensor(2.3412, grad_fn=<NllLossBackward0>)
tensor(2.2503, grad_fn=<NllLossBackward0>)
tensor(2.2562, grad_fn=<NllLossBackward0>)
tensor(2.2477, grad_fn=<NllLossBackward0>)
tensor(2.4734, grad_fn=<NllLossBackward0>)
tensor(2.2340, grad_fn=<NllLossBackward0>)
tensor(2.2652, grad_fn=<NllLossBackward0>)
tensor(2.0783, grad_fn=<NllLossBackward0>)
tensor(2.2709, grad_fn=<NllLossBackward0>)
tensor(2.2853, grad_fn=<NllLossBackward0>)
tensor(2.2065, grad_fn=<NllLossBackward0>)
tensor(2.3823, grad_fn=<NllLossBackward0>)
tensor(2.4479, grad_fn=<NllLossBackward0>)
tensor(2.1487, grad_fn=<NllLossBackward0>)
tensor(2.1738, grad_fn=<NllLossBackward0>)
tensor(2.3322, grad_fn=<NllLossBackward0>)
tensor(2.2562, grad_fn=<NllLossBackward0>)
tensor(2.1541, grad_fn=<NllLossBackward0>)
tensor(2.3199, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2448: 0.220
tensor(2.0161, grad_fn=<NllLossBackward0>)
tensor(2.2680, grad_fn=<NllLossBackward0>)
tensor(2.0342, grad_fn=<NllLossBackward0>)
tensor(2.1310, grad_fn=<NllLossBackward0>)
tensor(2.2773, grad_fn=<NllLossBackward0>)
tensor(2.1969, grad_fn=<NllLossBackward0>)
tensor(2.1690, grad_fn=<NllLossBackward0>)
tensor(2.2312, grad_fn=<NllLossBackward0>)
tensor(2.2246, grad_fn=<NllLossBackward0>)
tensor(2.3378, grad_fn=<NllLossBackward0>)
tensor(2.1691, grad_fn=<NllLossBackward0>)
tensor(2.3997, grad_fn=<NllLossBackward0>)
tensor(2.3545, grad_fn=<NllLossBackward0>)
tensor(2.2273, grad_fn=<NllLossBackward0>)
tensor(2.3621, grad_fn=<NllLossBackward0>)
tensor(2.0906, grad_fn=<NllLossBackward0>)
tensor(2.3000, grad_fn=<NllLossBackward0>)
tensor(2.2915, grad_fn=<NllLossBackward0>)
tensor(2.2167, grad_fn=<NllLossBackward0>)
tensor(2.2972, grad_fn=<NllLossBackward0>)
tensor(2.1405, grad_fn=<NllLossBackward0>)
tensor(2.2670, grad_fn=<NllLossBackward0>)
tensor(2.2557, grad_fn=<NllLossBackward0>)
tensor(2.0347, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2472: 0.257
tensor(2.3394, grad_fn=<NllLossBackward0>)
tensor(2.2702, grad_fn=<NllLossBackward0>)
tensor(2.3185, grad_fn=<NllLossBackward0>)
tensor(2.1681, grad_fn=<NllLossBackward0>)
tensor(2.0849, grad_fn=<NllLossBackward0>)
tensor(2.1278, grad_fn=<NllLossBackward0>)
tensor(2.1885, grad_fn=<NllLossBackward0>)
tensor(2.1286, grad_fn=<NllLossBackward0>)
tensor(2.2033, grad_fn=<NllLossBackward0>)
tensor(2.1879, grad_fn=<NllLossBackward0>)
tensor(2.3186, grad_fn=<NllLossBackward0>)
tensor(2.2074, grad_fn=<NllLossBackward0>)
tensor(2.3374, grad_fn=<NllLossBackward0>)
tensor(2.0993, grad_fn=<NllLossBackward0>)
tensor(1.9649, grad_fn=<NllLossBackward0>)
tensor(2.1707, grad_fn=<NllLossBackward0>)
tensor(2.3247, grad_fn=<NllLossBackward0>)
tensor(2.0462, grad_fn=<NllLossBackward0>)
tensor(2.1496, grad_fn=<NllLossBackward0>)
tensor(2.4162, grad_fn=<NllLossBackward0>)
tensor(2.3001, grad_fn=<NllLossBackward0>)
tensor(2.2215, grad_fn=<NllLossBackward0>)
tensor(2.1640, grad_fn=<NllLossBackward0>)
tensor(2.3238, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2496: 0.266
tensor(2.3044, grad_fn=<NllLossBackward0>)
tensor(2.2412, grad_fn=<NllLossBackward0>)
tensor(2.1230, grad_fn=<NllLossBackward0>)
tensor(2.2083, grad_fn=<NllLossBackward0>)
tensor(2.2060, grad_fn=<NllLossBackward0>)
tensor(2.2699, grad_fn=<NllLossBackward0>)
tensor(2.3690, grad_fn=<NllLossBackward0>)
tensor(2.2507, grad_fn=<NllLossBackward0>)
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.2116, grad_fn=<NllLossBackward0>)
tensor(2.4021, grad_fn=<NllLossBackward0>)
tensor(2.2104, grad_fn=<NllLossBackward0>)
tensor(2.0919, grad_fn=<NllLossBackward0>)
tensor(2.3179, grad_fn=<NllLossBackward0>)
tensor(2.2221, grad_fn=<NllLossBackward0>)
tensor(2.2956, grad_fn=<NllLossBackward0>)
tensor(2.1126, grad_fn=<NllLossBackward0>)
tensor(2.0403, grad_fn=<NllLossBackward0>)
tensor(2.0661, grad_fn=<NllLossBackward0>)
tensor(2.1306, grad_fn=<NllLossBackward0>)
tensor(2.1948, grad_fn=<NllLossBackward0>)
tensor(2.1845, grad_fn=<NllLossBackward0>)
tensor(2.0639, grad_fn=<NllLossBackward0>)
tensor(2.2711, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2520: 0.269
tensor(2.3479, grad_fn=<NllLossBackward0>)
tensor(2.1757, grad_fn=<NllLossBackward0>)
tensor(2.3344, grad_fn=<NllLossBackward0>)
tensor(2.2648, grad_fn=<NllLossBackward0>)
tensor(2.1928, grad_fn=<NllLossBackward0>)
tensor(2.1292, grad_fn=<NllLossBackward0>)
tensor(2.2943, grad_fn=<NllLossBackward0>)
tensor(2.1680, grad_fn=<NllLossBackward0>)
tensor(2.0327, grad_fn=<NllLossBackward0>)
tensor(2.2760, grad_fn=<NllLossBackward0>)
tensor(2.3008, grad_fn=<NllLossBackward0>)
tensor(2.0674, grad_fn=<NllLossBackward0>)
tensor(2.2183, grad_fn=<NllLossBackward0>)
tensor(2.2937, grad_fn=<NllLossBackward0>)
tensor(2.2967, grad_fn=<NllLossBackward0>)
tensor(2.0852, grad_fn=<NllLossBackward0>)
tensor(2.2055, grad_fn=<NllLossBackward0>)
tensor(2.2711, grad_fn=<NllLossBackward0>)
tensor(2.3381, grad_fn=<NllLossBackward0>)
tensor(2.3078, grad_fn=<NllLossBackward0>)
tensor(2.2741, grad_fn=<NllLossBackward0>)
tensor(2.1807, grad_fn=<NllLossBackward0>)
tensor(2.2094, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2544: 0.227
tensor(2.1633, grad_fn=<NllLossBackward0>)
tensor(2.1307, grad_fn=<NllLossBackward0>)
tensor(1.9331, grad_fn=<NllLossBackward0>)
tensor(2.3305, grad_fn=<NllLossBackward0>)
tensor(2.3278, grad_fn=<NllLossBackward0>)
tensor(2.3197, grad_fn=<NllLossBackward0>)
tensor(1.9720, grad_fn=<NllLossBackward0>)
tensor(2.0013, grad_fn=<NllLossBackward0>)
tensor(2.2898, grad_fn=<NllLossBackward0>)
tensor(2.3779, grad_fn=<NllLossBackward0>)
tensor(2.1838, grad_fn=<NllLossBackward0>)
tensor(2.3426, grad_fn=<NllLossBackward0>)
tensor(2.2081, grad_fn=<NllLossBackward0>)
tensor(2.2351, grad_fn=<NllLossBackward0>)
tensor(2.2889, grad_fn=<NllLossBackward0>)
tensor(2.2839, grad_fn=<NllLossBackward0>)
tensor(2.2687, grad_fn=<NllLossBackward0>)
tensor(2.0726, grad_fn=<NllLossBackward0>)
tensor(2.2399, grad_fn=<NllLossBackward0>)
tensor(2.1732, grad_fn=<NllLossBackward0>)
tensor(2.2269, grad_fn=<NllLossBackward0>)
tensor(2.3044, grad_fn=<NllLossBackward0>)
tensor(2.2710, grad_fn=<NllLossBackward0>)
tensor(2.2635, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2568: 0.250
tensor(2.3594, grad_fn=<NllLossBackward0>)
tensor(2.2046, grad_fn=<NllLossBackward0>)
tensor(2.2393, grad_fn=<NllLossBackward0>)
tensor(2.0349, grad_fn=<NllLossBackward0>)
tensor(2.2261, grad_fn=<NllLossBackward0>)
tensor(2.3176, grad_fn=<NllLossBackward0>)
tensor(2.1890, grad_fn=<NllLossBackward0>)
tensor(2.2282, grad_fn=<NllLossBackward0>)
tensor(2.2150, grad_fn=<NllLossBackward0>)
tensor(2.1397, grad_fn=<NllLossBackward0>)
tensor(2.2617, grad_fn=<NllLossBackward0>)
tensor(2.3628, grad_fn=<NllLossBackward0>)
tensor(2.4674, grad_fn=<NllLossBackward0>)
tensor(2.4535, grad_fn=<NllLossBackward0>)
tensor(2.1770, grad_fn=<NllLossBackward0>)
tensor(2.1277, grad_fn=<NllLossBackward0>)
tensor(2.1944, grad_fn=<NllLossBackward0>)
tensor(2.1692, grad_fn=<NllLossBackward0>)
tensor(2.3200, grad_fn=<NllLossBackward0>)
tensor(2.1844, grad_fn=<NllLossBackward0>)
tensor(2.1974, grad_fn=<NllLossBackward0>)
tensor(2.1199, grad_fn=<NllLossBackward0>)
tensor(2.3107, grad_fn=<NllLossBackward0>)
tensor(2.3004, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2592: 0.252
tensor(2.2551, grad_fn=<NllLossBackward0>)
tensor(2.0985, grad_fn=<NllLossBackward0>)
tensor(2.2301, grad_fn=<NllLossBackward0>)
tensor(2.2091, grad_fn=<NllLossBackward0>)
tensor(2.3103, grad_fn=<NllLossBackward0>)
tensor(2.1330, grad_fn=<NllLossBackward0>)
tensor(2.2265, grad_fn=<NllLossBackward0>)
tensor(2.2102, grad_fn=<NllLossBackward0>)
tensor(2.1595, grad_fn=<NllLossBackward0>)
tensor(2.1587, grad_fn=<NllLossBackward0>)
tensor(2.2524, grad_fn=<NllLossBackward0>)
tensor(2.1217, grad_fn=<NllLossBackward0>)
tensor(2.0756, grad_fn=<NllLossBackward0>)
tensor(2.1837, grad_fn=<NllLossBackward0>)
tensor(2.2310, grad_fn=<NllLossBackward0>)
tensor(2.2123, grad_fn=<NllLossBackward0>)
tensor(2.1365, grad_fn=<NllLossBackward0>)
tensor(2.2641, grad_fn=<NllLossBackward0>)
tensor(2.1742, grad_fn=<NllLossBackward0>)
tensor(2.0940, grad_fn=<NllLossBackward0>)
tensor(2.3740, grad_fn=<NllLossBackward0>)
tensor(2.3120, grad_fn=<NllLossBackward0>)
tensor(2.1988, grad_fn=<NllLossBackward0>)
tensor(2.1687, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2616: 0.264
tensor(2.2993, grad_fn=<NllLossBackward0>)
tensor(2.1323, grad_fn=<NllLossBackward0>)
tensor(2.2213, grad_fn=<NllLossBackward0>)
tensor(2.2252, grad_fn=<NllLossBackward0>)
tensor(2.2644, grad_fn=<NllLossBackward0>)
tensor(2.4076, grad_fn=<NllLossBackward0>)
tensor(2.3502, grad_fn=<NllLossBackward0>)
tensor(2.1915, grad_fn=<NllLossBackward0>)
tensor(2.0953, grad_fn=<NllLossBackward0>)
tensor(2.3407, grad_fn=<NllLossBackward0>)
tensor(2.1059, grad_fn=<NllLossBackward0>)
tensor(2.3612, grad_fn=<NllLossBackward0>)
tensor(2.3549, grad_fn=<NllLossBackward0>)
tensor(2.3233, grad_fn=<NllLossBackward0>)
tensor(2.4460, grad_fn=<NllLossBackward0>)
tensor(2.2539, grad_fn=<NllLossBackward0>)
tensor(2.2613, grad_fn=<NllLossBackward0>)
tensor(2.2581, grad_fn=<NllLossBackward0>)
tensor(2.2205, grad_fn=<NllLossBackward0>)
tensor(1.9683, grad_fn=<NllLossBackward0>)
tensor(2.2014, grad_fn=<NllLossBackward0>)
tensor(2.1926, grad_fn=<NllLossBackward0>)
tensor(2.2253, grad_fn=<NllLossBackward0>)
tensor(2.4084, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2640: 0.243
tensor(2.2368, grad_fn=<NllLossBackward0>)
tensor(2.2726, grad_fn=<NllLossBackward0>)
tensor(2.2233, grad_fn=<NllLossBackward0>)
tensor(2.1493, grad_fn=<NllLossBackward0>)
tensor(2.2108, grad_fn=<NllLossBackward0>)
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.2830, grad_fn=<NllLossBackward0>)
tensor(2.2831, grad_fn=<NllLossBackward0>)
tensor(2.1346, grad_fn=<NllLossBackward0>)
tensor(2.3119, grad_fn=<NllLossBackward0>)
tensor(2.3699, grad_fn=<NllLossBackward0>)
tensor(2.0831, grad_fn=<NllLossBackward0>)
tensor(2.1746, grad_fn=<NllLossBackward0>)
tensor(2.2690, grad_fn=<NllLossBackward0>)
tensor(2.2614, grad_fn=<NllLossBackward0>)
tensor(2.2373, grad_fn=<NllLossBackward0>)
tensor(2.2634, grad_fn=<NllLossBackward0>)
tensor(2.0531, grad_fn=<NllLossBackward0>)
tensor(2.2930, grad_fn=<NllLossBackward0>)
tensor(2.3164, grad_fn=<NllLossBackward0>)
tensor(2.2847, grad_fn=<NllLossBackward0>)
tensor(2.2134, grad_fn=<NllLossBackward0>)
tensor(2.2591, grad_fn=<NllLossBackward0>)
tensor(2.3149, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2664: 0.245
tensor(2.2646, grad_fn=<NllLossBackward0>)
tensor(2.0383, grad_fn=<NllLossBackward0>)
tensor(2.1994, grad_fn=<NllLossBackward0>)
tensor(2.1989, grad_fn=<NllLossBackward0>)
tensor(2.0657, grad_fn=<NllLossBackward0>)
tensor(2.3009, grad_fn=<NllLossBackward0>)
tensor(2.4123, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.1687, grad_fn=<NllLossBackward0>)
tensor(2.1516, grad_fn=<NllLossBackward0>)
tensor(2.3377, grad_fn=<NllLossBackward0>)
tensor(2.3927, grad_fn=<NllLossBackward0>)
tensor(2.3091, grad_fn=<NllLossBackward0>)
tensor(2.3030, grad_fn=<NllLossBackward0>)
tensor(2.1721, grad_fn=<NllLossBackward0>)
tensor(2.2362, grad_fn=<NllLossBackward0>)
tensor(2.2491, grad_fn=<NllLossBackward0>)
tensor(2.1682, grad_fn=<NllLossBackward0>)
tensor(2.2709, grad_fn=<NllLossBackward0>)
tensor(2.1260, grad_fn=<NllLossBackward0>)
tensor(2.2725, grad_fn=<NllLossBackward0>)
tensor(2.3272, grad_fn=<NllLossBackward0>)
tensor(2.2612, grad_fn=<NllLossBackward0>)
tensor(2.3099, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2688: 0.245
tensor(2.1343, grad_fn=<NllLossBackward0>)
tensor(2.4335, grad_fn=<NllLossBackward0>)
tensor(2.3451, grad_fn=<NllLossBackward0>)
tensor(2.2547, grad_fn=<NllLossBackward0>)
tensor(2.2822, grad_fn=<NllLossBackward0>)
tensor(2.1540, grad_fn=<NllLossBackward0>)
tensor(2.2852, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.3056, grad_fn=<NllLossBackward0>)
tensor(2.2113, grad_fn=<NllLossBackward0>)
tensor(2.2685, grad_fn=<NllLossBackward0>)
tensor(2.2557, grad_fn=<NllLossBackward0>)
tensor(2.1683, grad_fn=<NllLossBackward0>)
tensor(2.3408, grad_fn=<NllLossBackward0>)
tensor(2.1296, grad_fn=<NllLossBackward0>)
tensor(2.0859, grad_fn=<NllLossBackward0>)
tensor(2.1371, grad_fn=<NllLossBackward0>)
tensor(2.1298, grad_fn=<NllLossBackward0>)
tensor(2.3779, grad_fn=<NllLossBackward0>)
tensor(2.1878, grad_fn=<NllLossBackward0>)
tensor(2.0967, grad_fn=<NllLossBackward0>)
tensor(2.2698, grad_fn=<NllLossBackward0>)
tensor(2.2413, grad_fn=<NllLossBackward0>)
tensor(2.4138, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2712: 0.260
tensor(2.3746, grad_fn=<NllLossBackward0>)
tensor(2.2296, grad_fn=<NllLossBackward0>)
tensor(2.1906, grad_fn=<NllLossBackward0>)
tensor(2.2887, grad_fn=<NllLossBackward0>)
tensor(2.1953, grad_fn=<NllLossBackward0>)
tensor(2.1442, grad_fn=<NllLossBackward0>)
tensor(2.3664, grad_fn=<NllLossBackward0>)
tensor(2.1423, grad_fn=<NllLossBackward0>)
tensor(2.1321, grad_fn=<NllLossBackward0>)
tensor(2.4367, grad_fn=<NllLossBackward0>)
tensor(2.1172, grad_fn=<NllLossBackward0>)
tensor(2.0997, grad_fn=<NllLossBackward0>)
tensor(2.2160, grad_fn=<NllLossBackward0>)
tensor(2.2115, grad_fn=<NllLossBackward0>)
tensor(2.2835, grad_fn=<NllLossBackward0>)
tensor(2.0317, grad_fn=<NllLossBackward0>)
tensor(2.3457, grad_fn=<NllLossBackward0>)
tensor(2.2495, grad_fn=<NllLossBackward0>)
tensor(2.2873, grad_fn=<NllLossBackward0>)
tensor(2.2479, grad_fn=<NllLossBackward0>)
tensor(2.4678, grad_fn=<NllLossBackward0>)
tensor(2.1207, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.1656, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2736: 0.266
tensor(2.2219, grad_fn=<NllLossBackward0>)
tensor(2.1340, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.0513, grad_fn=<NllLossBackward0>)
tensor(2.1963, grad_fn=<NllLossBackward0>)
tensor(2.2351, grad_fn=<NllLossBackward0>)
tensor(2.2095, grad_fn=<NllLossBackward0>)
tensor(2.2344, grad_fn=<NllLossBackward0>)
tensor(2.2397, grad_fn=<NllLossBackward0>)
tensor(2.1554, grad_fn=<NllLossBackward0>)
tensor(2.4214, grad_fn=<NllLossBackward0>)
tensor(2.3269, grad_fn=<NllLossBackward0>)
tensor(2.0761, grad_fn=<NllLossBackward0>)
tensor(2.2851, grad_fn=<NllLossBackward0>)
tensor(2.0842, grad_fn=<NllLossBackward0>)
tensor(2.1687, grad_fn=<NllLossBackward0>)
tensor(2.2807, grad_fn=<NllLossBackward0>)
tensor(2.0552, grad_fn=<NllLossBackward0>)
tensor(2.2443, grad_fn=<NllLossBackward0>)
tensor(2.1285, grad_fn=<NllLossBackward0>)
tensor(2.1716, grad_fn=<NllLossBackward0>)
tensor(2.0569, grad_fn=<NllLossBackward0>)
tensor(2.1404, grad_fn=<NllLossBackward0>)
tensor(2.1900, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2760: 0.276
tensor(2.0643, grad_fn=<NllLossBackward0>)
tensor(2.1832, grad_fn=<NllLossBackward0>)
tensor(2.3375, grad_fn=<NllLossBackward0>)
tensor(2.2641, grad_fn=<NllLossBackward0>)
tensor(2.2556, grad_fn=<NllLossBackward0>)
tensor(2.2095, grad_fn=<NllLossBackward0>)
tensor(2.1934, grad_fn=<NllLossBackward0>)
tensor(2.2150, grad_fn=<NllLossBackward0>)
tensor(2.3671, grad_fn=<NllLossBackward0>)
tensor(2.2282, grad_fn=<NllLossBackward0>)
tensor(2.1265, grad_fn=<NllLossBackward0>)
tensor(2.1596, grad_fn=<NllLossBackward0>)
tensor(2.3004, grad_fn=<NllLossBackward0>)
tensor(2.3011, grad_fn=<NllLossBackward0>)
tensor(2.0478, grad_fn=<NllLossBackward0>)
tensor(2.4154, grad_fn=<NllLossBackward0>)
tensor(2.3168, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.0890, grad_fn=<NllLossBackward0>)
tensor(2.2056, grad_fn=<NllLossBackward0>)
tensor(2.4072, grad_fn=<NllLossBackward0>)
tensor(2.3070, grad_fn=<NllLossBackward0>)
tensor(2.2327, grad_fn=<NllLossBackward0>)
tensor(2.2091, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2784: 0.240
tensor(2.2223, grad_fn=<NllLossBackward0>)
tensor(2.2778, grad_fn=<NllLossBackward0>)
tensor(2.2511, grad_fn=<NllLossBackward0>)
tensor(2.2652, grad_fn=<NllLossBackward0>)
tensor(2.1855, grad_fn=<NllLossBackward0>)
tensor(2.1836, grad_fn=<NllLossBackward0>)
tensor(2.4202, grad_fn=<NllLossBackward0>)
tensor(2.1440, grad_fn=<NllLossBackward0>)
tensor(2.2608, grad_fn=<NllLossBackward0>)
tensor(2.2365, grad_fn=<NllLossBackward0>)
tensor(2.1705, grad_fn=<NllLossBackward0>)
tensor(2.2985, grad_fn=<NllLossBackward0>)
tensor(2.3261, grad_fn=<NllLossBackward0>)
tensor(2.1505, grad_fn=<NllLossBackward0>)
tensor(2.2722, grad_fn=<NllLossBackward0>)
tensor(2.3210, grad_fn=<NllLossBackward0>)
tensor(2.1789, grad_fn=<NllLossBackward0>)
tensor(2.1874, grad_fn=<NllLossBackward0>)
tensor(2.2094, grad_fn=<NllLossBackward0>)
tensor(2.2353, grad_fn=<NllLossBackward0>)
tensor(2.1503, grad_fn=<NllLossBackward0>)
tensor(2.0591, grad_fn=<NllLossBackward0>)
tensor(2.1931, grad_fn=<NllLossBackward0>)
tensor(2.2936, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2808: 0.245
tensor(2.1307, grad_fn=<NllLossBackward0>)
tensor(2.2409, grad_fn=<NllLossBackward0>)
tensor(2.2159, grad_fn=<NllLossBackward0>)
tensor(2.1972, grad_fn=<NllLossBackward0>)
tensor(2.2766, grad_fn=<NllLossBackward0>)
tensor(2.3262, grad_fn=<NllLossBackward0>)
tensor(2.4223, grad_fn=<NllLossBackward0>)
tensor(2.2008, grad_fn=<NllLossBackward0>)
tensor(2.4507, grad_fn=<NllLossBackward0>)
tensor(2.3887, grad_fn=<NllLossBackward0>)
tensor(2.2605, grad_fn=<NllLossBackward0>)
tensor(2.1312, grad_fn=<NllLossBackward0>)
tensor(2.2343, grad_fn=<NllLossBackward0>)
tensor(2.3827, grad_fn=<NllLossBackward0>)
tensor(2.2837, grad_fn=<NllLossBackward0>)
tensor(2.1549, grad_fn=<NllLossBackward0>)
tensor(2.0855, grad_fn=<NllLossBackward0>)
tensor(2.1370, grad_fn=<NllLossBackward0>)
tensor(2.2311, grad_fn=<NllLossBackward0>)
tensor(2.4415, grad_fn=<NllLossBackward0>)
tensor(2.2546, grad_fn=<NllLossBackward0>)
tensor(2.1793, grad_fn=<NllLossBackward0>)
tensor(2.1706, grad_fn=<NllLossBackward0>)
tensor(2.0988, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2832: 0.233
tensor(2.3563, grad_fn=<NllLossBackward0>)
tensor(2.1027, grad_fn=<NllLossBackward0>)
tensor(2.3266, grad_fn=<NllLossBackward0>)
tensor(2.2556, grad_fn=<NllLossBackward0>)
tensor(2.4421, grad_fn=<NllLossBackward0>)
tensor(2.2302, grad_fn=<NllLossBackward0>)
tensor(2.3463, grad_fn=<NllLossBackward0>)
tensor(2.1688, grad_fn=<NllLossBackward0>)
tensor(2.1970, grad_fn=<NllLossBackward0>)
tensor(2.1595, grad_fn=<NllLossBackward0>)
tensor(2.2654, grad_fn=<NllLossBackward0>)
tensor(2.1972, grad_fn=<NllLossBackward0>)
tensor(2.2811, grad_fn=<NllLossBackward0>)
tensor(2.1455, grad_fn=<NllLossBackward0>)
tensor(2.1339, grad_fn=<NllLossBackward0>)
tensor(2.2484, grad_fn=<NllLossBackward0>)
tensor(2.1585, grad_fn=<NllLossBackward0>)
tensor(2.3395, grad_fn=<NllLossBackward0>)
tensor(2.4024, grad_fn=<NllLossBackward0>)
tensor(2.2011, grad_fn=<NllLossBackward0>)
tensor(2.1361, grad_fn=<NllLossBackward0>)
tensor(2.1850, grad_fn=<NllLossBackward0>)
tensor(2.0163, grad_fn=<NllLossBackward0>)
tensor(2.1710, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2856: 0.234
tensor(2.3173, grad_fn=<NllLossBackward0>)
tensor(2.1116, grad_fn=<NllLossBackward0>)
tensor(2.2452, grad_fn=<NllLossBackward0>)
tensor(2.3768, grad_fn=<NllLossBackward0>)
tensor(2.2523, grad_fn=<NllLossBackward0>)
tensor(2.1441, grad_fn=<NllLossBackward0>)
tensor(2.2652, grad_fn=<NllLossBackward0>)
tensor(2.2084, grad_fn=<NllLossBackward0>)
tensor(2.3257, grad_fn=<NllLossBackward0>)
tensor(2.3993, grad_fn=<NllLossBackward0>)
tensor(2.0246, grad_fn=<NllLossBackward0>)
tensor(2.3926, grad_fn=<NllLossBackward0>)
tensor(2.1413, grad_fn=<NllLossBackward0>)
tensor(2.3865, grad_fn=<NllLossBackward0>)
tensor(2.3787, grad_fn=<NllLossBackward0>)
tensor(2.4398, grad_fn=<NllLossBackward0>)
tensor(2.0585, grad_fn=<NllLossBackward0>)
tensor(2.0706, grad_fn=<NllLossBackward0>)
tensor(2.2825, grad_fn=<NllLossBackward0>)
tensor(2.0529, grad_fn=<NllLossBackward0>)
tensor(2.4099, grad_fn=<NllLossBackward0>)
tensor(2.1414, grad_fn=<NllLossBackward0>)
tensor(2.2955, grad_fn=<NllLossBackward0>)
tensor(2.2523, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2880: 0.229
tensor(2.2404, grad_fn=<NllLossBackward0>)
tensor(2.2891, grad_fn=<NllLossBackward0>)
tensor(2.1653, grad_fn=<NllLossBackward0>)
tensor(2.2256, grad_fn=<NllLossBackward0>)
tensor(2.3270, grad_fn=<NllLossBackward0>)
tensor(2.1703, grad_fn=<NllLossBackward0>)
tensor(2.2619, grad_fn=<NllLossBackward0>)
tensor(2.2279, grad_fn=<NllLossBackward0>)
tensor(2.0333, grad_fn=<NllLossBackward0>)
tensor(2.2490, grad_fn=<NllLossBackward0>)
tensor(2.3055, grad_fn=<NllLossBackward0>)
tensor(2.2519, grad_fn=<NllLossBackward0>)
tensor(2.3719, grad_fn=<NllLossBackward0>)
tensor(2.2787, grad_fn=<NllLossBackward0>)
tensor(2.3079, grad_fn=<NllLossBackward0>)
tensor(2.0457, grad_fn=<NllLossBackward0>)
tensor(2.2312, grad_fn=<NllLossBackward0>)
tensor(2.1601, grad_fn=<NllLossBackward0>)
tensor(2.1732, grad_fn=<NllLossBackward0>)
tensor(2.3142, grad_fn=<NllLossBackward0>)
tensor(2.0582, grad_fn=<NllLossBackward0>)
tensor(1.9732, grad_fn=<NllLossBackward0>)
tensor(2.3861, grad_fn=<NllLossBackward0>)
tensor(2.2944, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2904: 0.252
tensor(1.9112, grad_fn=<NllLossBackward0>)
tensor(2.1336, grad_fn=<NllLossBackward0>)
tensor(2.3193, grad_fn=<NllLossBackward0>)
tensor(2.2399, grad_fn=<NllLossBackward0>)
tensor(2.2039, grad_fn=<NllLossBackward0>)
tensor(2.2264, grad_fn=<NllLossBackward0>)
tensor(2.2086, grad_fn=<NllLossBackward0>)
tensor(2.1803, grad_fn=<NllLossBackward0>)
tensor(2.1520, grad_fn=<NllLossBackward0>)
tensor(2.2213, grad_fn=<NllLossBackward0>)
tensor(2.1699, grad_fn=<NllLossBackward0>)
tensor(2.2743, grad_fn=<NllLossBackward0>)
tensor(2.1234, grad_fn=<NllLossBackward0>)
tensor(2.0732, grad_fn=<NllLossBackward0>)
tensor(2.0851, grad_fn=<NllLossBackward0>)
tensor(2.1137, grad_fn=<NllLossBackward0>)
tensor(2.2035, grad_fn=<NllLossBackward0>)
tensor(2.3442, grad_fn=<NllLossBackward0>)
tensor(2.1474, grad_fn=<NllLossBackward0>)
tensor(2.3177, grad_fn=<NllLossBackward0>)
tensor(2.3051, grad_fn=<NllLossBackward0>)
tensor(2.2145, grad_fn=<NllLossBackward0>)
tensor(2.3544, grad_fn=<NllLossBackward0>)
tensor(2.4539, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2928: 0.236
tensor(2.1753, grad_fn=<NllLossBackward0>)
tensor(2.2284, grad_fn=<NllLossBackward0>)
tensor(2.2891, grad_fn=<NllLossBackward0>)
tensor(2.3269, grad_fn=<NllLossBackward0>)
tensor(2.1784, grad_fn=<NllLossBackward0>)
tensor(2.2759, grad_fn=<NllLossBackward0>)
tensor(2.3776, grad_fn=<NllLossBackward0>)
tensor(2.1978, grad_fn=<NllLossBackward0>)
tensor(2.2653, grad_fn=<NllLossBackward0>)
tensor(2.0424, grad_fn=<NllLossBackward0>)
tensor(2.1406, grad_fn=<NllLossBackward0>)
tensor(2.1408, grad_fn=<NllLossBackward0>)
tensor(2.3646, grad_fn=<NllLossBackward0>)
tensor(2.1984, grad_fn=<NllLossBackward0>)
tensor(2.3389, grad_fn=<NllLossBackward0>)
tensor(2.2245, grad_fn=<NllLossBackward0>)
tensor(2.2134, grad_fn=<NllLossBackward0>)
tensor(2.1178, grad_fn=<NllLossBackward0>)
tensor(2.3399, grad_fn=<NllLossBackward0>)
tensor(2.0836, grad_fn=<NllLossBackward0>)
tensor(2.1528, grad_fn=<NllLossBackward0>)
tensor(2.1656, grad_fn=<NllLossBackward0>)
tensor(2.1464, grad_fn=<NllLossBackward0>)
tensor(2.1898, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2952: 0.260
tensor(2.2639, grad_fn=<NllLossBackward0>)
tensor(2.2110, grad_fn=<NllLossBackward0>)
tensor(2.3803, grad_fn=<NllLossBackward0>)
tensor(2.1678, grad_fn=<NllLossBackward0>)
tensor(2.1921, grad_fn=<NllLossBackward0>)
tensor(2.3427, grad_fn=<NllLossBackward0>)
tensor(2.1569, grad_fn=<NllLossBackward0>)
tensor(2.2314, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(2.3812, grad_fn=<NllLossBackward0>)
tensor(2.2861, grad_fn=<NllLossBackward0>)
tensor(2.2258, grad_fn=<NllLossBackward0>)
tensor(2.2365, grad_fn=<NllLossBackward0>)
tensor(2.0728, grad_fn=<NllLossBackward0>)
tensor(2.0898, grad_fn=<NllLossBackward0>)
tensor(2.2269, grad_fn=<NllLossBackward0>)
tensor(2.1342, grad_fn=<NllLossBackward0>)
tensor(2.2541, grad_fn=<NllLossBackward0>)
tensor(2.2444, grad_fn=<NllLossBackward0>)
tensor(2.3077, grad_fn=<NllLossBackward0>)
tensor(2.1736, grad_fn=<NllLossBackward0>)
tensor(2.1627, grad_fn=<NllLossBackward0>)
tensor(2.2699, grad_fn=<NllLossBackward0>)
tensor(2.0145, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2976: 0.240
tensor(2.3018, grad_fn=<NllLossBackward0>)
tensor(2.1785, grad_fn=<NllLossBackward0>)
tensor(2.0514, grad_fn=<NllLossBackward0>)
tensor(2.2472, grad_fn=<NllLossBackward0>)
tensor(2.3947, grad_fn=<NllLossBackward0>)
tensor(2.2858, grad_fn=<NllLossBackward0>)
tensor(2.3606, grad_fn=<NllLossBackward0>)
tensor(2.3350, grad_fn=<NllLossBackward0>)
tensor(2.0351, grad_fn=<NllLossBackward0>)
tensor(1.8328, grad_fn=<NllLossBackward0>)
tensor(2.3068, grad_fn=<NllLossBackward0>)
tensor(2.2973, grad_fn=<NllLossBackward0>)
tensor(2.1875, grad_fn=<NllLossBackward0>)
tensor(2.2655, grad_fn=<NllLossBackward0>)
tensor(2.1270, grad_fn=<NllLossBackward0>)
tensor(2.2129, grad_fn=<NllLossBackward0>)
tensor(2.2195, grad_fn=<NllLossBackward0>)
tensor(2.2779, grad_fn=<NllLossBackward0>)
tensor(2.2755, grad_fn=<NllLossBackward0>)
tensor(2.2823, grad_fn=<NllLossBackward0>)
tensor(2.2182, grad_fn=<NllLossBackward0>)
tensor(2.1464, grad_fn=<NllLossBackward0>)
tensor(2.1081, grad_fn=<NllLossBackward0>)
tensor(2.2447, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3000: 0.227
tensor(2.1039, grad_fn=<NllLossBackward0>)
tensor(2.2267, grad_fn=<NllLossBackward0>)
tensor(2.3877, grad_fn=<NllLossBackward0>)
tensor(2.2355, grad_fn=<NllLossBackward0>)
tensor(2.1442, grad_fn=<NllLossBackward0>)
tensor(2.1874, grad_fn=<NllLossBackward0>)
tensor(2.1760, grad_fn=<NllLossBackward0>)
tensor(1.9612, grad_fn=<NllLossBackward0>)
tensor(2.1455, grad_fn=<NllLossBackward0>)
tensor(1.9355, grad_fn=<NllLossBackward0>)
tensor(2.2798, grad_fn=<NllLossBackward0>)
tensor(2.1445, grad_fn=<NllLossBackward0>)
tensor(2.1145, grad_fn=<NllLossBackward0>)
tensor(2.3215, grad_fn=<NllLossBackward0>)
tensor(2.1825, grad_fn=<NllLossBackward0>)
tensor(2.1030, grad_fn=<NllLossBackward0>)
tensor(2.0780, grad_fn=<NllLossBackward0>)
tensor(2.2829, grad_fn=<NllLossBackward0>)
tensor(2.1941, grad_fn=<NllLossBackward0>)
tensor(2.2916, grad_fn=<NllLossBackward0>)
tensor(1.9390, grad_fn=<NllLossBackward0>)
tensor(2.3514, grad_fn=<NllLossBackward0>)
tensor(2.2325, grad_fn=<NllLossBackward0>)
tensor(2.1720, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3024: 0.259
tensor(2.0237, grad_fn=<NllLossBackward0>)
tensor(2.1049, grad_fn=<NllLossBackward0>)
tensor(2.3824, grad_fn=<NllLossBackward0>)
tensor(2.1037, grad_fn=<NllLossBackward0>)
tensor(2.2633, grad_fn=<NllLossBackward0>)
tensor(2.3072, grad_fn=<NllLossBackward0>)
tensor(2.1286, grad_fn=<NllLossBackward0>)
tensor(2.1485, grad_fn=<NllLossBackward0>)
tensor(2.2338, grad_fn=<NllLossBackward0>)
tensor(2.2254, grad_fn=<NllLossBackward0>)
tensor(2.2236, grad_fn=<NllLossBackward0>)
tensor(2.2234, grad_fn=<NllLossBackward0>)
tensor(2.2010, grad_fn=<NllLossBackward0>)
tensor(2.0276, grad_fn=<NllLossBackward0>)
tensor(2.1709, grad_fn=<NllLossBackward0>)
tensor(2.2475, grad_fn=<NllLossBackward0>)
tensor(2.2725, grad_fn=<NllLossBackward0>)
tensor(2.3116, grad_fn=<NllLossBackward0>)
tensor(2.2229, grad_fn=<NllLossBackward0>)
tensor(2.0705, grad_fn=<NllLossBackward0>)
tensor(2.1163, grad_fn=<NllLossBackward0>)
tensor(2.3551, grad_fn=<NllLossBackward0>)
tensor(2.0262, grad_fn=<NllLossBackward0>)
tensor(2.0706, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3048: 0.247
tensor(2.2594, grad_fn=<NllLossBackward0>)
tensor(2.3970, grad_fn=<NllLossBackward0>)
tensor(2.2987, grad_fn=<NllLossBackward0>)
tensor(2.2791, grad_fn=<NllLossBackward0>)
tensor(2.0471, grad_fn=<NllLossBackward0>)
tensor(2.3736, grad_fn=<NllLossBackward0>)
tensor(2.3458, grad_fn=<NllLossBackward0>)
tensor(2.4539, grad_fn=<NllLossBackward0>)
tensor(2.2607, grad_fn=<NllLossBackward0>)
tensor(2.1448, grad_fn=<NllLossBackward0>)
tensor(2.4030, grad_fn=<NllLossBackward0>)
tensor(2.1974, grad_fn=<NllLossBackward0>)
tensor(2.0784, grad_fn=<NllLossBackward0>)
tensor(2.0196, grad_fn=<NllLossBackward0>)
tensor(2.1363, grad_fn=<NllLossBackward0>)
tensor(2.2126, grad_fn=<NllLossBackward0>)
tensor(2.3118, grad_fn=<NllLossBackward0>)
tensor(2.1331, grad_fn=<NllLossBackward0>)
tensor(2.1934, grad_fn=<NllLossBackward0>)
tensor(2.2015, grad_fn=<NllLossBackward0>)
tensor(2.1076, grad_fn=<NllLossBackward0>)
tensor(2.1676, grad_fn=<NllLossBackward0>)
tensor(2.2523, grad_fn=<NllLossBackward0>)
tensor(2.0756, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3072: 0.229
tensor(2.3637, grad_fn=<NllLossBackward0>)
tensor(2.2197, grad_fn=<NllLossBackward0>)
tensor(2.2561, grad_fn=<NllLossBackward0>)
tensor(2.2362, grad_fn=<NllLossBackward0>)
tensor(2.1513, grad_fn=<NllLossBackward0>)
tensor(2.2534, grad_fn=<NllLossBackward0>)
tensor(1.9319, grad_fn=<NllLossBackward0>)
tensor(2.3145, grad_fn=<NllLossBackward0>)
tensor(1.9918, grad_fn=<NllLossBackward0>)
tensor(2.3779, grad_fn=<NllLossBackward0>)
tensor(2.2695, grad_fn=<NllLossBackward0>)
tensor(2.4454, grad_fn=<NllLossBackward0>)
tensor(2.3409, grad_fn=<NllLossBackward0>)
tensor(2.0706, grad_fn=<NllLossBackward0>)
tensor(2.3220, grad_fn=<NllLossBackward0>)
tensor(2.0841, grad_fn=<NllLossBackward0>)
tensor(2.2023, grad_fn=<NllLossBackward0>)
tensor(2.4386, grad_fn=<NllLossBackward0>)
tensor(1.9596, grad_fn=<NllLossBackward0>)
tensor(2.1368, grad_fn=<NllLossBackward0>)
tensor(2.2238, grad_fn=<NllLossBackward0>)
tensor(2.3566, grad_fn=<NllLossBackward0>)
tensor(2.3262, grad_fn=<NllLossBackward0>)
tensor(2.2109, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3096: 0.257
tensor(2.0765, grad_fn=<NllLossBackward0>)
tensor(2.1544, grad_fn=<NllLossBackward0>)
tensor(2.2875, grad_fn=<NllLossBackward0>)
tensor(2.1863, grad_fn=<NllLossBackward0>)
tensor(2.1202, grad_fn=<NllLossBackward0>)
tensor(2.4958, grad_fn=<NllLossBackward0>)
tensor(2.2382, grad_fn=<NllLossBackward0>)
tensor(2.2560, grad_fn=<NllLossBackward0>)
tensor(2.1024, grad_fn=<NllLossBackward0>)
tensor(2.1295, grad_fn=<NllLossBackward0>)
tensor(2.2124, grad_fn=<NllLossBackward0>)
tensor(2.2348, grad_fn=<NllLossBackward0>)
tensor(2.3631, grad_fn=<NllLossBackward0>)
tensor(2.2844, grad_fn=<NllLossBackward0>)
tensor(2.1161, grad_fn=<NllLossBackward0>)
tensor(2.1569, grad_fn=<NllLossBackward0>)
tensor(2.1968, grad_fn=<NllLossBackward0>)
tensor(2.3385, grad_fn=<NllLossBackward0>)
tensor(2.1918, grad_fn=<NllLossBackward0>)
tensor(2.3265, grad_fn=<NllLossBackward0>)
tensor(2.1855, grad_fn=<NllLossBackward0>)
tensor(2.1652, grad_fn=<NllLossBackward0>)
tensor(2.2648, grad_fn=<NllLossBackward0>)
tensor(2.1111, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3120: 0.267
tensor(2.3799, grad_fn=<NllLossBackward0>)
tensor(2.1638, grad_fn=<NllLossBackward0>)
tensor(2.3487, grad_fn=<NllLossBackward0>)
tensor(2.2820, grad_fn=<NllLossBackward0>)
tensor(2.4620, grad_fn=<NllLossBackward0>)
tensor(2.2803, grad_fn=<NllLossBackward0>)
tensor(2.1144, grad_fn=<NllLossBackward0>)
tensor(2.1585, grad_fn=<NllLossBackward0>)
tensor(2.2415, grad_fn=<NllLossBackward0>)
tensor(2.1899, grad_fn=<NllLossBackward0>)
tensor(2.1272, grad_fn=<NllLossBackward0>)
tensor(2.1275, grad_fn=<NllLossBackward0>)
tensor(2.0752, grad_fn=<NllLossBackward0>)
tensor(2.1662, grad_fn=<NllLossBackward0>)
tensor(2.2592, grad_fn=<NllLossBackward0>)
tensor(2.1836, grad_fn=<NllLossBackward0>)
tensor(2.4483, grad_fn=<NllLossBackward0>)
tensor(2.0997, grad_fn=<NllLossBackward0>)
tensor(2.1478, grad_fn=<NllLossBackward0>)
tensor(2.3030, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.2606, grad_fn=<NllLossBackward0>)
tensor(2.0393, grad_fn=<NllLossBackward0>)
tensor(2.1161, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3144: 0.257
tensor(2.2579, grad_fn=<NllLossBackward0>)
tensor(2.4070, grad_fn=<NllLossBackward0>)
tensor(2.2281, grad_fn=<NllLossBackward0>)
tensor(2.1258, grad_fn=<NllLossBackward0>)
tensor(2.2095, grad_fn=<NllLossBackward0>)
tensor(2.0873, grad_fn=<NllLossBackward0>)
tensor(2.0477, grad_fn=<NllLossBackward0>)
tensor(2.1707, grad_fn=<NllLossBackward0>)
tensor(2.2505, grad_fn=<NllLossBackward0>)
tensor(2.1773, grad_fn=<NllLossBackward0>)
tensor(2.1469, grad_fn=<NllLossBackward0>)
tensor(2.3051, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.2719, grad_fn=<NllLossBackward0>)
tensor(2.1122, grad_fn=<NllLossBackward0>)
tensor(2.1385, grad_fn=<NllLossBackward0>)
tensor(2.2801, grad_fn=<NllLossBackward0>)
tensor(2.2921, grad_fn=<NllLossBackward0>)
tensor(1.8039, grad_fn=<NllLossBackward0>)
tensor(2.3815, grad_fn=<NllLossBackward0>)
tensor(2.3015, grad_fn=<NllLossBackward0>)
tensor(2.0346, grad_fn=<NllLossBackward0>)
tensor(2.1611, grad_fn=<NllLossBackward0>)
tensor(2.0506, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3168: 0.262
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.3234, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.1963, grad_fn=<NllLossBackward0>)
tensor(2.1086, grad_fn=<NllLossBackward0>)
tensor(2.3617, grad_fn=<NllLossBackward0>)
tensor(2.1126, grad_fn=<NllLossBackward0>)
tensor(2.2346, grad_fn=<NllLossBackward0>)
tensor(2.1633, grad_fn=<NllLossBackward0>)
tensor(2.0968, grad_fn=<NllLossBackward0>)
tensor(2.2490, grad_fn=<NllLossBackward0>)
tensor(2.3474, grad_fn=<NllLossBackward0>)
tensor(2.1493, grad_fn=<NllLossBackward0>)
tensor(2.3951, grad_fn=<NllLossBackward0>)
tensor(2.1492, grad_fn=<NllLossBackward0>)
tensor(2.2979, grad_fn=<NllLossBackward0>)
tensor(2.2565, grad_fn=<NllLossBackward0>)
tensor(2.0711, grad_fn=<NllLossBackward0>)
tensor(2.2228, grad_fn=<NllLossBackward0>)
tensor(2.2850, grad_fn=<NllLossBackward0>)
tensor(2.0448, grad_fn=<NllLossBackward0>)
tensor(2.0852, grad_fn=<NllLossBackward0>)
tensor(2.1927, grad_fn=<NllLossBackward0>)
tensor(2.3685, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3192: 0.229
tensor(2.0493, grad_fn=<NllLossBackward0>)
tensor(2.3402, grad_fn=<NllLossBackward0>)
tensor(2.2005, grad_fn=<NllLossBackward0>)
tensor(2.1318, grad_fn=<NllLossBackward0>)
tensor(2.0644, grad_fn=<NllLossBackward0>)
tensor(2.0679, grad_fn=<NllLossBackward0>)
tensor(2.0351, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.3007, grad_fn=<NllLossBackward0>)
tensor(2.2816, grad_fn=<NllLossBackward0>)
tensor(2.1390, grad_fn=<NllLossBackward0>)
tensor(2.2137, grad_fn=<NllLossBackward0>)
tensor(2.2951, grad_fn=<NllLossBackward0>)
tensor(2.2081, grad_fn=<NllLossBackward0>)
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.3709, grad_fn=<NllLossBackward0>)
tensor(2.2834, grad_fn=<NllLossBackward0>)
tensor(2.2358, grad_fn=<NllLossBackward0>)
tensor(2.2302, grad_fn=<NllLossBackward0>)
tensor(2.0498, grad_fn=<NllLossBackward0>)
tensor(2.2943, grad_fn=<NllLossBackward0>)
tensor(2.3376, grad_fn=<NllLossBackward0>)
tensor(2.2898, grad_fn=<NllLossBackward0>)
tensor(1.9871, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3216: 0.243
tensor(2.2133, grad_fn=<NllLossBackward0>)
tensor(2.2543, grad_fn=<NllLossBackward0>)
tensor(2.1057, grad_fn=<NllLossBackward0>)
tensor(2.0621, grad_fn=<NllLossBackward0>)
tensor(2.3311, grad_fn=<NllLossBackward0>)
tensor(2.1318, grad_fn=<NllLossBackward0>)
tensor(2.2194, grad_fn=<NllLossBackward0>)
tensor(2.4229, grad_fn=<NllLossBackward0>)
tensor(2.2956, grad_fn=<NllLossBackward0>)
tensor(2.2846, grad_fn=<NllLossBackward0>)
tensor(2.3523, grad_fn=<NllLossBackward0>)
tensor(2.0182, grad_fn=<NllLossBackward0>)
tensor(2.2048, grad_fn=<NllLossBackward0>)
tensor(2.0620, grad_fn=<NllLossBackward0>)
tensor(2.0561, grad_fn=<NllLossBackward0>)
tensor(2.1576, grad_fn=<NllLossBackward0>)
tensor(2.2594, grad_fn=<NllLossBackward0>)
tensor(2.1141, grad_fn=<NllLossBackward0>)
tensor(2.2288, grad_fn=<NllLossBackward0>)
tensor(2.2238, grad_fn=<NllLossBackward0>)
tensor(2.0942, grad_fn=<NllLossBackward0>)
tensor(2.2365, grad_fn=<NllLossBackward0>)
tensor(2.1133, grad_fn=<NllLossBackward0>)
tensor(2.2746, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3240: 0.281
tensor(2.3510, grad_fn=<NllLossBackward0>)
tensor(2.1994, grad_fn=<NllLossBackward0>)
tensor(2.3769, grad_fn=<NllLossBackward0>)
tensor(2.0230, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.2668, grad_fn=<NllLossBackward0>)
tensor(2.2117, grad_fn=<NllLossBackward0>)
tensor(2.3853, grad_fn=<NllLossBackward0>)
tensor(2.3825, grad_fn=<NllLossBackward0>)
tensor(2.2422, grad_fn=<NllLossBackward0>)
tensor(2.3795, grad_fn=<NllLossBackward0>)
tensor(2.1380, grad_fn=<NllLossBackward0>)
tensor(2.1896, grad_fn=<NllLossBackward0>)
tensor(2.1611, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.0846, grad_fn=<NllLossBackward0>)
tensor(2.1525, grad_fn=<NllLossBackward0>)
tensor(2.0901, grad_fn=<NllLossBackward0>)
tensor(2.2463, grad_fn=<NllLossBackward0>)
tensor(2.3019, grad_fn=<NllLossBackward0>)
tensor(2.3519, grad_fn=<NllLossBackward0>)
tensor(2.3160, grad_fn=<NllLossBackward0>)
tensor(2.3898, grad_fn=<NllLossBackward0>)
tensor(2.2718, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3264: 0.227
tensor(2.1788, grad_fn=<NllLossBackward0>)
tensor(2.3415, grad_fn=<NllLossBackward0>)
tensor(1.9555, grad_fn=<NllLossBackward0>)
tensor(2.3624, grad_fn=<NllLossBackward0>)
tensor(2.1217, grad_fn=<NllLossBackward0>)
tensor(2.3439, grad_fn=<NllLossBackward0>)
tensor(2.2106, grad_fn=<NllLossBackward0>)
tensor(2.2224, grad_fn=<NllLossBackward0>)
tensor(2.1575, grad_fn=<NllLossBackward0>)
tensor(2.2718, grad_fn=<NllLossBackward0>)
tensor(2.2861, grad_fn=<NllLossBackward0>)
tensor(2.0924, grad_fn=<NllLossBackward0>)
tensor(2.0681, grad_fn=<NllLossBackward0>)
tensor(2.0569, grad_fn=<NllLossBackward0>)
tensor(2.3243, grad_fn=<NllLossBackward0>)
tensor(2.2213, grad_fn=<NllLossBackward0>)
tensor(2.2777, grad_fn=<NllLossBackward0>)
tensor(2.4650, grad_fn=<NllLossBackward0>)
tensor(2.2499, grad_fn=<NllLossBackward0>)
tensor(2.0507, grad_fn=<NllLossBackward0>)
tensor(2.1652, grad_fn=<NllLossBackward0>)
tensor(2.3079, grad_fn=<NllLossBackward0>)
tensor(2.2241, grad_fn=<NllLossBackward0>)
tensor(2.1094, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3288: 0.240
tensor(2.1400, grad_fn=<NllLossBackward0>)
tensor(1.9471, grad_fn=<NllLossBackward0>)
tensor(2.1202, grad_fn=<NllLossBackward0>)
tensor(2.2622, grad_fn=<NllLossBackward0>)
tensor(2.2533, grad_fn=<NllLossBackward0>)
tensor(2.3362, grad_fn=<NllLossBackward0>)
tensor(1.9794, grad_fn=<NllLossBackward0>)
tensor(2.1994, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(2.0208, grad_fn=<NllLossBackward0>)
tensor(2.1022, grad_fn=<NllLossBackward0>)
tensor(2.3507, grad_fn=<NllLossBackward0>)
tensor(2.2963, grad_fn=<NllLossBackward0>)
tensor(2.1979, grad_fn=<NllLossBackward0>)
tensor(2.2699, grad_fn=<NllLossBackward0>)
tensor(2.0646, grad_fn=<NllLossBackward0>)
tensor(2.1664, grad_fn=<NllLossBackward0>)
tensor(2.2363, grad_fn=<NllLossBackward0>)
tensor(2.1012, grad_fn=<NllLossBackward0>)
tensor(2.2586, grad_fn=<NllLossBackward0>)
tensor(2.1886, grad_fn=<NllLossBackward0>)
tensor(2.1901, grad_fn=<NllLossBackward0>)
tensor(2.1969, grad_fn=<NllLossBackward0>)
tensor(2.3353, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3312: 0.241
tensor(2.0942, grad_fn=<NllLossBackward0>)
tensor(2.0963, grad_fn=<NllLossBackward0>)
tensor(2.0993, grad_fn=<NllLossBackward0>)
tensor(2.0469, grad_fn=<NllLossBackward0>)
tensor(2.1302, grad_fn=<NllLossBackward0>)
tensor(2.3594, grad_fn=<NllLossBackward0>)
tensor(2.2148, grad_fn=<NllLossBackward0>)
tensor(2.2977, grad_fn=<NllLossBackward0>)
tensor(2.2205, grad_fn=<NllLossBackward0>)
tensor(2.2673, grad_fn=<NllLossBackward0>)
tensor(2.1856, grad_fn=<NllLossBackward0>)
tensor(2.0926, grad_fn=<NllLossBackward0>)
tensor(2.0650, grad_fn=<NllLossBackward0>)
tensor(2.3056, grad_fn=<NllLossBackward0>)
tensor(2.1551, grad_fn=<NllLossBackward0>)
tensor(2.1073, grad_fn=<NllLossBackward0>)
tensor(2.2458, grad_fn=<NllLossBackward0>)
tensor(2.1167, grad_fn=<NllLossBackward0>)
tensor(2.2140, grad_fn=<NllLossBackward0>)
tensor(2.2107, grad_fn=<NllLossBackward0>)
tensor(2.3061, grad_fn=<NllLossBackward0>)
tensor(2.0063, grad_fn=<NllLossBackward0>)
tensor(2.0725, grad_fn=<NllLossBackward0>)
tensor(2.1343, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3336: 0.247
tensor(2.2184, grad_fn=<NllLossBackward0>)
tensor(2.0247, grad_fn=<NllLossBackward0>)
tensor(2.0495, grad_fn=<NllLossBackward0>)
tensor(2.1895, grad_fn=<NllLossBackward0>)
tensor(2.4329, grad_fn=<NllLossBackward0>)
tensor(2.1391, grad_fn=<NllLossBackward0>)
tensor(2.2990, grad_fn=<NllLossBackward0>)
tensor(2.1804, grad_fn=<NllLossBackward0>)
tensor(2.4199, grad_fn=<NllLossBackward0>)
tensor(2.1938, grad_fn=<NllLossBackward0>)
tensor(2.0412, grad_fn=<NllLossBackward0>)
tensor(2.3141, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.3852, grad_fn=<NllLossBackward0>)
tensor(2.1709, grad_fn=<NllLossBackward0>)
tensor(2.0605, grad_fn=<NllLossBackward0>)
tensor(2.3337, grad_fn=<NllLossBackward0>)
tensor(2.2815, grad_fn=<NllLossBackward0>)
tensor(2.2485, grad_fn=<NllLossBackward0>)
tensor(2.1331, grad_fn=<NllLossBackward0>)
tensor(2.2724, grad_fn=<NllLossBackward0>)
tensor(2.1404, grad_fn=<NllLossBackward0>)
tensor(2.1987, grad_fn=<NllLossBackward0>)
tensor(2.2161, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3360: 0.248
tensor(2.2579, grad_fn=<NllLossBackward0>)
tensor(2.1270, grad_fn=<NllLossBackward0>)
tensor(2.2005, grad_fn=<NllLossBackward0>)
tensor(2.3290, grad_fn=<NllLossBackward0>)
tensor(2.2655, grad_fn=<NllLossBackward0>)
tensor(2.2958, grad_fn=<NllLossBackward0>)
tensor(2.0518, grad_fn=<NllLossBackward0>)
tensor(2.1227, grad_fn=<NllLossBackward0>)
tensor(2.3930, grad_fn=<NllLossBackward0>)
tensor(2.0872, grad_fn=<NllLossBackward0>)
tensor(2.2023, grad_fn=<NllLossBackward0>)
tensor(2.0590, grad_fn=<NllLossBackward0>)
tensor(1.9596, grad_fn=<NllLossBackward0>)
tensor(2.2346, grad_fn=<NllLossBackward0>)
tensor(2.1456, grad_fn=<NllLossBackward0>)
tensor(2.2720, grad_fn=<NllLossBackward0>)
tensor(2.0069, grad_fn=<NllLossBackward0>)
tensor(2.1977, grad_fn=<NllLossBackward0>)
tensor(2.1066, grad_fn=<NllLossBackward0>)
tensor(2.2182, grad_fn=<NllLossBackward0>)
tensor(2.1327, grad_fn=<NllLossBackward0>)
tensor(2.3503, grad_fn=<NllLossBackward0>)
tensor(2.0807, grad_fn=<NllLossBackward0>)
tensor(1.9153, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3384: 0.267
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.2013, grad_fn=<NllLossBackward0>)
tensor(2.1922, grad_fn=<NllLossBackward0>)
tensor(2.2557, grad_fn=<NllLossBackward0>)
tensor(1.9180, grad_fn=<NllLossBackward0>)
tensor(2.2990, grad_fn=<NllLossBackward0>)
tensor(2.2962, grad_fn=<NllLossBackward0>)
tensor(2.1525, grad_fn=<NllLossBackward0>)
tensor(2.2522, grad_fn=<NllLossBackward0>)
tensor(2.3878, grad_fn=<NllLossBackward0>)
tensor(2.4076, grad_fn=<NllLossBackward0>)
tensor(2.0053, grad_fn=<NllLossBackward0>)
tensor(2.1679, grad_fn=<NllLossBackward0>)
tensor(2.3950, grad_fn=<NllLossBackward0>)
tensor(2.0809, grad_fn=<NllLossBackward0>)
tensor(2.4144, grad_fn=<NllLossBackward0>)
tensor(2.0726, grad_fn=<NllLossBackward0>)
tensor(2.2830, grad_fn=<NllLossBackward0>)
tensor(2.2950, grad_fn=<NllLossBackward0>)
tensor(2.2173, grad_fn=<NllLossBackward0>)
tensor(2.0281, grad_fn=<NllLossBackward0>)
tensor(2.2258, grad_fn=<NllLossBackward0>)
tensor(2.0996, grad_fn=<NllLossBackward0>)
tensor(2.2769, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3408: 0.240
tensor(2.2143, grad_fn=<NllLossBackward0>)
tensor(2.1638, grad_fn=<NllLossBackward0>)
tensor(2.2751, grad_fn=<NllLossBackward0>)
tensor(2.0080, grad_fn=<NllLossBackward0>)
tensor(2.1492, grad_fn=<NllLossBackward0>)
tensor(2.0610, grad_fn=<NllLossBackward0>)
tensor(2.2618, grad_fn=<NllLossBackward0>)
tensor(2.2988, grad_fn=<NllLossBackward0>)
tensor(1.9050, grad_fn=<NllLossBackward0>)
tensor(1.9661, grad_fn=<NllLossBackward0>)
tensor(2.0919, grad_fn=<NllLossBackward0>)
tensor(2.2964, grad_fn=<NllLossBackward0>)
tensor(2.2767, grad_fn=<NllLossBackward0>)
tensor(2.3172, grad_fn=<NllLossBackward0>)
tensor(1.9819, grad_fn=<NllLossBackward0>)
tensor(2.3269, grad_fn=<NllLossBackward0>)
tensor(2.1937, grad_fn=<NllLossBackward0>)
tensor(2.0850, grad_fn=<NllLossBackward0>)
tensor(2.1782, grad_fn=<NllLossBackward0>)
tensor(2.1374, grad_fn=<NllLossBackward0>)
tensor(2.2295, grad_fn=<NllLossBackward0>)
tensor(2.1444, grad_fn=<NllLossBackward0>)
tensor(2.2200, grad_fn=<NllLossBackward0>)
tensor(2.0122, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3432: 0.292
tensor(2.3486, grad_fn=<NllLossBackward0>)
tensor(2.3043, grad_fn=<NllLossBackward0>)
tensor(1.8452, grad_fn=<NllLossBackward0>)
tensor(2.2098, grad_fn=<NllLossBackward0>)
tensor(2.2241, grad_fn=<NllLossBackward0>)
tensor(2.2323, grad_fn=<NllLossBackward0>)
tensor(2.1671, grad_fn=<NllLossBackward0>)
tensor(2.0697, grad_fn=<NllLossBackward0>)
tensor(2.2838, grad_fn=<NllLossBackward0>)
tensor(2.1979, grad_fn=<NllLossBackward0>)
tensor(2.1404, grad_fn=<NllLossBackward0>)
tensor(2.1937, grad_fn=<NllLossBackward0>)
tensor(2.1541, grad_fn=<NllLossBackward0>)
tensor(2.3035, grad_fn=<NllLossBackward0>)
tensor(2.2115, grad_fn=<NllLossBackward0>)
tensor(2.0796, grad_fn=<NllLossBackward0>)
tensor(2.3351, grad_fn=<NllLossBackward0>)
tensor(2.3000, grad_fn=<NllLossBackward0>)
tensor(2.0498, grad_fn=<NllLossBackward0>)
tensor(2.0993, grad_fn=<NllLossBackward0>)
tensor(2.2614, grad_fn=<NllLossBackward0>)
tensor(2.3171, grad_fn=<NllLossBackward0>)
tensor(2.2489, grad_fn=<NllLossBackward0>)
tensor(2.2583, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3456: 0.255
tensor(2.4308, grad_fn=<NllLossBackward0>)
tensor(2.2399, grad_fn=<NllLossBackward0>)
tensor(2.0522, grad_fn=<NllLossBackward0>)
tensor(2.4426, grad_fn=<NllLossBackward0>)
tensor(2.1258, grad_fn=<NllLossBackward0>)
tensor(2.1473, grad_fn=<NllLossBackward0>)
tensor(2.2099, grad_fn=<NllLossBackward0>)
tensor(2.2538, grad_fn=<NllLossBackward0>)
tensor(2.0574, grad_fn=<NllLossBackward0>)
tensor(2.1586, grad_fn=<NllLossBackward0>)
tensor(2.2451, grad_fn=<NllLossBackward0>)
tensor(2.3834, grad_fn=<NllLossBackward0>)
tensor(2.0350, grad_fn=<NllLossBackward0>)
tensor(2.2060, grad_fn=<NllLossBackward0>)
tensor(2.3336, grad_fn=<NllLossBackward0>)
tensor(2.0998, grad_fn=<NllLossBackward0>)
tensor(2.1355, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.1430, grad_fn=<NllLossBackward0>)
tensor(2.1914, grad_fn=<NllLossBackward0>)
tensor(2.1077, grad_fn=<NllLossBackward0>)
tensor(2.2385, grad_fn=<NllLossBackward0>)
tensor(2.1883, grad_fn=<NllLossBackward0>)
tensor(2.1034, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3480: 0.229
tensor(2.3282, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.4233, grad_fn=<NllLossBackward0>)
tensor(2.2670, grad_fn=<NllLossBackward0>)
tensor(2.2248, grad_fn=<NllLossBackward0>)
tensor(2.0545, grad_fn=<NllLossBackward0>)
tensor(2.1390, grad_fn=<NllLossBackward0>)
tensor(2.0672, grad_fn=<NllLossBackward0>)
tensor(2.2256, grad_fn=<NllLossBackward0>)
tensor(2.1206, grad_fn=<NllLossBackward0>)
tensor(2.3072, grad_fn=<NllLossBackward0>)
tensor(2.1691, grad_fn=<NllLossBackward0>)
tensor(2.0364, grad_fn=<NllLossBackward0>)
tensor(2.0693, grad_fn=<NllLossBackward0>)
tensor(2.2476, grad_fn=<NllLossBackward0>)
tensor(2.2785, grad_fn=<NllLossBackward0>)
tensor(2.2860, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.1751, grad_fn=<NllLossBackward0>)
tensor(2.2500, grad_fn=<NllLossBackward0>)
tensor(2.1573, grad_fn=<NllLossBackward0>)
tensor(2.1433, grad_fn=<NllLossBackward0>)
tensor(2.2186, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3504: 0.219
tensor(2.2032, grad_fn=<NllLossBackward0>)
tensor(2.2816, grad_fn=<NllLossBackward0>)
tensor(2.1977, grad_fn=<NllLossBackward0>)
tensor(2.2309, grad_fn=<NllLossBackward0>)
tensor(2.1119, grad_fn=<NllLossBackward0>)
tensor(2.1901, grad_fn=<NllLossBackward0>)
tensor(2.2664, grad_fn=<NllLossBackward0>)
tensor(2.1980, grad_fn=<NllLossBackward0>)
tensor(2.1075, grad_fn=<NllLossBackward0>)
tensor(2.2194, grad_fn=<NllLossBackward0>)
tensor(1.9423, grad_fn=<NllLossBackward0>)
tensor(2.0849, grad_fn=<NllLossBackward0>)
tensor(2.1967, grad_fn=<NllLossBackward0>)
tensor(2.0231, grad_fn=<NllLossBackward0>)
tensor(2.1193, grad_fn=<NllLossBackward0>)
tensor(2.2033, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(1.9595, grad_fn=<NllLossBackward0>)
tensor(2.2959, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.3568, grad_fn=<NllLossBackward0>)
tensor(2.2759, grad_fn=<NllLossBackward0>)
tensor(2.3053, grad_fn=<NllLossBackward0>)
tensor(2.2387, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3528: 0.280
tensor(2.1216, grad_fn=<NllLossBackward0>)
tensor(2.2230, grad_fn=<NllLossBackward0>)
tensor(2.0594, grad_fn=<NllLossBackward0>)
tensor(2.2504, grad_fn=<NllLossBackward0>)
tensor(2.2410, grad_fn=<NllLossBackward0>)
tensor(2.0105, grad_fn=<NllLossBackward0>)
tensor(1.9127, grad_fn=<NllLossBackward0>)
tensor(2.0718, grad_fn=<NllLossBackward0>)
tensor(2.2679, grad_fn=<NllLossBackward0>)
tensor(1.9378, grad_fn=<NllLossBackward0>)
tensor(2.2904, grad_fn=<NllLossBackward0>)
tensor(2.0863, grad_fn=<NllLossBackward0>)
tensor(1.8951, grad_fn=<NllLossBackward0>)
tensor(2.2395, grad_fn=<NllLossBackward0>)
tensor(2.0260, grad_fn=<NllLossBackward0>)
tensor(1.9300, grad_fn=<NllLossBackward0>)
tensor(2.1690, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(1.9934, grad_fn=<NllLossBackward0>)
tensor(2.2429, grad_fn=<NllLossBackward0>)
tensor(2.1097, grad_fn=<NllLossBackward0>)
tensor(2.2729, grad_fn=<NllLossBackward0>)
tensor(2.0790, grad_fn=<NllLossBackward0>)
tensor(2.1141, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3552: 0.273
tensor(2.3228, grad_fn=<NllLossBackward0>)
tensor(2.3012, grad_fn=<NllLossBackward0>)
tensor(2.2191, grad_fn=<NllLossBackward0>)
tensor(2.1233, grad_fn=<NllLossBackward0>)
tensor(2.0397, grad_fn=<NllLossBackward0>)
tensor(2.0781, grad_fn=<NllLossBackward0>)
tensor(2.2133, grad_fn=<NllLossBackward0>)
tensor(2.1990, grad_fn=<NllLossBackward0>)
tensor(2.2106, grad_fn=<NllLossBackward0>)
tensor(2.3666, grad_fn=<NllLossBackward0>)
tensor(2.1650, grad_fn=<NllLossBackward0>)
tensor(2.0686, grad_fn=<NllLossBackward0>)
tensor(2.1829, grad_fn=<NllLossBackward0>)
tensor(2.1273, grad_fn=<NllLossBackward0>)
tensor(2.0965, grad_fn=<NllLossBackward0>)
tensor(2.1242, grad_fn=<NllLossBackward0>)
tensor(2.3308, grad_fn=<NllLossBackward0>)
tensor(2.2327, grad_fn=<NllLossBackward0>)
tensor(1.8629, grad_fn=<NllLossBackward0>)
tensor(2.2174, grad_fn=<NllLossBackward0>)
tensor(1.8875, grad_fn=<NllLossBackward0>)
tensor(1.9411, grad_fn=<NllLossBackward0>)
tensor(2.3420, grad_fn=<NllLossBackward0>)
tensor(1.9812, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3576: 0.269
tensor(2.2429, grad_fn=<NllLossBackward0>)
tensor(2.0491, grad_fn=<NllLossBackward0>)
tensor(2.0174, grad_fn=<NllLossBackward0>)
tensor(2.1014, grad_fn=<NllLossBackward0>)
tensor(2.2827, grad_fn=<NllLossBackward0>)
tensor(2.1657, grad_fn=<NllLossBackward0>)
tensor(2.4382, grad_fn=<NllLossBackward0>)
tensor(2.3559, grad_fn=<NllLossBackward0>)
tensor(2.2608, grad_fn=<NllLossBackward0>)
tensor(2.0166, grad_fn=<NllLossBackward0>)
tensor(2.0965, grad_fn=<NllLossBackward0>)
tensor(2.0655, grad_fn=<NllLossBackward0>)
tensor(2.0268, grad_fn=<NllLossBackward0>)
tensor(2.0913, grad_fn=<NllLossBackward0>)
tensor(2.2885, grad_fn=<NllLossBackward0>)
tensor(2.1390, grad_fn=<NllLossBackward0>)
tensor(2.1294, grad_fn=<NllLossBackward0>)
tensor(2.1636, grad_fn=<NllLossBackward0>)
tensor(2.1124, grad_fn=<NllLossBackward0>)
tensor(2.3378, grad_fn=<NllLossBackward0>)
tensor(2.4119, grad_fn=<NllLossBackward0>)
tensor(2.1203, grad_fn=<NllLossBackward0>)
tensor(2.4385, grad_fn=<NllLossBackward0>)
tensor(2.1765, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3600: 0.250
tensor(2.1953, grad_fn=<NllLossBackward0>)
tensor(2.2192, grad_fn=<NllLossBackward0>)
tensor(1.9927, grad_fn=<NllLossBackward0>)
tensor(2.2293, grad_fn=<NllLossBackward0>)
tensor(2.3063, grad_fn=<NllLossBackward0>)
tensor(1.9767, grad_fn=<NllLossBackward0>)
tensor(2.2554, grad_fn=<NllLossBackward0>)
tensor(2.1424, grad_fn=<NllLossBackward0>)
tensor(2.1974, grad_fn=<NllLossBackward0>)
tensor(2.0969, grad_fn=<NllLossBackward0>)
tensor(2.1703, grad_fn=<NllLossBackward0>)
tensor(2.1919, grad_fn=<NllLossBackward0>)
tensor(2.2061, grad_fn=<NllLossBackward0>)
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.1102, grad_fn=<NllLossBackward0>)
tensor(2.1918, grad_fn=<NllLossBackward0>)
tensor(2.2564, grad_fn=<NllLossBackward0>)
tensor(2.1908, grad_fn=<NllLossBackward0>)
tensor(2.1957, grad_fn=<NllLossBackward0>)
tensor(2.0898, grad_fn=<NllLossBackward0>)
tensor(2.3540, grad_fn=<NllLossBackward0>)
tensor(2.1697, grad_fn=<NllLossBackward0>)
tensor(2.2214, grad_fn=<NllLossBackward0>)
tensor(2.3730, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3624: 0.236
tensor(2.1732, grad_fn=<NllLossBackward0>)
tensor(2.2617, grad_fn=<NllLossBackward0>)
tensor(2.2580, grad_fn=<NllLossBackward0>)
tensor(2.1922, grad_fn=<NllLossBackward0>)
tensor(2.2534, grad_fn=<NllLossBackward0>)
tensor(2.2111, grad_fn=<NllLossBackward0>)
tensor(2.3479, grad_fn=<NllLossBackward0>)
tensor(2.1728, grad_fn=<NllLossBackward0>)
tensor(2.0152, grad_fn=<NllLossBackward0>)
tensor(1.9606, grad_fn=<NllLossBackward0>)
tensor(2.3104, grad_fn=<NllLossBackward0>)
tensor(2.1015, grad_fn=<NllLossBackward0>)
tensor(2.2436, grad_fn=<NllLossBackward0>)
tensor(1.9584, grad_fn=<NllLossBackward0>)
tensor(2.1352, grad_fn=<NllLossBackward0>)
tensor(2.0873, grad_fn=<NllLossBackward0>)
tensor(2.4349, grad_fn=<NllLossBackward0>)
tensor(2.2112, grad_fn=<NllLossBackward0>)
tensor(2.2024, grad_fn=<NllLossBackward0>)
tensor(2.1064, grad_fn=<NllLossBackward0>)
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(2.1068, grad_fn=<NllLossBackward0>)
tensor(2.1279, grad_fn=<NllLossBackward0>)
tensor(2.3036, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3648: 0.252
tensor(2.0522, grad_fn=<NllLossBackward0>)
tensor(2.2063, grad_fn=<NllLossBackward0>)
tensor(2.1574, grad_fn=<NllLossBackward0>)
tensor(2.1650, grad_fn=<NllLossBackward0>)
tensor(2.2551, grad_fn=<NllLossBackward0>)
tensor(2.1613, grad_fn=<NllLossBackward0>)
tensor(1.9669, grad_fn=<NllLossBackward0>)
tensor(2.2444, grad_fn=<NllLossBackward0>)
tensor(2.1502, grad_fn=<NllLossBackward0>)
tensor(2.2051, grad_fn=<NllLossBackward0>)
tensor(2.2014, grad_fn=<NllLossBackward0>)
tensor(2.3800, grad_fn=<NllLossBackward0>)
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.1499, grad_fn=<NllLossBackward0>)
tensor(2.2207, grad_fn=<NllLossBackward0>)
tensor(2.1792, grad_fn=<NllLossBackward0>)
tensor(2.2873, grad_fn=<NllLossBackward0>)
tensor(2.1881, grad_fn=<NllLossBackward0>)
tensor(2.1818, grad_fn=<NllLossBackward0>)
tensor(2.2258, grad_fn=<NllLossBackward0>)
tensor(2.0868, grad_fn=<NllLossBackward0>)
tensor(2.1639, grad_fn=<NllLossBackward0>)
tensor(2.2674, grad_fn=<NllLossBackward0>)
tensor(2.2391, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3672: 0.233
tensor(2.1621, grad_fn=<NllLossBackward0>)
tensor(2.2127, grad_fn=<NllLossBackward0>)
tensor(2.2523, grad_fn=<NllLossBackward0>)
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(2.4067, grad_fn=<NllLossBackward0>)
tensor(2.0101, grad_fn=<NllLossBackward0>)
tensor(2.1921, grad_fn=<NllLossBackward0>)
tensor(2.1358, grad_fn=<NllLossBackward0>)
tensor(2.1757, grad_fn=<NllLossBackward0>)
tensor(2.3899, grad_fn=<NllLossBackward0>)
tensor(2.2028, grad_fn=<NllLossBackward0>)
tensor(2.1127, grad_fn=<NllLossBackward0>)
tensor(2.2337, grad_fn=<NllLossBackward0>)
tensor(2.2316, grad_fn=<NllLossBackward0>)
tensor(2.2349, grad_fn=<NllLossBackward0>)
tensor(2.0596, grad_fn=<NllLossBackward0>)
tensor(2.2376, grad_fn=<NllLossBackward0>)
tensor(2.1734, grad_fn=<NllLossBackward0>)
tensor(2.1646, grad_fn=<NllLossBackward0>)
tensor(2.1495, grad_fn=<NllLossBackward0>)
tensor(2.0653, grad_fn=<NllLossBackward0>)
tensor(2.1223, grad_fn=<NllLossBackward0>)
tensor(1.9413, grad_fn=<NllLossBackward0>)
tensor(2.2610, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3696: 0.233
tensor(2.2900, grad_fn=<NllLossBackward0>)
tensor(2.0742, grad_fn=<NllLossBackward0>)
tensor(2.3490, grad_fn=<NllLossBackward0>)
tensor(2.1573, grad_fn=<NllLossBackward0>)
tensor(2.3458, grad_fn=<NllLossBackward0>)
tensor(2.1647, grad_fn=<NllLossBackward0>)
tensor(2.2939, grad_fn=<NllLossBackward0>)
tensor(2.1955, grad_fn=<NllLossBackward0>)
tensor(2.4067, grad_fn=<NllLossBackward0>)
tensor(2.2156, grad_fn=<NllLossBackward0>)
tensor(2.3385, grad_fn=<NllLossBackward0>)
tensor(2.1039, grad_fn=<NllLossBackward0>)
tensor(2.2115, grad_fn=<NllLossBackward0>)
tensor(2.0882, grad_fn=<NllLossBackward0>)
tensor(2.1909, grad_fn=<NllLossBackward0>)
tensor(2.1985, grad_fn=<NllLossBackward0>)
tensor(2.2513, grad_fn=<NllLossBackward0>)
tensor(2.1685, grad_fn=<NllLossBackward0>)
tensor(2.1725, grad_fn=<NllLossBackward0>)
tensor(2.2353, grad_fn=<NllLossBackward0>)
tensor(2.1124, grad_fn=<NllLossBackward0>)
tensor(2.0906, grad_fn=<NllLossBackward0>)
tensor(2.2498, grad_fn=<NllLossBackward0>)
tensor(2.1615, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3720: 0.267
tensor(2.2099, grad_fn=<NllLossBackward0>)
tensor(2.3218, grad_fn=<NllLossBackward0>)
tensor(2.1126, grad_fn=<NllLossBackward0>)
tensor(2.1283, grad_fn=<NllLossBackward0>)
tensor(2.0686, grad_fn=<NllLossBackward0>)
tensor(2.0605, grad_fn=<NllLossBackward0>)
tensor(2.2649, grad_fn=<NllLossBackward0>)
tensor(2.1584, grad_fn=<NllLossBackward0>)
tensor(2.2883, grad_fn=<NllLossBackward0>)
tensor(1.9905, grad_fn=<NllLossBackward0>)
tensor(2.1430, grad_fn=<NllLossBackward0>)
tensor(2.1484, grad_fn=<NllLossBackward0>)
tensor(2.2790, grad_fn=<NllLossBackward0>)
tensor(2.2439, grad_fn=<NllLossBackward0>)
tensor(2.1401, grad_fn=<NllLossBackward0>)
tensor(2.1391, grad_fn=<NllLossBackward0>)
tensor(2.1564, grad_fn=<NllLossBackward0>)
tensor(2.0984, grad_fn=<NllLossBackward0>)
tensor(2.0671, grad_fn=<NllLossBackward0>)
tensor(2.1127, grad_fn=<NllLossBackward0>)
tensor(2.3257, grad_fn=<NllLossBackward0>)
tensor(2.2140, grad_fn=<NllLossBackward0>)
tensor(2.1453, grad_fn=<NllLossBackward0>)
tensor(2.2777, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3744: 0.266
tensor(2.2262, grad_fn=<NllLossBackward0>)
tensor(2.3204, grad_fn=<NllLossBackward0>)
tensor(2.4628, grad_fn=<NllLossBackward0>)
tensor(2.1006, grad_fn=<NllLossBackward0>)
tensor(2.0458, grad_fn=<NllLossBackward0>)
tensor(2.2799, grad_fn=<NllLossBackward0>)
tensor(2.2628, grad_fn=<NllLossBackward0>)
tensor(2.2576, grad_fn=<NllLossBackward0>)
tensor(2.1956, grad_fn=<NllLossBackward0>)
tensor(2.2249, grad_fn=<NllLossBackward0>)
tensor(2.3951, grad_fn=<NllLossBackward0>)
tensor(2.1179, grad_fn=<NllLossBackward0>)
tensor(2.0425, grad_fn=<NllLossBackward0>)
tensor(2.2684, grad_fn=<NllLossBackward0>)
tensor(2.1889, grad_fn=<NllLossBackward0>)
tensor(2.3190, grad_fn=<NllLossBackward0>)
tensor(2.3757, grad_fn=<NllLossBackward0>)
tensor(2.2450, grad_fn=<NllLossBackward0>)
tensor(2.2876, grad_fn=<NllLossBackward0>)
tensor(2.2147, grad_fn=<NllLossBackward0>)
tensor(2.1451, grad_fn=<NllLossBackward0>)
tensor(2.1405, grad_fn=<NllLossBackward0>)
tensor(2.1405, grad_fn=<NllLossBackward0>)
tensor(2.0927, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3768: 0.214
tensor(1.9811, grad_fn=<NllLossBackward0>)
tensor(2.1814, grad_fn=<NllLossBackward0>)
tensor(2.2473, grad_fn=<NllLossBackward0>)
tensor(2.3465, grad_fn=<NllLossBackward0>)
tensor(2.1476, grad_fn=<NllLossBackward0>)
tensor(2.0444, grad_fn=<NllLossBackward0>)
tensor(2.1590, grad_fn=<NllLossBackward0>)
tensor(2.1003, grad_fn=<NllLossBackward0>)
tensor(2.0527, grad_fn=<NllLossBackward0>)
tensor(2.1710, grad_fn=<NllLossBackward0>)
tensor(2.2028, grad_fn=<NllLossBackward0>)
tensor(2.1823, grad_fn=<NllLossBackward0>)
tensor(2.0856, grad_fn=<NllLossBackward0>)
tensor(2.0755, grad_fn=<NllLossBackward0>)
tensor(2.0610, grad_fn=<NllLossBackward0>)
tensor(2.1274, grad_fn=<NllLossBackward0>)
tensor(2.1934, grad_fn=<NllLossBackward0>)
tensor(2.3411, grad_fn=<NllLossBackward0>)
tensor(2.1931, grad_fn=<NllLossBackward0>)
tensor(2.1057, grad_fn=<NllLossBackward0>)
tensor(1.7888, grad_fn=<NllLossBackward0>)
tensor(2.2083, grad_fn=<NllLossBackward0>)
tensor(2.0837, grad_fn=<NllLossBackward0>)
tensor(2.2018, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3792: 0.283
tensor(2.2655, grad_fn=<NllLossBackward0>)
tensor(2.2600, grad_fn=<NllLossBackward0>)
tensor(2.1659, grad_fn=<NllLossBackward0>)
tensor(1.9729, grad_fn=<NllLossBackward0>)
tensor(1.9993, grad_fn=<NllLossBackward0>)
tensor(2.1742, grad_fn=<NllLossBackward0>)
tensor(2.3462, grad_fn=<NllLossBackward0>)
tensor(2.1772, grad_fn=<NllLossBackward0>)
tensor(2.0962, grad_fn=<NllLossBackward0>)
tensor(2.1787, grad_fn=<NllLossBackward0>)
tensor(2.0034, grad_fn=<NllLossBackward0>)
tensor(2.0411, grad_fn=<NllLossBackward0>)
tensor(2.1707, grad_fn=<NllLossBackward0>)
tensor(2.3992, grad_fn=<NllLossBackward0>)
tensor(2.0674, grad_fn=<NllLossBackward0>)
tensor(2.2425, grad_fn=<NllLossBackward0>)
tensor(2.1141, grad_fn=<NllLossBackward0>)
tensor(2.3766, grad_fn=<NllLossBackward0>)
tensor(2.1082, grad_fn=<NllLossBackward0>)
tensor(2.1688, grad_fn=<NllLossBackward0>)
tensor(2.2218, grad_fn=<NllLossBackward0>)
tensor(2.1302, grad_fn=<NllLossBackward0>)
tensor(2.4290, grad_fn=<NllLossBackward0>)
tensor(2.2006, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3816: 0.257
tensor(2.2154, grad_fn=<NllLossBackward0>)
tensor(2.0769, grad_fn=<NllLossBackward0>)
tensor(2.2247, grad_fn=<NllLossBackward0>)
tensor(2.2325, grad_fn=<NllLossBackward0>)
tensor(1.9514, grad_fn=<NllLossBackward0>)
tensor(2.2471, grad_fn=<NllLossBackward0>)
tensor(2.1344, grad_fn=<NllLossBackward0>)
tensor(2.2909, grad_fn=<NllLossBackward0>)
tensor(2.0318, grad_fn=<NllLossBackward0>)
tensor(1.9884, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.1565, grad_fn=<NllLossBackward0>)
tensor(2.1963, grad_fn=<NllLossBackward0>)
tensor(2.2039, grad_fn=<NllLossBackward0>)
tensor(2.1305, grad_fn=<NllLossBackward0>)
tensor(2.2879, grad_fn=<NllLossBackward0>)
tensor(2.2100, grad_fn=<NllLossBackward0>)
tensor(2.1510, grad_fn=<NllLossBackward0>)
tensor(2.2690, grad_fn=<NllLossBackward0>)
tensor(2.0574, grad_fn=<NllLossBackward0>)
tensor(2.1917, grad_fn=<NllLossBackward0>)
tensor(2.2716, grad_fn=<NllLossBackward0>)
tensor(2.3379, grad_fn=<NllLossBackward0>)
tensor(2.2228, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3840: 0.240
tensor(2.3187, grad_fn=<NllLossBackward0>)
tensor(2.2384, grad_fn=<NllLossBackward0>)
tensor(2.2241, grad_fn=<NllLossBackward0>)
tensor(2.0804, grad_fn=<NllLossBackward0>)
tensor(2.2612, grad_fn=<NllLossBackward0>)
tensor(2.0732, grad_fn=<NllLossBackward0>)
tensor(2.2650, grad_fn=<NllLossBackward0>)
tensor(2.1803, grad_fn=<NllLossBackward0>)
tensor(2.0566, grad_fn=<NllLossBackward0>)
tensor(2.1705, grad_fn=<NllLossBackward0>)
tensor(2.2205, grad_fn=<NllLossBackward0>)
tensor(2.1600, grad_fn=<NllLossBackward0>)
tensor(2.2266, grad_fn=<NllLossBackward0>)
tensor(2.4297, grad_fn=<NllLossBackward0>)
tensor(2.0249, grad_fn=<NllLossBackward0>)
tensor(2.0495, grad_fn=<NllLossBackward0>)
tensor(1.9849, grad_fn=<NllLossBackward0>)
tensor(2.3179, grad_fn=<NllLossBackward0>)
tensor(2.1855, grad_fn=<NllLossBackward0>)
tensor(2.1297, grad_fn=<NllLossBackward0>)
tensor(2.1005, grad_fn=<NllLossBackward0>)
tensor(2.0856, grad_fn=<NllLossBackward0>)
tensor(2.2635, grad_fn=<NllLossBackward0>)
tensor(2.2322, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3864: 0.288
tensor(1.9794, grad_fn=<NllLossBackward0>)
tensor(2.3015, grad_fn=<NllLossBackward0>)
tensor(2.1931, grad_fn=<NllLossBackward0>)
tensor(2.2472, grad_fn=<NllLossBackward0>)
tensor(2.1642, grad_fn=<NllLossBackward0>)
tensor(2.3586, grad_fn=<NllLossBackward0>)
tensor(2.2136, grad_fn=<NllLossBackward0>)
tensor(2.1436, grad_fn=<NllLossBackward0>)
tensor(2.3039, grad_fn=<NllLossBackward0>)
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.2755, grad_fn=<NllLossBackward0>)
tensor(2.0241, grad_fn=<NllLossBackward0>)
tensor(2.1402, grad_fn=<NllLossBackward0>)
tensor(1.9778, grad_fn=<NllLossBackward0>)
tensor(2.0478, grad_fn=<NllLossBackward0>)
tensor(2.3311, grad_fn=<NllLossBackward0>)
tensor(2.0770, grad_fn=<NllLossBackward0>)
tensor(2.0832, grad_fn=<NllLossBackward0>)
tensor(2.0818, grad_fn=<NllLossBackward0>)
tensor(2.0833, grad_fn=<NllLossBackward0>)
tensor(2.1610, grad_fn=<NllLossBackward0>)
tensor(2.1411, grad_fn=<NllLossBackward0>)
tensor(2.2107, grad_fn=<NllLossBackward0>)
tensor(2.1486, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3888: 0.269
tensor(2.1731, grad_fn=<NllLossBackward0>)
tensor(2.2803, grad_fn=<NllLossBackward0>)
tensor(2.1149, grad_fn=<NllLossBackward0>)
tensor(2.0997, grad_fn=<NllLossBackward0>)
tensor(2.1250, grad_fn=<NllLossBackward0>)
tensor(2.2771, grad_fn=<NllLossBackward0>)
tensor(2.1651, grad_fn=<NllLossBackward0>)
tensor(2.0175, grad_fn=<NllLossBackward0>)
tensor(2.2236, grad_fn=<NllLossBackward0>)
tensor(2.1240, grad_fn=<NllLossBackward0>)
tensor(1.9079, grad_fn=<NllLossBackward0>)
tensor(2.2958, grad_fn=<NllLossBackward0>)
tensor(2.3043, grad_fn=<NllLossBackward0>)
tensor(2.2548, grad_fn=<NllLossBackward0>)
tensor(2.2188, grad_fn=<NllLossBackward0>)
tensor(1.9897, grad_fn=<NllLossBackward0>)
tensor(2.1488, grad_fn=<NllLossBackward0>)
tensor(2.2071, grad_fn=<NllLossBackward0>)
tensor(2.1422, grad_fn=<NllLossBackward0>)
tensor(2.1655, grad_fn=<NllLossBackward0>)
tensor(2.1819, grad_fn=<NllLossBackward0>)
tensor(2.3225, grad_fn=<NllLossBackward0>)
tensor(2.1584, grad_fn=<NllLossBackward0>)
tensor(2.3577, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3912: 0.253
tensor(2.1941, grad_fn=<NllLossBackward0>)
tensor(2.1059, grad_fn=<NllLossBackward0>)
tensor(2.1336, grad_fn=<NllLossBackward0>)
tensor(2.2903, grad_fn=<NllLossBackward0>)
tensor(2.2537, grad_fn=<NllLossBackward0>)
tensor(2.2564, grad_fn=<NllLossBackward0>)
tensor(2.2354, grad_fn=<NllLossBackward0>)
tensor(2.1383, grad_fn=<NllLossBackward0>)
tensor(2.2539, grad_fn=<NllLossBackward0>)
tensor(2.0089, grad_fn=<NllLossBackward0>)
tensor(2.1550, grad_fn=<NllLossBackward0>)
tensor(2.1763, grad_fn=<NllLossBackward0>)
tensor(2.2871, grad_fn=<NllLossBackward0>)
tensor(2.0224, grad_fn=<NllLossBackward0>)
tensor(2.0156, grad_fn=<NllLossBackward0>)
tensor(2.1564, grad_fn=<NllLossBackward0>)
tensor(2.1263, grad_fn=<NllLossBackward0>)
tensor(2.0493, grad_fn=<NllLossBackward0>)
tensor(2.1367, grad_fn=<NllLossBackward0>)
tensor(2.1488, grad_fn=<NllLossBackward0>)
tensor(2.1707, grad_fn=<NllLossBackward0>)
tensor(1.9818, grad_fn=<NllLossBackward0>)
tensor(2.2421, grad_fn=<NllLossBackward0>)
tensor(2.1439, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3936: 0.276
tensor(2.1588, grad_fn=<NllLossBackward0>)
tensor(2.1284, grad_fn=<NllLossBackward0>)
tensor(2.0955, grad_fn=<NllLossBackward0>)
tensor(2.2189, grad_fn=<NllLossBackward0>)
tensor(2.1684, grad_fn=<NllLossBackward0>)
tensor(2.2236, grad_fn=<NllLossBackward0>)
tensor(2.2829, grad_fn=<NllLossBackward0>)
tensor(2.2943, grad_fn=<NllLossBackward0>)
tensor(2.1392, grad_fn=<NllLossBackward0>)
tensor(2.0742, grad_fn=<NllLossBackward0>)
tensor(2.0645, grad_fn=<NllLossBackward0>)
tensor(2.0871, grad_fn=<NllLossBackward0>)
tensor(2.1555, grad_fn=<NllLossBackward0>)
tensor(2.1461, grad_fn=<NllLossBackward0>)
tensor(2.2863, grad_fn=<NllLossBackward0>)
tensor(1.9183, grad_fn=<NllLossBackward0>)
tensor(2.2350, grad_fn=<NllLossBackward0>)
tensor(2.2690, grad_fn=<NllLossBackward0>)
tensor(2.1291, grad_fn=<NllLossBackward0>)
tensor(2.2152, grad_fn=<NllLossBackward0>)
tensor(2.0991, grad_fn=<NllLossBackward0>)
tensor(2.4881, grad_fn=<NllLossBackward0>)
tensor(2.1033, grad_fn=<NllLossBackward0>)
tensor(2.2448, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3960: 0.257
tensor(2.0583, grad_fn=<NllLossBackward0>)
tensor(1.8916, grad_fn=<NllLossBackward0>)
tensor(2.1880, grad_fn=<NllLossBackward0>)
tensor(1.9422, grad_fn=<NllLossBackward0>)
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.1722, grad_fn=<NllLossBackward0>)
tensor(2.1650, grad_fn=<NllLossBackward0>)
tensor(2.2243, grad_fn=<NllLossBackward0>)
tensor(2.1844, grad_fn=<NllLossBackward0>)
tensor(2.1375, grad_fn=<NllLossBackward0>)
tensor(2.3878, grad_fn=<NllLossBackward0>)
tensor(1.9527, grad_fn=<NllLossBackward0>)
tensor(2.0934, grad_fn=<NllLossBackward0>)
tensor(2.2694, grad_fn=<NllLossBackward0>)
tensor(2.2999, grad_fn=<NllLossBackward0>)
tensor(1.9781, grad_fn=<NllLossBackward0>)
tensor(2.1075, grad_fn=<NllLossBackward0>)
tensor(2.3451, grad_fn=<NllLossBackward0>)
tensor(2.1063, grad_fn=<NllLossBackward0>)
tensor(2.2546, grad_fn=<NllLossBackward0>)
tensor(2.3178, grad_fn=<NllLossBackward0>)
tensor(2.1007, grad_fn=<NllLossBackward0>)
tensor(2.1390, grad_fn=<NllLossBackward0>)
tensor(2.4548, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  3984: 0.273
tensor(2.2491, grad_fn=<NllLossBackward0>)
tensor(2.1040, grad_fn=<NllLossBackward0>)
tensor(2.3099, grad_fn=<NllLossBackward0>)
tensor(2.1831, grad_fn=<NllLossBackward0>)
tensor(2.1580, grad_fn=<NllLossBackward0>)
tensor(2.0673, grad_fn=<NllLossBackward0>)
tensor(2.3146, grad_fn=<NllLossBackward0>)
tensor(2.0210, grad_fn=<NllLossBackward0>)
tensor(1.9790, grad_fn=<NllLossBackward0>)
tensor(2.2079, grad_fn=<NllLossBackward0>)
tensor(2.1937, grad_fn=<NllLossBackward0>)
tensor(2.1393, grad_fn=<NllLossBackward0>)
tensor(2.1518, grad_fn=<NllLossBackward0>)
tensor(2.1281, grad_fn=<NllLossBackward0>)
tensor(2.1125, grad_fn=<NllLossBackward0>)
tensor(2.2289, grad_fn=<NllLossBackward0>)
tensor(2.0119, grad_fn=<NllLossBackward0>)
tensor(2.0553, grad_fn=<NllLossBackward0>)
tensor(2.4708, grad_fn=<NllLossBackward0>)
tensor(2.2361, grad_fn=<NllLossBackward0>)
tensor(2.0098, grad_fn=<NllLossBackward0>)
tensor(2.2136, grad_fn=<NllLossBackward0>)
tensor(2.2431, grad_fn=<NllLossBackward0>)
tensor(2.3377, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4008: 0.227
tensor(2.1254, grad_fn=<NllLossBackward0>)
tensor(2.2146, grad_fn=<NllLossBackward0>)
tensor(2.2055, grad_fn=<NllLossBackward0>)
tensor(2.3513, grad_fn=<NllLossBackward0>)
tensor(1.9330, grad_fn=<NllLossBackward0>)
tensor(2.1213, grad_fn=<NllLossBackward0>)
tensor(2.1287, grad_fn=<NllLossBackward0>)
tensor(2.3223, grad_fn=<NllLossBackward0>)
tensor(2.1122, grad_fn=<NllLossBackward0>)
tensor(1.9694, grad_fn=<NllLossBackward0>)
tensor(2.0854, grad_fn=<NllLossBackward0>)
tensor(2.0650, grad_fn=<NllLossBackward0>)
tensor(2.2551, grad_fn=<NllLossBackward0>)
tensor(2.0312, grad_fn=<NllLossBackward0>)
tensor(2.2222, grad_fn=<NllLossBackward0>)
tensor(2.2484, grad_fn=<NllLossBackward0>)
tensor(1.9732, grad_fn=<NllLossBackward0>)
tensor(2.2322, grad_fn=<NllLossBackward0>)
tensor(2.1312, grad_fn=<NllLossBackward0>)
tensor(2.3804, grad_fn=<NllLossBackward0>)
tensor(2.1683, grad_fn=<NllLossBackward0>)
tensor(2.0910, grad_fn=<NllLossBackward0>)
tensor(2.0270, grad_fn=<NllLossBackward0>)
tensor(2.1536, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4032: 0.260
tensor(2.1841, grad_fn=<NllLossBackward0>)
tensor(1.9929, grad_fn=<NllLossBackward0>)
tensor(2.2654, grad_fn=<NllLossBackward0>)
tensor(2.3893, grad_fn=<NllLossBackward0>)
tensor(2.4011, grad_fn=<NllLossBackward0>)
tensor(2.1612, grad_fn=<NllLossBackward0>)
tensor(2.1966, grad_fn=<NllLossBackward0>)
tensor(2.1495, grad_fn=<NllLossBackward0>)
tensor(1.9938, grad_fn=<NllLossBackward0>)
tensor(2.2699, grad_fn=<NllLossBackward0>)
tensor(2.2317, grad_fn=<NllLossBackward0>)
tensor(2.1325, grad_fn=<NllLossBackward0>)
tensor(1.9923, grad_fn=<NllLossBackward0>)
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.2005, grad_fn=<NllLossBackward0>)
tensor(2.0390, grad_fn=<NllLossBackward0>)
tensor(2.2557, grad_fn=<NllLossBackward0>)
tensor(2.2796, grad_fn=<NllLossBackward0>)
tensor(2.2295, grad_fn=<NllLossBackward0>)
tensor(2.2048, grad_fn=<NllLossBackward0>)
tensor(2.2816, grad_fn=<NllLossBackward0>)
tensor(2.1995, grad_fn=<NllLossBackward0>)
tensor(2.0776, grad_fn=<NllLossBackward0>)
tensor(2.1922, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4056: 0.245
tensor(2.1154, grad_fn=<NllLossBackward0>)
tensor(2.2698, grad_fn=<NllLossBackward0>)
tensor(2.1080, grad_fn=<NllLossBackward0>)
tensor(2.3919, grad_fn=<NllLossBackward0>)
tensor(2.2446, grad_fn=<NllLossBackward0>)
tensor(1.9797, grad_fn=<NllLossBackward0>)
tensor(2.2964, grad_fn=<NllLossBackward0>)
tensor(2.1517, grad_fn=<NllLossBackward0>)
tensor(2.2449, grad_fn=<NllLossBackward0>)
tensor(2.2369, grad_fn=<NllLossBackward0>)
tensor(2.2197, grad_fn=<NllLossBackward0>)
tensor(2.1236, grad_fn=<NllLossBackward0>)
tensor(2.2125, grad_fn=<NllLossBackward0>)
tensor(2.0674, grad_fn=<NllLossBackward0>)
tensor(2.1914, grad_fn=<NllLossBackward0>)
tensor(2.2093, grad_fn=<NllLossBackward0>)
tensor(2.3275, grad_fn=<NllLossBackward0>)
tensor(2.1987, grad_fn=<NllLossBackward0>)
tensor(1.9914, grad_fn=<NllLossBackward0>)
tensor(2.1379, grad_fn=<NllLossBackward0>)
tensor(2.0871, grad_fn=<NllLossBackward0>)
tensor(2.0580, grad_fn=<NllLossBackward0>)
tensor(2.1728, grad_fn=<NllLossBackward0>)
tensor(2.2444, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4080: 0.229
tensor(2.3495, grad_fn=<NllLossBackward0>)
tensor(2.1650, grad_fn=<NllLossBackward0>)
tensor(2.0260, grad_fn=<NllLossBackward0>)
tensor(2.0978, grad_fn=<NllLossBackward0>)
tensor(2.1356, grad_fn=<NllLossBackward0>)
tensor(2.1898, grad_fn=<NllLossBackward0>)
tensor(2.2500, grad_fn=<NllLossBackward0>)
tensor(1.9374, grad_fn=<NllLossBackward0>)
tensor(2.2338, grad_fn=<NllLossBackward0>)
tensor(2.1429, grad_fn=<NllLossBackward0>)
tensor(1.9956, grad_fn=<NllLossBackward0>)
tensor(2.1843, grad_fn=<NllLossBackward0>)
tensor(2.1924, grad_fn=<NllLossBackward0>)
tensor(2.2639, grad_fn=<NllLossBackward0>)
tensor(2.3620, grad_fn=<NllLossBackward0>)
tensor(1.9780, grad_fn=<NllLossBackward0>)
tensor(2.1528, grad_fn=<NllLossBackward0>)
tensor(2.2005, grad_fn=<NllLossBackward0>)
tensor(2.1733, grad_fn=<NllLossBackward0>)
tensor(2.3377, grad_fn=<NllLossBackward0>)
tensor(2.3447, grad_fn=<NllLossBackward0>)
tensor(2.2422, grad_fn=<NllLossBackward0>)
tensor(2.0711, grad_fn=<NllLossBackward0>)
tensor(2.0808, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4104: 0.234
tensor(2.1820, grad_fn=<NllLossBackward0>)
tensor(2.1796, grad_fn=<NllLossBackward0>)
tensor(2.2871, grad_fn=<NllLossBackward0>)
tensor(2.0701, grad_fn=<NllLossBackward0>)
tensor(2.2439, grad_fn=<NllLossBackward0>)
tensor(2.1574, grad_fn=<NllLossBackward0>)
tensor(2.2485, grad_fn=<NllLossBackward0>)
tensor(2.1301, grad_fn=<NllLossBackward0>)
tensor(2.0457, grad_fn=<NllLossBackward0>)
tensor(2.1625, grad_fn=<NllLossBackward0>)
tensor(2.2023, grad_fn=<NllLossBackward0>)
tensor(2.2685, grad_fn=<NllLossBackward0>)
tensor(2.2903, grad_fn=<NllLossBackward0>)
tensor(2.1961, grad_fn=<NllLossBackward0>)
tensor(2.0676, grad_fn=<NllLossBackward0>)
tensor(2.1996, grad_fn=<NllLossBackward0>)
tensor(2.3143, grad_fn=<NllLossBackward0>)
tensor(1.8537, grad_fn=<NllLossBackward0>)
tensor(2.1554, grad_fn=<NllLossBackward0>)
tensor(2.0880, grad_fn=<NllLossBackward0>)
tensor(2.1939, grad_fn=<NllLossBackward0>)
tensor(2.3897, grad_fn=<NllLossBackward0>)
tensor(2.1757, grad_fn=<NllLossBackward0>)
tensor(1.9409, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4128: 0.252
tensor(2.1796, grad_fn=<NllLossBackward0>)
tensor(2.1129, grad_fn=<NllLossBackward0>)
tensor(2.3084, grad_fn=<NllLossBackward0>)
tensor(2.1650, grad_fn=<NllLossBackward0>)
tensor(2.1424, grad_fn=<NllLossBackward0>)
tensor(2.1820, grad_fn=<NllLossBackward0>)
tensor(2.1876, grad_fn=<NllLossBackward0>)
tensor(2.1720, grad_fn=<NllLossBackward0>)
tensor(2.2195, grad_fn=<NllLossBackward0>)
tensor(2.0790, grad_fn=<NllLossBackward0>)
tensor(2.3154, grad_fn=<NllLossBackward0>)
tensor(2.0207, grad_fn=<NllLossBackward0>)
tensor(2.0021, grad_fn=<NllLossBackward0>)
tensor(2.3815, grad_fn=<NllLossBackward0>)
tensor(2.0731, grad_fn=<NllLossBackward0>)
tensor(2.2719, grad_fn=<NllLossBackward0>)
tensor(2.1373, grad_fn=<NllLossBackward0>)
tensor(2.0498, grad_fn=<NllLossBackward0>)
tensor(2.2215, grad_fn=<NllLossBackward0>)
tensor(2.2658, grad_fn=<NllLossBackward0>)
tensor(2.0664, grad_fn=<NllLossBackward0>)
tensor(2.2300, grad_fn=<NllLossBackward0>)
tensor(2.1072, grad_fn=<NllLossBackward0>)
tensor(2.2164, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4152: 0.273
tensor(2.3202, grad_fn=<NllLossBackward0>)
tensor(2.0278, grad_fn=<NllLossBackward0>)
tensor(2.2214, grad_fn=<NllLossBackward0>)
tensor(2.3000, grad_fn=<NllLossBackward0>)
tensor(1.9908, grad_fn=<NllLossBackward0>)
tensor(2.0219, grad_fn=<NllLossBackward0>)
tensor(2.1337, grad_fn=<NllLossBackward0>)
tensor(2.2377, grad_fn=<NllLossBackward0>)
tensor(2.2311, grad_fn=<NllLossBackward0>)
tensor(1.9662, grad_fn=<NllLossBackward0>)
tensor(2.1844, grad_fn=<NllLossBackward0>)
tensor(2.1279, grad_fn=<NllLossBackward0>)
tensor(2.1422, grad_fn=<NllLossBackward0>)
tensor(2.3436, grad_fn=<NllLossBackward0>)
tensor(2.0488, grad_fn=<NllLossBackward0>)
tensor(2.2768, grad_fn=<NllLossBackward0>)
tensor(2.2855, grad_fn=<NllLossBackward0>)
tensor(2.0915, grad_fn=<NllLossBackward0>)
tensor(2.1592, grad_fn=<NllLossBackward0>)
tensor(2.0906, grad_fn=<NllLossBackward0>)
tensor(2.0709, grad_fn=<NllLossBackward0>)
tensor(2.2098, grad_fn=<NllLossBackward0>)
tensor(2.0799, grad_fn=<NllLossBackward0>)
tensor(2.1763, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4176: 0.266
tensor(1.9976, grad_fn=<NllLossBackward0>)
tensor(2.2916, grad_fn=<NllLossBackward0>)
tensor(2.3031, grad_fn=<NllLossBackward0>)
tensor(1.9106, grad_fn=<NllLossBackward0>)
tensor(1.9524, grad_fn=<NllLossBackward0>)
tensor(2.0760, grad_fn=<NllLossBackward0>)
tensor(2.3273, grad_fn=<NllLossBackward0>)
tensor(2.1389, grad_fn=<NllLossBackward0>)
tensor(2.1601, grad_fn=<NllLossBackward0>)
tensor(2.0937, grad_fn=<NllLossBackward0>)
tensor(2.4063, grad_fn=<NllLossBackward0>)
tensor(2.0334, grad_fn=<NllLossBackward0>)
tensor(2.1132, grad_fn=<NllLossBackward0>)
tensor(2.2722, grad_fn=<NllLossBackward0>)
tensor(1.9538, grad_fn=<NllLossBackward0>)
tensor(2.3070, grad_fn=<NllLossBackward0>)
tensor(2.0816, grad_fn=<NllLossBackward0>)
tensor(2.1227, grad_fn=<NllLossBackward0>)
tensor(2.1797, grad_fn=<NllLossBackward0>)
tensor(2.1015, grad_fn=<NllLossBackward0>)
tensor(2.1341, grad_fn=<NllLossBackward0>)
tensor(2.2012, grad_fn=<NllLossBackward0>)
tensor(2.1962, grad_fn=<NllLossBackward0>)
tensor(2.2441, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4200: 0.226
tensor(2.2552, grad_fn=<NllLossBackward0>)
tensor(2.1965, grad_fn=<NllLossBackward0>)
tensor(2.1044, grad_fn=<NllLossBackward0>)
tensor(2.1443, grad_fn=<NllLossBackward0>)
tensor(2.1455, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
tensor(2.3678, grad_fn=<NllLossBackward0>)
tensor(2.0342, grad_fn=<NllLossBackward0>)
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.1318, grad_fn=<NllLossBackward0>)
tensor(2.1434, grad_fn=<NllLossBackward0>)
tensor(2.1020, grad_fn=<NllLossBackward0>)
tensor(2.1383, grad_fn=<NllLossBackward0>)
tensor(2.2003, grad_fn=<NllLossBackward0>)
tensor(2.1205, grad_fn=<NllLossBackward0>)
tensor(1.9829, grad_fn=<NllLossBackward0>)
tensor(2.1320, grad_fn=<NllLossBackward0>)
tensor(2.1246, grad_fn=<NllLossBackward0>)
tensor(2.1077, grad_fn=<NllLossBackward0>)
tensor(2.0724, grad_fn=<NllLossBackward0>)
tensor(2.0853, grad_fn=<NllLossBackward0>)
tensor(2.2529, grad_fn=<NllLossBackward0>)
tensor(2.1033, grad_fn=<NllLossBackward0>)
tensor(1.9384, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4224: 0.283
tensor(2.4099, grad_fn=<NllLossBackward0>)
tensor(2.2954, grad_fn=<NllLossBackward0>)
tensor(2.1257, grad_fn=<NllLossBackward0>)
tensor(1.9264, grad_fn=<NllLossBackward0>)
tensor(2.1242, grad_fn=<NllLossBackward0>)
tensor(2.0686, grad_fn=<NllLossBackward0>)
tensor(2.1024, grad_fn=<NllLossBackward0>)
tensor(2.1001, grad_fn=<NllLossBackward0>)
tensor(1.9992, grad_fn=<NllLossBackward0>)
tensor(2.3200, grad_fn=<NllLossBackward0>)
tensor(2.1899, grad_fn=<NllLossBackward0>)
tensor(2.0850, grad_fn=<NllLossBackward0>)
tensor(2.0681, grad_fn=<NllLossBackward0>)
tensor(2.1497, grad_fn=<NllLossBackward0>)
tensor(2.1584, grad_fn=<NllLossBackward0>)
tensor(2.1026, grad_fn=<NllLossBackward0>)
tensor(2.2131, grad_fn=<NllLossBackward0>)
tensor(2.2927, grad_fn=<NllLossBackward0>)
tensor(2.0052, grad_fn=<NllLossBackward0>)
tensor(2.0141, grad_fn=<NllLossBackward0>)
tensor(2.0374, grad_fn=<NllLossBackward0>)
tensor(2.0833, grad_fn=<NllLossBackward0>)
tensor(1.9093, grad_fn=<NllLossBackward0>)
tensor(2.2667, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4248: 0.280
tensor(2.2774, grad_fn=<NllLossBackward0>)
tensor(2.2651, grad_fn=<NllLossBackward0>)
tensor(2.3000, grad_fn=<NllLossBackward0>)
tensor(2.0433, grad_fn=<NllLossBackward0>)
tensor(2.2196, grad_fn=<NllLossBackward0>)
tensor(2.0704, grad_fn=<NllLossBackward0>)
tensor(2.2182, grad_fn=<NllLossBackward0>)
tensor(2.2345, grad_fn=<NllLossBackward0>)
tensor(2.1712, grad_fn=<NllLossBackward0>)
tensor(2.1392, grad_fn=<NllLossBackward0>)
tensor(2.1822, grad_fn=<NllLossBackward0>)
tensor(2.3090, grad_fn=<NllLossBackward0>)
tensor(2.1243, grad_fn=<NllLossBackward0>)
tensor(2.1042, grad_fn=<NllLossBackward0>)
tensor(2.0843, grad_fn=<NllLossBackward0>)
tensor(2.1067, grad_fn=<NllLossBackward0>)
tensor(1.9738, grad_fn=<NllLossBackward0>)
tensor(2.1693, grad_fn=<NllLossBackward0>)
tensor(2.1211, grad_fn=<NllLossBackward0>)
tensor(2.0540, grad_fn=<NllLossBackward0>)
tensor(1.7981, grad_fn=<NllLossBackward0>)
tensor(2.0675, grad_fn=<NllLossBackward0>)
tensor(2.0544, grad_fn=<NllLossBackward0>)
tensor(2.2585, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4272: 0.266
tensor(2.2987, grad_fn=<NllLossBackward0>)
tensor(2.1145, grad_fn=<NllLossBackward0>)
tensor(2.2377, grad_fn=<NllLossBackward0>)
tensor(2.0631, grad_fn=<NllLossBackward0>)
tensor(2.2536, grad_fn=<NllLossBackward0>)
tensor(2.0032, grad_fn=<NllLossBackward0>)
tensor(2.2805, grad_fn=<NllLossBackward0>)
tensor(2.3125, grad_fn=<NllLossBackward0>)
tensor(2.1930, grad_fn=<NllLossBackward0>)
tensor(2.3873, grad_fn=<NllLossBackward0>)
tensor(2.1133, grad_fn=<NllLossBackward0>)
tensor(2.0630, grad_fn=<NllLossBackward0>)
tensor(2.2777, grad_fn=<NllLossBackward0>)
tensor(2.1009, grad_fn=<NllLossBackward0>)
tensor(2.0803, grad_fn=<NllLossBackward0>)
tensor(2.2936, grad_fn=<NllLossBackward0>)
tensor(2.1669, grad_fn=<NllLossBackward0>)
tensor(2.0430, grad_fn=<NllLossBackward0>)
tensor(2.2891, grad_fn=<NllLossBackward0>)
tensor(2.2803, grad_fn=<NllLossBackward0>)
tensor(1.9824, grad_fn=<NllLossBackward0>)
tensor(2.0365, grad_fn=<NllLossBackward0>)
tensor(2.1792, grad_fn=<NllLossBackward0>)
tensor(2.0319, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4296: 0.255
tensor(2.1751, grad_fn=<NllLossBackward0>)
tensor(2.3257, grad_fn=<NllLossBackward0>)
tensor(2.2291, grad_fn=<NllLossBackward0>)
tensor(2.1255, grad_fn=<NllLossBackward0>)
tensor(2.3054, grad_fn=<NllLossBackward0>)
tensor(2.4779, grad_fn=<NllLossBackward0>)
tensor(2.1390, grad_fn=<NllLossBackward0>)
tensor(2.0863, grad_fn=<NllLossBackward0>)
tensor(2.0818, grad_fn=<NllLossBackward0>)
tensor(2.1878, grad_fn=<NllLossBackward0>)
tensor(2.1844, grad_fn=<NllLossBackward0>)
tensor(2.2221, grad_fn=<NllLossBackward0>)
tensor(2.1239, grad_fn=<NllLossBackward0>)
tensor(2.1194, grad_fn=<NllLossBackward0>)
tensor(1.9655, grad_fn=<NllLossBackward0>)
tensor(2.2402, grad_fn=<NllLossBackward0>)
tensor(2.2858, grad_fn=<NllLossBackward0>)
tensor(2.4791, grad_fn=<NllLossBackward0>)
tensor(2.2132, grad_fn=<NllLossBackward0>)
tensor(2.0736, grad_fn=<NllLossBackward0>)
tensor(1.9384, grad_fn=<NllLossBackward0>)
tensor(2.2367, grad_fn=<NllLossBackward0>)
tensor(2.2199, grad_fn=<NllLossBackward0>)
tensor(2.3607, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4320: 0.229
tensor(2.1266, grad_fn=<NllLossBackward0>)
tensor(2.0522, grad_fn=<NllLossBackward0>)
tensor(2.2346, grad_fn=<NllLossBackward0>)
tensor(2.2543, grad_fn=<NllLossBackward0>)
tensor(2.3820, grad_fn=<NllLossBackward0>)
tensor(2.2265, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.0867, grad_fn=<NllLossBackward0>)
tensor(2.2245, grad_fn=<NllLossBackward0>)
tensor(2.2198, grad_fn=<NllLossBackward0>)
tensor(2.0921, grad_fn=<NllLossBackward0>)
tensor(2.1040, grad_fn=<NllLossBackward0>)
tensor(2.1799, grad_fn=<NllLossBackward0>)
tensor(2.2579, grad_fn=<NllLossBackward0>)
tensor(1.8294, grad_fn=<NllLossBackward0>)
tensor(2.1863, grad_fn=<NllLossBackward0>)
tensor(2.0697, grad_fn=<NllLossBackward0>)
tensor(2.1359, grad_fn=<NllLossBackward0>)
tensor(2.0598, grad_fn=<NllLossBackward0>)
tensor(2.1967, grad_fn=<NllLossBackward0>)
tensor(2.0847, grad_fn=<NllLossBackward0>)
tensor(2.3411, grad_fn=<NllLossBackward0>)
tensor(2.2966, grad_fn=<NllLossBackward0>)
tensor(2.2372, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4344: 0.260
tensor(2.2252, grad_fn=<NllLossBackward0>)
tensor(2.0705, grad_fn=<NllLossBackward0>)
tensor(2.2227, grad_fn=<NllLossBackward0>)
tensor(2.3767, grad_fn=<NllLossBackward0>)
tensor(2.1121, grad_fn=<NllLossBackward0>)
tensor(2.2289, grad_fn=<NllLossBackward0>)
tensor(2.3350, grad_fn=<NllLossBackward0>)
tensor(2.1840, grad_fn=<NllLossBackward0>)
tensor(2.4653, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(2.0735, grad_fn=<NllLossBackward0>)
tensor(2.2065, grad_fn=<NllLossBackward0>)
tensor(2.2914, grad_fn=<NllLossBackward0>)
tensor(2.2461, grad_fn=<NllLossBackward0>)
tensor(2.2124, grad_fn=<NllLossBackward0>)
tensor(2.0254, grad_fn=<NllLossBackward0>)
tensor(2.0252, grad_fn=<NllLossBackward0>)
tensor(2.1141, grad_fn=<NllLossBackward0>)
tensor(2.1010, grad_fn=<NllLossBackward0>)
tensor(2.2786, grad_fn=<NllLossBackward0>)
tensor(2.3105, grad_fn=<NllLossBackward0>)
tensor(1.8894, grad_fn=<NllLossBackward0>)
tensor(2.3805, grad_fn=<NllLossBackward0>)
tensor(2.2046, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4368: 0.255
tensor(2.1411, grad_fn=<NllLossBackward0>)
tensor(2.1976, grad_fn=<NllLossBackward0>)
tensor(2.0245, grad_fn=<NllLossBackward0>)
tensor(2.2494, grad_fn=<NllLossBackward0>)
tensor(2.0034, grad_fn=<NllLossBackward0>)
tensor(2.2165, grad_fn=<NllLossBackward0>)
tensor(2.2883, grad_fn=<NllLossBackward0>)
tensor(2.1030, grad_fn=<NllLossBackward0>)
tensor(1.8786, grad_fn=<NllLossBackward0>)
tensor(2.2543, grad_fn=<NllLossBackward0>)
tensor(2.2579, grad_fn=<NllLossBackward0>)
tensor(2.0393, grad_fn=<NllLossBackward0>)
tensor(2.0595, grad_fn=<NllLossBackward0>)
tensor(2.1449, grad_fn=<NllLossBackward0>)
tensor(2.0806, grad_fn=<NllLossBackward0>)
tensor(2.1778, grad_fn=<NllLossBackward0>)
tensor(2.0651, grad_fn=<NllLossBackward0>)
tensor(2.4759, grad_fn=<NllLossBackward0>)
tensor(2.0366, grad_fn=<NllLossBackward0>)
tensor(2.2019, grad_fn=<NllLossBackward0>)
tensor(2.0956, grad_fn=<NllLossBackward0>)
tensor(2.0867, grad_fn=<NllLossBackward0>)
tensor(2.2394, grad_fn=<NllLossBackward0>)
tensor(2.2425, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4392: 0.253
tensor(2.2252, grad_fn=<NllLossBackward0>)
tensor(2.3005, grad_fn=<NllLossBackward0>)
tensor(2.1230, grad_fn=<NllLossBackward0>)
tensor(2.2391, grad_fn=<NllLossBackward0>)
tensor(2.2166, grad_fn=<NllLossBackward0>)
tensor(2.1160, grad_fn=<NllLossBackward0>)
tensor(2.1134, grad_fn=<NllLossBackward0>)
tensor(2.3010, grad_fn=<NllLossBackward0>)
tensor(2.2431, grad_fn=<NllLossBackward0>)
tensor(2.1462, grad_fn=<NllLossBackward0>)
tensor(2.1807, grad_fn=<NllLossBackward0>)
tensor(2.1439, grad_fn=<NllLossBackward0>)
tensor(2.1456, grad_fn=<NllLossBackward0>)
tensor(2.2811, grad_fn=<NllLossBackward0>)
tensor(2.3233, grad_fn=<NllLossBackward0>)
tensor(2.0942, grad_fn=<NllLossBackward0>)
tensor(1.9854, grad_fn=<NllLossBackward0>)
tensor(2.3221, grad_fn=<NllLossBackward0>)
tensor(2.1208, grad_fn=<NllLossBackward0>)
tensor(2.1306, grad_fn=<NllLossBackward0>)
tensor(2.4076, grad_fn=<NllLossBackward0>)
tensor(2.2069, grad_fn=<NllLossBackward0>)
tensor(1.9277, grad_fn=<NllLossBackward0>)
tensor(2.2283, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4416: 0.243
tensor(2.1636, grad_fn=<NllLossBackward0>)
tensor(2.3414, grad_fn=<NllLossBackward0>)
tensor(2.2519, grad_fn=<NllLossBackward0>)
tensor(2.3340, grad_fn=<NllLossBackward0>)
tensor(2.1816, grad_fn=<NllLossBackward0>)
tensor(2.0967, grad_fn=<NllLossBackward0>)
tensor(2.0871, grad_fn=<NllLossBackward0>)
tensor(2.3035, grad_fn=<NllLossBackward0>)
tensor(2.3365, grad_fn=<NllLossBackward0>)
tensor(2.0725, grad_fn=<NllLossBackward0>)
tensor(2.2315, grad_fn=<NllLossBackward0>)
tensor(2.2791, grad_fn=<NllLossBackward0>)
tensor(2.2188, grad_fn=<NllLossBackward0>)
tensor(1.9562, grad_fn=<NllLossBackward0>)
tensor(1.9268, grad_fn=<NllLossBackward0>)
tensor(2.1078, grad_fn=<NllLossBackward0>)
tensor(2.2863, grad_fn=<NllLossBackward0>)
tensor(2.3390, grad_fn=<NllLossBackward0>)
tensor(2.3935, grad_fn=<NllLossBackward0>)
tensor(2.2204, grad_fn=<NllLossBackward0>)
tensor(2.1425, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.0825, grad_fn=<NllLossBackward0>)
tensor(1.9705, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4440: 0.241
tensor(1.9878, grad_fn=<NllLossBackward0>)
tensor(1.9632, grad_fn=<NllLossBackward0>)
tensor(2.2272, grad_fn=<NllLossBackward0>)
tensor(2.1677, grad_fn=<NllLossBackward0>)
tensor(2.2218, grad_fn=<NllLossBackward0>)
tensor(2.1178, grad_fn=<NllLossBackward0>)
tensor(2.3734, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.1275, grad_fn=<NllLossBackward0>)
tensor(2.2252, grad_fn=<NllLossBackward0>)
tensor(2.2231, grad_fn=<NllLossBackward0>)
tensor(2.0521, grad_fn=<NllLossBackward0>)
tensor(2.1854, grad_fn=<NllLossBackward0>)
tensor(2.2056, grad_fn=<NllLossBackward0>)
tensor(2.0261, grad_fn=<NllLossBackward0>)
tensor(2.2199, grad_fn=<NllLossBackward0>)
tensor(2.1302, grad_fn=<NllLossBackward0>)
tensor(2.1834, grad_fn=<NllLossBackward0>)
tensor(2.1885, grad_fn=<NllLossBackward0>)
tensor(2.2184, grad_fn=<NllLossBackward0>)
tensor(2.4257, grad_fn=<NllLossBackward0>)
tensor(1.9341, grad_fn=<NllLossBackward0>)
tensor(2.1286, grad_fn=<NllLossBackward0>)
tensor(2.1669, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4464: 0.267
tensor(2.2184, grad_fn=<NllLossBackward0>)
tensor(2.2197, grad_fn=<NllLossBackward0>)
tensor(2.1677, grad_fn=<NllLossBackward0>)
tensor(2.2868, grad_fn=<NllLossBackward0>)
tensor(2.2509, grad_fn=<NllLossBackward0>)
tensor(2.3042, grad_fn=<NllLossBackward0>)
tensor(2.0737, grad_fn=<NllLossBackward0>)
tensor(1.9805, grad_fn=<NllLossBackward0>)
tensor(2.0040, grad_fn=<NllLossBackward0>)
tensor(2.0030, grad_fn=<NllLossBackward0>)
tensor(2.2136, grad_fn=<NllLossBackward0>)
tensor(2.0964, grad_fn=<NllLossBackward0>)
tensor(2.2631, grad_fn=<NllLossBackward0>)
tensor(2.0966, grad_fn=<NllLossBackward0>)
tensor(2.3669, grad_fn=<NllLossBackward0>)
tensor(2.1251, grad_fn=<NllLossBackward0>)
tensor(2.1422, grad_fn=<NllLossBackward0>)
tensor(2.0290, grad_fn=<NllLossBackward0>)
tensor(2.0940, grad_fn=<NllLossBackward0>)
tensor(2.0716, grad_fn=<NllLossBackward0>)
tensor(2.0918, grad_fn=<NllLossBackward0>)
tensor(2.2266, grad_fn=<NllLossBackward0>)
tensor(1.8915, grad_fn=<NllLossBackward0>)
tensor(2.4037, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4488: 0.267
tensor(2.1085, grad_fn=<NllLossBackward0>)
tensor(2.1261, grad_fn=<NllLossBackward0>)
tensor(1.9280, grad_fn=<NllLossBackward0>)
tensor(2.0923, grad_fn=<NllLossBackward0>)
tensor(2.1845, grad_fn=<NllLossBackward0>)
tensor(2.0710, grad_fn=<NllLossBackward0>)
tensor(1.9594, grad_fn=<NllLossBackward0>)
tensor(2.2679, grad_fn=<NllLossBackward0>)
tensor(1.9124, grad_fn=<NllLossBackward0>)
tensor(2.3641, grad_fn=<NllLossBackward0>)
tensor(1.9684, grad_fn=<NllLossBackward0>)
tensor(2.0744, grad_fn=<NllLossBackward0>)
tensor(2.2059, grad_fn=<NllLossBackward0>)
tensor(2.2610, grad_fn=<NllLossBackward0>)
tensor(2.2281, grad_fn=<NllLossBackward0>)
tensor(2.1302, grad_fn=<NllLossBackward0>)
tensor(1.7622, grad_fn=<NllLossBackward0>)
tensor(2.2258, grad_fn=<NllLossBackward0>)
tensor(2.2988, grad_fn=<NllLossBackward0>)
tensor(1.8483, grad_fn=<NllLossBackward0>)
tensor(1.9246, grad_fn=<NllLossBackward0>)
tensor(2.3144, grad_fn=<NllLossBackward0>)
tensor(2.1354, grad_fn=<NllLossBackward0>)
tensor(2.0139, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4512: 0.267
tensor(1.9966, grad_fn=<NllLossBackward0>)
tensor(2.2840, grad_fn=<NllLossBackward0>)
tensor(2.0466, grad_fn=<NllLossBackward0>)
tensor(2.2976, grad_fn=<NllLossBackward0>)
tensor(2.1455, grad_fn=<NllLossBackward0>)
tensor(2.0772, grad_fn=<NllLossBackward0>)
tensor(2.1093, grad_fn=<NllLossBackward0>)
tensor(2.2598, grad_fn=<NllLossBackward0>)
tensor(2.2143, grad_fn=<NllLossBackward0>)
tensor(2.0013, grad_fn=<NllLossBackward0>)
tensor(2.2153, grad_fn=<NllLossBackward0>)
tensor(2.2605, grad_fn=<NllLossBackward0>)
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.1433, grad_fn=<NllLossBackward0>)
tensor(2.1367, grad_fn=<NllLossBackward0>)
tensor(2.2193, grad_fn=<NllLossBackward0>)
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(2.0302, grad_fn=<NllLossBackward0>)
tensor(2.0925, grad_fn=<NllLossBackward0>)
tensor(2.2631, grad_fn=<NllLossBackward0>)
tensor(2.2430, grad_fn=<NllLossBackward0>)
tensor(2.2981, grad_fn=<NllLossBackward0>)
tensor(2.1189, grad_fn=<NllLossBackward0>)
tensor(2.1353, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4536: 0.274
tensor(1.8500, grad_fn=<NllLossBackward0>)
tensor(2.1638, grad_fn=<NllLossBackward0>)
tensor(2.2472, grad_fn=<NllLossBackward0>)
tensor(2.1929, grad_fn=<NllLossBackward0>)
tensor(2.1741, grad_fn=<NllLossBackward0>)
tensor(2.2738, grad_fn=<NllLossBackward0>)
tensor(1.9700, grad_fn=<NllLossBackward0>)
tensor(2.0972, grad_fn=<NllLossBackward0>)
tensor(2.2701, grad_fn=<NllLossBackward0>)
tensor(2.1313, grad_fn=<NllLossBackward0>)
tensor(1.9562, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.1569, grad_fn=<NllLossBackward0>)
tensor(2.2548, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.0181, grad_fn=<NllLossBackward0>)
tensor(1.9745, grad_fn=<NllLossBackward0>)
tensor(1.9608, grad_fn=<NllLossBackward0>)
tensor(2.0263, grad_fn=<NllLossBackward0>)
tensor(2.1053, grad_fn=<NllLossBackward0>)
tensor(2.1257, grad_fn=<NllLossBackward0>)
tensor(2.0856, grad_fn=<NllLossBackward0>)
tensor(2.1455, grad_fn=<NllLossBackward0>)
tensor(2.1679, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4560: 0.255
tensor(2.2283, grad_fn=<NllLossBackward0>)
tensor(2.2343, grad_fn=<NllLossBackward0>)
tensor(2.0650, grad_fn=<NllLossBackward0>)
tensor(2.1899, grad_fn=<NllLossBackward0>)
tensor(2.0353, grad_fn=<NllLossBackward0>)
tensor(2.2938, grad_fn=<NllLossBackward0>)
tensor(2.2887, grad_fn=<NllLossBackward0>)
tensor(2.4799, grad_fn=<NllLossBackward0>)
tensor(2.3083, grad_fn=<NllLossBackward0>)
tensor(2.0705, grad_fn=<NllLossBackward0>)
tensor(1.8977, grad_fn=<NllLossBackward0>)
tensor(2.2035, grad_fn=<NllLossBackward0>)
tensor(2.1827, grad_fn=<NllLossBackward0>)
tensor(2.1946, grad_fn=<NllLossBackward0>)
tensor(1.9341, grad_fn=<NllLossBackward0>)
tensor(2.2332, grad_fn=<NllLossBackward0>)
tensor(2.2961, grad_fn=<NllLossBackward0>)
tensor(2.2586, grad_fn=<NllLossBackward0>)
tensor(2.0122, grad_fn=<NllLossBackward0>)
tensor(2.1018, grad_fn=<NllLossBackward0>)
tensor(2.1024, grad_fn=<NllLossBackward0>)
tensor(2.0739, grad_fn=<NllLossBackward0>)
tensor(2.1051, grad_fn=<NllLossBackward0>)
tensor(2.2220, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4584: 0.241
tensor(2.2785, grad_fn=<NllLossBackward0>)
tensor(2.3474, grad_fn=<NllLossBackward0>)
tensor(2.2489, grad_fn=<NllLossBackward0>)
tensor(1.9565, grad_fn=<NllLossBackward0>)
tensor(2.1842, grad_fn=<NllLossBackward0>)
tensor(1.9921, grad_fn=<NllLossBackward0>)
tensor(2.1458, grad_fn=<NllLossBackward0>)
tensor(2.0796, grad_fn=<NllLossBackward0>)
tensor(2.1874, grad_fn=<NllLossBackward0>)
tensor(2.1908, grad_fn=<NllLossBackward0>)
tensor(2.0791, grad_fn=<NllLossBackward0>)
tensor(2.3397, grad_fn=<NllLossBackward0>)
tensor(2.0279, grad_fn=<NllLossBackward0>)
tensor(2.0909, grad_fn=<NllLossBackward0>)
tensor(2.2187, grad_fn=<NllLossBackward0>)
tensor(1.8337, grad_fn=<NllLossBackward0>)
tensor(2.0750, grad_fn=<NllLossBackward0>)
tensor(2.1318, grad_fn=<NllLossBackward0>)
tensor(2.3017, grad_fn=<NllLossBackward0>)
tensor(2.1916, grad_fn=<NllLossBackward0>)
tensor(2.0721, grad_fn=<NllLossBackward0>)
tensor(2.2616, grad_fn=<NllLossBackward0>)
tensor(2.0156, grad_fn=<NllLossBackward0>)
tensor(2.3685, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4608: 0.257
tensor(2.1495, grad_fn=<NllLossBackward0>)
tensor(2.0675, grad_fn=<NllLossBackward0>)
tensor(2.0222, grad_fn=<NllLossBackward0>)
tensor(2.0952, grad_fn=<NllLossBackward0>)
tensor(1.8025, grad_fn=<NllLossBackward0>)
tensor(2.2577, grad_fn=<NllLossBackward0>)
tensor(2.3807, grad_fn=<NllLossBackward0>)
tensor(2.1213, grad_fn=<NllLossBackward0>)
tensor(1.9326, grad_fn=<NllLossBackward0>)
tensor(2.1690, grad_fn=<NllLossBackward0>)
tensor(2.2854, grad_fn=<NllLossBackward0>)
tensor(2.1054, grad_fn=<NllLossBackward0>)
tensor(2.0477, grad_fn=<NllLossBackward0>)
tensor(2.0379, grad_fn=<NllLossBackward0>)
tensor(2.1602, grad_fn=<NllLossBackward0>)
tensor(2.1037, grad_fn=<NllLossBackward0>)
tensor(2.1796, grad_fn=<NllLossBackward0>)
tensor(2.2194, grad_fn=<NllLossBackward0>)
tensor(2.2148, grad_fn=<NllLossBackward0>)
tensor(2.1594, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
tensor(2.1954, grad_fn=<NllLossBackward0>)
tensor(2.0767, grad_fn=<NllLossBackward0>)
tensor(2.0359, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4632: 0.283
tensor(2.2444, grad_fn=<NllLossBackward0>)
tensor(2.1311, grad_fn=<NllLossBackward0>)
tensor(2.1745, grad_fn=<NllLossBackward0>)
tensor(1.9885, grad_fn=<NllLossBackward0>)
tensor(2.2869, grad_fn=<NllLossBackward0>)
tensor(2.1532, grad_fn=<NllLossBackward0>)
tensor(2.1620, grad_fn=<NllLossBackward0>)
tensor(2.2048, grad_fn=<NllLossBackward0>)
tensor(2.0245, grad_fn=<NllLossBackward0>)
tensor(2.1641, grad_fn=<NllLossBackward0>)
tensor(2.1069, grad_fn=<NllLossBackward0>)
tensor(1.8577, grad_fn=<NllLossBackward0>)
tensor(2.2167, grad_fn=<NllLossBackward0>)
tensor(2.2049, grad_fn=<NllLossBackward0>)
tensor(2.0974, grad_fn=<NllLossBackward0>)
tensor(2.1511, grad_fn=<NllLossBackward0>)
tensor(2.0890, grad_fn=<NllLossBackward0>)
tensor(1.9451, grad_fn=<NllLossBackward0>)
tensor(2.2118, grad_fn=<NllLossBackward0>)
tensor(2.1039, grad_fn=<NllLossBackward0>)
tensor(1.9796, grad_fn=<NllLossBackward0>)
tensor(2.0615, grad_fn=<NllLossBackward0>)
tensor(2.2132, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  4656: 0.247
tensor(1.9587, grad_fn=<NllLossBackward0>)
tensor(2.1450, grad_fn=<NllLossBackward0>)
tensor(2.1860, grad_fn=<NllLossBackward0>)
tensor(2.0964, grad_fn=<NllLossBackward0>)
tensor(2.3994, grad_fn=<NllLossBackward0>)
tensor(2.2674, grad_fn=<NllLossBackward0>)
tensor(2.2067, grad_fn=<NllLossBackward0>)
tensor(1.9606, grad_fn=<NllLossBackward0>)
tensor(2.1205, grad_fn=<NllLossBackward0>)
tensor(2.1970, grad_fn=<NllLossBackward0>)
Validation loss after mini-batch    24: 0.155
Validation loss after mini-batch    48: 0.188
Validation loss after mini-batch    72: 0.153
Validation loss after mini-batch    96: 0.168
Validation loss after mini-batch   120: 0.165
Validation loss after mini-batch   144: 0.186
Validation loss after mini-batch   168: 0.139
Validation loss after mini-batch   192: 0.186
Validation loss after mini-batch   216: 0.170
Validation loss after mini-batch   240: 0.170
Validation loss after mini-batch   264: 0.181
Validation loss after mini-batch   288: 0.177
Validation loss after mini-batch   312: 0.177
Validation loss after mini-batch   336: 0.163
Validation loss after mini-batch   360: 0.175
Validation loss after mini-batch   384: 0.170
Validation loss after mini-batch   408: 0.144
Validation loss after mini-batch   432: 0.181
Validation loss after mini-batch   456: 0.149
Validation loss after mini-batch   480: 0.172
Validation loss after mini-batch   504: 0.175
Validation loss after mini-batch   528: 0.181
Validation loss after mini-batch   552: 0.160
Validation loss after mini-batch   576: 0.181
Validation loss after mini-batch   600: 0.187
Validation loss after mini-batch   624: 0.161
Validation loss after mini-batch   648: 0.201
Validation loss after mini-batch   672: 0.177
Validation loss after mini-batch   696: 0.198
Validation loss after mini-batch   720: 0.170
Validation loss after mini-batch   744: 0.174
Validation loss after mini-batch   768: 0.198
Validation loss after mini-batch   792: 0.224
Validation loss after mini-batch   816: 0.200
Validation loss after mini-batch   840: 0.194
Validation loss after mini-batch   864: 0.170
Validation loss after mini-batch   888: 0.167
Validation loss after mini-batch   912: 0.191
Validation loss after mini-batch   936: 0.160
Validation loss after mini-batch   960: 0.196
Validation loss after mini-batch   984: 0.186
Starting epoch 2
tensor(2.3357, grad_fn=<NllLossBackward0>)
tensor(2.1745, grad_fn=<NllLossBackward0>)
tensor(1.9972, grad_fn=<NllLossBackward0>)
tensor(2.2403, grad_fn=<NllLossBackward0>)
tensor(2.1644, grad_fn=<NllLossBackward0>)
tensor(2.1241, grad_fn=<NllLossBackward0>)
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.1738, grad_fn=<NllLossBackward0>)
tensor(2.0111, grad_fn=<NllLossBackward0>)
tensor(1.9907, grad_fn=<NllLossBackward0>)
tensor(2.1655, grad_fn=<NllLossBackward0>)
tensor(2.1716, grad_fn=<NllLossBackward0>)
tensor(2.2560, grad_fn=<NllLossBackward0>)
tensor(2.1900, grad_fn=<NllLossBackward0>)
tensor(2.2017, grad_fn=<NllLossBackward0>)
tensor(2.1150, grad_fn=<NllLossBackward0>)
tensor(2.1372, grad_fn=<NllLossBackward0>)
tensor(1.9802, grad_fn=<NllLossBackward0>)
tensor(2.0268, grad_fn=<NllLossBackward0>)
tensor(2.0736, grad_fn=<NllLossBackward0>)
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.0142, grad_fn=<NllLossBackward0>)
tensor(2.1787, grad_fn=<NllLossBackward0>)
tensor(1.9379, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    24: 0.266
tensor(2.3033, grad_fn=<NllLossBackward0>)
tensor(2.0090, grad_fn=<NllLossBackward0>)
tensor(2.2458, grad_fn=<NllLossBackward0>)
tensor(2.1380, grad_fn=<NllLossBackward0>)
tensor(2.1179, grad_fn=<NllLossBackward0>)
tensor(2.1215, grad_fn=<NllLossBackward0>)
tensor(2.3986, grad_fn=<NllLossBackward0>)
tensor(2.3093, grad_fn=<NllLossBackward0>)
tensor(1.9928, grad_fn=<NllLossBackward0>)
tensor(2.1981, grad_fn=<NllLossBackward0>)
tensor(2.2144, grad_fn=<NllLossBackward0>)
tensor(2.3790, grad_fn=<NllLossBackward0>)
tensor(2.2661, grad_fn=<NllLossBackward0>)
tensor(2.2121, grad_fn=<NllLossBackward0>)
tensor(2.0276, grad_fn=<NllLossBackward0>)
tensor(2.1532, grad_fn=<NllLossBackward0>)
tensor(2.1131, grad_fn=<NllLossBackward0>)
tensor(2.1564, grad_fn=<NllLossBackward0>)
tensor(2.0594, grad_fn=<NllLossBackward0>)
tensor(2.0797, grad_fn=<NllLossBackward0>)
tensor(2.2258, grad_fn=<NllLossBackward0>)
tensor(2.2714, grad_fn=<NllLossBackward0>)
tensor(2.2608, grad_fn=<NllLossBackward0>)
tensor(2.1420, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    48: 0.247
tensor(2.2062, grad_fn=<NllLossBackward0>)
tensor(2.1217, grad_fn=<NllLossBackward0>)
tensor(2.1096, grad_fn=<NllLossBackward0>)
tensor(2.1591, grad_fn=<NllLossBackward0>)
tensor(2.1087, grad_fn=<NllLossBackward0>)
tensor(2.2724, grad_fn=<NllLossBackward0>)
tensor(2.0657, grad_fn=<NllLossBackward0>)
tensor(2.0825, grad_fn=<NllLossBackward0>)
tensor(2.0663, grad_fn=<NllLossBackward0>)
tensor(2.2883, grad_fn=<NllLossBackward0>)
tensor(2.0825, grad_fn=<NllLossBackward0>)
tensor(2.1461, grad_fn=<NllLossBackward0>)
tensor(2.1457, grad_fn=<NllLossBackward0>)
tensor(2.0280, grad_fn=<NllLossBackward0>)
tensor(2.2889, grad_fn=<NllLossBackward0>)
tensor(2.1088, grad_fn=<NllLossBackward0>)
tensor(2.1857, grad_fn=<NllLossBackward0>)
tensor(2.1033, grad_fn=<NllLossBackward0>)
tensor(2.2087, grad_fn=<NllLossBackward0>)
tensor(2.2418, grad_fn=<NllLossBackward0>)
tensor(2.1288, grad_fn=<NllLossBackward0>)
tensor(2.2762, grad_fn=<NllLossBackward0>)
tensor(2.1459, grad_fn=<NllLossBackward0>)
tensor(2.2581, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    72: 0.234
tensor(1.9285, grad_fn=<NllLossBackward0>)
tensor(2.0237, grad_fn=<NllLossBackward0>)
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.2256, grad_fn=<NllLossBackward0>)
tensor(2.3348, grad_fn=<NllLossBackward0>)
tensor(2.1596, grad_fn=<NllLossBackward0>)
tensor(2.3223, grad_fn=<NllLossBackward0>)
tensor(1.9066, grad_fn=<NllLossBackward0>)
tensor(2.1270, grad_fn=<NllLossBackward0>)
tensor(1.9185, grad_fn=<NllLossBackward0>)
tensor(1.9906, grad_fn=<NllLossBackward0>)
tensor(1.9232, grad_fn=<NllLossBackward0>)
tensor(1.9325, grad_fn=<NllLossBackward0>)
tensor(2.1574, grad_fn=<NllLossBackward0>)
tensor(2.0691, grad_fn=<NllLossBackward0>)
tensor(2.2373, grad_fn=<NllLossBackward0>)
tensor(2.1447, grad_fn=<NllLossBackward0>)
tensor(2.0858, grad_fn=<NllLossBackward0>)
tensor(2.0728, grad_fn=<NllLossBackward0>)
tensor(2.3599, grad_fn=<NllLossBackward0>)
tensor(2.3339, grad_fn=<NllLossBackward0>)
tensor(2.2076, grad_fn=<NllLossBackward0>)
tensor(1.9904, grad_fn=<NllLossBackward0>)
tensor(2.3024, grad_fn=<NllLossBackward0>)
Training loss after mini-batch    96: 0.262
tensor(2.1801, grad_fn=<NllLossBackward0>)
tensor(2.1369, grad_fn=<NllLossBackward0>)
tensor(1.9653, grad_fn=<NllLossBackward0>)
tensor(2.1658, grad_fn=<NllLossBackward0>)
tensor(2.1444, grad_fn=<NllLossBackward0>)
tensor(2.2206, grad_fn=<NllLossBackward0>)
tensor(2.2552, grad_fn=<NllLossBackward0>)
tensor(2.2141, grad_fn=<NllLossBackward0>)
tensor(2.1895, grad_fn=<NllLossBackward0>)
tensor(2.0497, grad_fn=<NllLossBackward0>)
tensor(1.9884, grad_fn=<NllLossBackward0>)
tensor(2.1030, grad_fn=<NllLossBackward0>)
tensor(2.0584, grad_fn=<NllLossBackward0>)
tensor(2.1659, grad_fn=<NllLossBackward0>)
tensor(2.0573, grad_fn=<NllLossBackward0>)
tensor(2.2220, grad_fn=<NllLossBackward0>)
tensor(2.2663, grad_fn=<NllLossBackward0>)
tensor(2.1258, grad_fn=<NllLossBackward0>)
tensor(2.0448, grad_fn=<NllLossBackward0>)
tensor(2.0608, grad_fn=<NllLossBackward0>)
tensor(2.3110, grad_fn=<NllLossBackward0>)
tensor(1.9981, grad_fn=<NllLossBackward0>)
tensor(2.0983, grad_fn=<NllLossBackward0>)
tensor(2.1127, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   120: 0.286
tensor(2.2272, grad_fn=<NllLossBackward0>)
tensor(2.0054, grad_fn=<NllLossBackward0>)
tensor(2.1286, grad_fn=<NllLossBackward0>)
tensor(2.2125, grad_fn=<NllLossBackward0>)
tensor(2.0274, grad_fn=<NllLossBackward0>)
tensor(2.2087, grad_fn=<NllLossBackward0>)
tensor(2.2370, grad_fn=<NllLossBackward0>)
tensor(2.2626, grad_fn=<NllLossBackward0>)
tensor(2.3894, grad_fn=<NllLossBackward0>)
tensor(2.1855, grad_fn=<NllLossBackward0>)
tensor(2.1447, grad_fn=<NllLossBackward0>)
tensor(2.4063, grad_fn=<NllLossBackward0>)
tensor(2.1005, grad_fn=<NllLossBackward0>)
tensor(1.9680, grad_fn=<NllLossBackward0>)
tensor(2.1724, grad_fn=<NllLossBackward0>)
tensor(2.3691, grad_fn=<NllLossBackward0>)
tensor(2.1755, grad_fn=<NllLossBackward0>)
tensor(1.9673, grad_fn=<NllLossBackward0>)
tensor(2.1235, grad_fn=<NllLossBackward0>)
tensor(2.4528, grad_fn=<NllLossBackward0>)
tensor(2.1635, grad_fn=<NllLossBackward0>)
tensor(2.2350, grad_fn=<NllLossBackward0>)
tensor(2.1727, grad_fn=<NllLossBackward0>)
tensor(2.1873, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   144: 0.238
tensor(2.1548, grad_fn=<NllLossBackward0>)
tensor(1.9923, grad_fn=<NllLossBackward0>)
tensor(2.3017, grad_fn=<NllLossBackward0>)
tensor(1.9075, grad_fn=<NllLossBackward0>)
tensor(2.2604, grad_fn=<NllLossBackward0>)
tensor(2.1175, grad_fn=<NllLossBackward0>)
tensor(2.0862, grad_fn=<NllLossBackward0>)
tensor(2.0963, grad_fn=<NllLossBackward0>)
tensor(2.2567, grad_fn=<NllLossBackward0>)
tensor(2.0747, grad_fn=<NllLossBackward0>)
tensor(2.0089, grad_fn=<NllLossBackward0>)
tensor(2.1367, grad_fn=<NllLossBackward0>)
tensor(2.1333, grad_fn=<NllLossBackward0>)
tensor(2.2712, grad_fn=<NllLossBackward0>)
tensor(2.1629, grad_fn=<NllLossBackward0>)
tensor(2.3296, grad_fn=<NllLossBackward0>)
tensor(2.0710, grad_fn=<NllLossBackward0>)
tensor(2.2163, grad_fn=<NllLossBackward0>)
tensor(1.9411, grad_fn=<NllLossBackward0>)
tensor(2.0909, grad_fn=<NllLossBackward0>)
tensor(2.0196, grad_fn=<NllLossBackward0>)
tensor(1.9877, grad_fn=<NllLossBackward0>)
tensor(2.1775, grad_fn=<NllLossBackward0>)
tensor(2.2149, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   168: 0.273
tensor(2.0192, grad_fn=<NllLossBackward0>)
tensor(2.0731, grad_fn=<NllLossBackward0>)
tensor(2.1753, grad_fn=<NllLossBackward0>)
tensor(2.2505, grad_fn=<NllLossBackward0>)
tensor(2.2695, grad_fn=<NllLossBackward0>)
tensor(2.0423, grad_fn=<NllLossBackward0>)
tensor(2.0679, grad_fn=<NllLossBackward0>)
tensor(1.9131, grad_fn=<NllLossBackward0>)
tensor(2.1711, grad_fn=<NllLossBackward0>)
tensor(2.2863, grad_fn=<NllLossBackward0>)
tensor(2.0728, grad_fn=<NllLossBackward0>)
tensor(1.8972, grad_fn=<NllLossBackward0>)
tensor(2.0830, grad_fn=<NllLossBackward0>)
tensor(2.0863, grad_fn=<NllLossBackward0>)
tensor(2.2491, grad_fn=<NllLossBackward0>)
tensor(2.1555, grad_fn=<NllLossBackward0>)
tensor(2.0777, grad_fn=<NllLossBackward0>)
tensor(2.1555, grad_fn=<NllLossBackward0>)
tensor(2.2442, grad_fn=<NllLossBackward0>)
tensor(2.1631, grad_fn=<NllLossBackward0>)
tensor(2.2644, grad_fn=<NllLossBackward0>)
tensor(2.0716, grad_fn=<NllLossBackward0>)
tensor(2.2087, grad_fn=<NllLossBackward0>)
tensor(2.1250, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   192: 0.262
tensor(2.4229, grad_fn=<NllLossBackward0>)
tensor(2.1846, grad_fn=<NllLossBackward0>)
tensor(2.2668, grad_fn=<NllLossBackward0>)
tensor(2.0118, grad_fn=<NllLossBackward0>)
tensor(2.2821, grad_fn=<NllLossBackward0>)
tensor(2.2090, grad_fn=<NllLossBackward0>)
tensor(2.0977, grad_fn=<NllLossBackward0>)
tensor(2.0871, grad_fn=<NllLossBackward0>)
tensor(2.2447, grad_fn=<NllLossBackward0>)
tensor(2.0893, grad_fn=<NllLossBackward0>)
tensor(2.0486, grad_fn=<NllLossBackward0>)
tensor(2.0438, grad_fn=<NllLossBackward0>)
tensor(2.2359, grad_fn=<NllLossBackward0>)
tensor(2.1884, grad_fn=<NllLossBackward0>)
tensor(2.3436, grad_fn=<NllLossBackward0>)
tensor(1.9420, grad_fn=<NllLossBackward0>)
tensor(1.8122, grad_fn=<NllLossBackward0>)
tensor(2.1756, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.3734, grad_fn=<NllLossBackward0>)
tensor(2.1281, grad_fn=<NllLossBackward0>)
tensor(1.9618, grad_fn=<NllLossBackward0>)
tensor(2.0063, grad_fn=<NllLossBackward0>)
tensor(2.0507, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   216: 0.276
tensor(2.1607, grad_fn=<NllLossBackward0>)
tensor(2.3810, grad_fn=<NllLossBackward0>)
tensor(2.1757, grad_fn=<NllLossBackward0>)
tensor(1.9538, grad_fn=<NllLossBackward0>)
tensor(2.1310, grad_fn=<NllLossBackward0>)
tensor(2.1793, grad_fn=<NllLossBackward0>)
tensor(2.2051, grad_fn=<NllLossBackward0>)
tensor(2.2446, grad_fn=<NllLossBackward0>)
tensor(2.1817, grad_fn=<NllLossBackward0>)
tensor(1.9685, grad_fn=<NllLossBackward0>)
tensor(2.2728, grad_fn=<NllLossBackward0>)
tensor(2.1245, grad_fn=<NllLossBackward0>)
tensor(2.0514, grad_fn=<NllLossBackward0>)
tensor(1.9239, grad_fn=<NllLossBackward0>)
tensor(1.9176, grad_fn=<NllLossBackward0>)
tensor(2.2226, grad_fn=<NllLossBackward0>)
tensor(2.0650, grad_fn=<NllLossBackward0>)
tensor(2.3601, grad_fn=<NllLossBackward0>)
tensor(2.1115, grad_fn=<NllLossBackward0>)
tensor(2.3135, grad_fn=<NllLossBackward0>)
tensor(2.1695, grad_fn=<NllLossBackward0>)
tensor(2.2441, grad_fn=<NllLossBackward0>)
tensor(2.0812, grad_fn=<NllLossBackward0>)
tensor(2.3191, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   240: 0.233
tensor(2.4029, grad_fn=<NllLossBackward0>)
tensor(2.0122, grad_fn=<NllLossBackward0>)
tensor(2.1190, grad_fn=<NllLossBackward0>)
tensor(2.1290, grad_fn=<NllLossBackward0>)
tensor(2.0861, grad_fn=<NllLossBackward0>)
tensor(2.3186, grad_fn=<NllLossBackward0>)
tensor(2.3411, grad_fn=<NllLossBackward0>)
tensor(2.2082, grad_fn=<NllLossBackward0>)
tensor(2.1289, grad_fn=<NllLossBackward0>)
tensor(2.2942, grad_fn=<NllLossBackward0>)
tensor(2.1662, grad_fn=<NllLossBackward0>)
tensor(2.1440, grad_fn=<NllLossBackward0>)
tensor(2.0790, grad_fn=<NllLossBackward0>)
tensor(2.2730, grad_fn=<NllLossBackward0>)
tensor(2.1748, grad_fn=<NllLossBackward0>)
tensor(1.9837, grad_fn=<NllLossBackward0>)
tensor(2.1350, grad_fn=<NllLossBackward0>)
tensor(2.2405, grad_fn=<NllLossBackward0>)
tensor(2.1479, grad_fn=<NllLossBackward0>)
tensor(2.1976, grad_fn=<NllLossBackward0>)
tensor(2.1503, grad_fn=<NllLossBackward0>)
tensor(2.0992, grad_fn=<NllLossBackward0>)
tensor(2.1984, grad_fn=<NllLossBackward0>)
tensor(2.1085, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   264: 0.271
tensor(1.9452, grad_fn=<NllLossBackward0>)
tensor(2.0843, grad_fn=<NllLossBackward0>)
tensor(2.1000, grad_fn=<NllLossBackward0>)
tensor(2.2602, grad_fn=<NllLossBackward0>)
tensor(2.0627, grad_fn=<NllLossBackward0>)
tensor(2.2922, grad_fn=<NllLossBackward0>)
tensor(2.3955, grad_fn=<NllLossBackward0>)
tensor(2.0181, grad_fn=<NllLossBackward0>)
tensor(2.0534, grad_fn=<NllLossBackward0>)
tensor(2.0015, grad_fn=<NllLossBackward0>)
tensor(2.0643, grad_fn=<NllLossBackward0>)
tensor(2.3105, grad_fn=<NllLossBackward0>)
tensor(2.2093, grad_fn=<NllLossBackward0>)
tensor(2.0302, grad_fn=<NllLossBackward0>)
tensor(2.0759, grad_fn=<NllLossBackward0>)
tensor(2.3291, grad_fn=<NllLossBackward0>)
tensor(1.9621, grad_fn=<NllLossBackward0>)
tensor(2.0829, grad_fn=<NllLossBackward0>)
tensor(1.9441, grad_fn=<NllLossBackward0>)
tensor(2.2081, grad_fn=<NllLossBackward0>)
tensor(2.1931, grad_fn=<NllLossBackward0>)
tensor(2.1684, grad_fn=<NllLossBackward0>)
tensor(1.9978, grad_fn=<NllLossBackward0>)
tensor(2.3000, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   288: 0.273
tensor(2.3302, grad_fn=<NllLossBackward0>)
tensor(2.1288, grad_fn=<NllLossBackward0>)
tensor(2.1153, grad_fn=<NllLossBackward0>)
tensor(2.0427, grad_fn=<NllLossBackward0>)
tensor(2.3443, grad_fn=<NllLossBackward0>)
tensor(1.9749, grad_fn=<NllLossBackward0>)
tensor(2.1008, grad_fn=<NllLossBackward0>)
tensor(2.1553, grad_fn=<NllLossBackward0>)
tensor(2.1720, grad_fn=<NllLossBackward0>)
tensor(2.1084, grad_fn=<NllLossBackward0>)
tensor(2.0919, grad_fn=<NllLossBackward0>)
tensor(1.9953, grad_fn=<NllLossBackward0>)
tensor(2.0319, grad_fn=<NllLossBackward0>)
tensor(2.0840, grad_fn=<NllLossBackward0>)
tensor(2.1847, grad_fn=<NllLossBackward0>)
tensor(2.2227, grad_fn=<NllLossBackward0>)
tensor(2.2132, grad_fn=<NllLossBackward0>)
tensor(2.1134, grad_fn=<NllLossBackward0>)
tensor(2.0225, grad_fn=<NllLossBackward0>)
tensor(2.1511, grad_fn=<NllLossBackward0>)
tensor(2.2819, grad_fn=<NllLossBackward0>)
tensor(2.1868, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.0360, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   312: 0.257
tensor(2.1450, grad_fn=<NllLossBackward0>)
tensor(2.1509, grad_fn=<NllLossBackward0>)
tensor(2.2192, grad_fn=<NllLossBackward0>)
tensor(2.1933, grad_fn=<NllLossBackward0>)
tensor(1.9387, grad_fn=<NllLossBackward0>)
tensor(2.0404, grad_fn=<NllLossBackward0>)
tensor(2.2600, grad_fn=<NllLossBackward0>)
tensor(2.3707, grad_fn=<NllLossBackward0>)
tensor(2.1844, grad_fn=<NllLossBackward0>)
tensor(2.1402, grad_fn=<NllLossBackward0>)
tensor(2.1190, grad_fn=<NllLossBackward0>)
tensor(2.0956, grad_fn=<NllLossBackward0>)
tensor(2.1343, grad_fn=<NllLossBackward0>)
tensor(2.5543, grad_fn=<NllLossBackward0>)
tensor(2.2196, grad_fn=<NllLossBackward0>)
tensor(2.1134, grad_fn=<NllLossBackward0>)
tensor(2.1727, grad_fn=<NllLossBackward0>)
tensor(2.2163, grad_fn=<NllLossBackward0>)
tensor(2.2538, grad_fn=<NllLossBackward0>)
tensor(2.2168, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.2393, grad_fn=<NllLossBackward0>)
tensor(2.1263, grad_fn=<NllLossBackward0>)
tensor(2.3338, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   336: 0.229
tensor(2.1406, grad_fn=<NllLossBackward0>)
tensor(2.2866, grad_fn=<NllLossBackward0>)
tensor(2.2658, grad_fn=<NllLossBackward0>)
tensor(1.8632, grad_fn=<NllLossBackward0>)
tensor(2.0585, grad_fn=<NllLossBackward0>)
tensor(2.2801, grad_fn=<NllLossBackward0>)
tensor(1.9236, grad_fn=<NllLossBackward0>)
tensor(2.0808, grad_fn=<NllLossBackward0>)
tensor(2.1435, grad_fn=<NllLossBackward0>)
tensor(2.2007, grad_fn=<NllLossBackward0>)
tensor(2.0476, grad_fn=<NllLossBackward0>)
tensor(2.0812, grad_fn=<NllLossBackward0>)
tensor(2.0308, grad_fn=<NllLossBackward0>)
tensor(2.2861, grad_fn=<NllLossBackward0>)
tensor(1.8541, grad_fn=<NllLossBackward0>)
tensor(1.9696, grad_fn=<NllLossBackward0>)
tensor(2.3137, grad_fn=<NllLossBackward0>)
tensor(2.1558, grad_fn=<NllLossBackward0>)
tensor(2.1321, grad_fn=<NllLossBackward0>)
tensor(2.1418, grad_fn=<NllLossBackward0>)
tensor(2.2939, grad_fn=<NllLossBackward0>)
tensor(2.0192, grad_fn=<NllLossBackward0>)
tensor(2.5839, grad_fn=<NllLossBackward0>)
tensor(2.2045, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   360: 0.259
tensor(2.0792, grad_fn=<NllLossBackward0>)
tensor(2.1791, grad_fn=<NllLossBackward0>)
tensor(2.2220, grad_fn=<NllLossBackward0>)
tensor(2.2779, grad_fn=<NllLossBackward0>)
tensor(2.0822, grad_fn=<NllLossBackward0>)
tensor(2.2267, grad_fn=<NllLossBackward0>)
tensor(2.0647, grad_fn=<NllLossBackward0>)
tensor(2.0887, grad_fn=<NllLossBackward0>)
tensor(2.1487, grad_fn=<NllLossBackward0>)
tensor(1.9968, grad_fn=<NllLossBackward0>)
tensor(2.0725, grad_fn=<NllLossBackward0>)
tensor(2.1734, grad_fn=<NllLossBackward0>)
tensor(2.1664, grad_fn=<NllLossBackward0>)
tensor(2.0266, grad_fn=<NllLossBackward0>)
tensor(2.0441, grad_fn=<NllLossBackward0>)
tensor(2.4529, grad_fn=<NllLossBackward0>)
tensor(2.0859, grad_fn=<NllLossBackward0>)
tensor(1.8015, grad_fn=<NllLossBackward0>)
tensor(2.0176, grad_fn=<NllLossBackward0>)
tensor(2.1378, grad_fn=<NllLossBackward0>)
tensor(2.2879, grad_fn=<NllLossBackward0>)
tensor(2.0708, grad_fn=<NllLossBackward0>)
tensor(2.3558, grad_fn=<NllLossBackward0>)
tensor(2.2214, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   384: 0.285
tensor(2.0657, grad_fn=<NllLossBackward0>)
tensor(2.1147, grad_fn=<NllLossBackward0>)
tensor(2.1808, grad_fn=<NllLossBackward0>)
tensor(2.3575, grad_fn=<NllLossBackward0>)
tensor(2.0480, grad_fn=<NllLossBackward0>)
tensor(2.2762, grad_fn=<NllLossBackward0>)
tensor(2.0736, grad_fn=<NllLossBackward0>)
tensor(2.1182, grad_fn=<NllLossBackward0>)
tensor(2.0741, grad_fn=<NllLossBackward0>)
tensor(2.1862, grad_fn=<NllLossBackward0>)
tensor(2.3410, grad_fn=<NllLossBackward0>)
tensor(2.0223, grad_fn=<NllLossBackward0>)
tensor(2.2931, grad_fn=<NllLossBackward0>)
tensor(2.2300, grad_fn=<NllLossBackward0>)
tensor(2.0249, grad_fn=<NllLossBackward0>)
tensor(2.3335, grad_fn=<NllLossBackward0>)
tensor(2.1613, grad_fn=<NllLossBackward0>)
tensor(2.1451, grad_fn=<NllLossBackward0>)
tensor(2.1298, grad_fn=<NllLossBackward0>)
tensor(2.1383, grad_fn=<NllLossBackward0>)
tensor(2.1864, grad_fn=<NllLossBackward0>)
tensor(2.0489, grad_fn=<NllLossBackward0>)
tensor(1.9999, grad_fn=<NllLossBackward0>)
tensor(2.2154, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   408: 0.248
tensor(2.2266, grad_fn=<NllLossBackward0>)
tensor(1.9707, grad_fn=<NllLossBackward0>)
tensor(2.0309, grad_fn=<NllLossBackward0>)
tensor(2.0773, grad_fn=<NllLossBackward0>)
tensor(2.1328, grad_fn=<NllLossBackward0>)
tensor(2.0265, grad_fn=<NllLossBackward0>)
tensor(2.2879, grad_fn=<NllLossBackward0>)
tensor(2.2791, grad_fn=<NllLossBackward0>)
tensor(2.2882, grad_fn=<NllLossBackward0>)
tensor(1.9387, grad_fn=<NllLossBackward0>)
tensor(2.1121, grad_fn=<NllLossBackward0>)
tensor(2.1149, grad_fn=<NllLossBackward0>)
tensor(2.0208, grad_fn=<NllLossBackward0>)
tensor(2.4528, grad_fn=<NllLossBackward0>)
tensor(2.2642, grad_fn=<NllLossBackward0>)
tensor(1.9905, grad_fn=<NllLossBackward0>)
tensor(2.0751, grad_fn=<NllLossBackward0>)
tensor(2.2868, grad_fn=<NllLossBackward0>)
tensor(2.3554, grad_fn=<NllLossBackward0>)
tensor(2.1523, grad_fn=<NllLossBackward0>)
tensor(2.3762, grad_fn=<NllLossBackward0>)
tensor(2.2057, grad_fn=<NllLossBackward0>)
tensor(2.1516, grad_fn=<NllLossBackward0>)
tensor(2.1414, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   432: 0.255
tensor(2.1582, grad_fn=<NllLossBackward0>)
tensor(2.1605, grad_fn=<NllLossBackward0>)
tensor(1.9657, grad_fn=<NllLossBackward0>)
tensor(2.1830, grad_fn=<NllLossBackward0>)
tensor(2.1225, grad_fn=<NllLossBackward0>)
tensor(2.0470, grad_fn=<NllLossBackward0>)
tensor(2.2149, grad_fn=<NllLossBackward0>)
tensor(2.2589, grad_fn=<NllLossBackward0>)
tensor(2.0256, grad_fn=<NllLossBackward0>)
tensor(2.1855, grad_fn=<NllLossBackward0>)
tensor(2.1115, grad_fn=<NllLossBackward0>)
tensor(2.1943, grad_fn=<NllLossBackward0>)
tensor(2.0904, grad_fn=<NllLossBackward0>)
tensor(2.2344, grad_fn=<NllLossBackward0>)
tensor(2.1223, grad_fn=<NllLossBackward0>)
tensor(2.1716, grad_fn=<NllLossBackward0>)
tensor(2.0020, grad_fn=<NllLossBackward0>)
tensor(2.0674, grad_fn=<NllLossBackward0>)
tensor(1.9253, grad_fn=<NllLossBackward0>)
tensor(2.1589, grad_fn=<NllLossBackward0>)
tensor(2.1599, grad_fn=<NllLossBackward0>)
tensor(2.1982, grad_fn=<NllLossBackward0>)
tensor(2.0460, grad_fn=<NllLossBackward0>)
tensor(2.2088, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   456: 0.259
tensor(2.1487, grad_fn=<NllLossBackward0>)
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.1597, grad_fn=<NllLossBackward0>)
tensor(2.1473, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.1292, grad_fn=<NllLossBackward0>)
tensor(2.2652, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(1.9872, grad_fn=<NllLossBackward0>)
tensor(2.1831, grad_fn=<NllLossBackward0>)
tensor(1.9960, grad_fn=<NllLossBackward0>)
tensor(2.2048, grad_fn=<NllLossBackward0>)
tensor(2.0735, grad_fn=<NllLossBackward0>)
tensor(2.0912, grad_fn=<NllLossBackward0>)
tensor(2.0066, grad_fn=<NllLossBackward0>)
tensor(2.1167, grad_fn=<NllLossBackward0>)
tensor(2.3048, grad_fn=<NllLossBackward0>)
tensor(2.2008, grad_fn=<NllLossBackward0>)
tensor(2.1331, grad_fn=<NllLossBackward0>)
tensor(2.2627, grad_fn=<NllLossBackward0>)
tensor(1.8968, grad_fn=<NllLossBackward0>)
tensor(2.4337, grad_fn=<NllLossBackward0>)
tensor(2.0500, grad_fn=<NllLossBackward0>)
tensor(1.9887, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   480: 0.264
tensor(2.1339, grad_fn=<NllLossBackward0>)
tensor(2.1673, grad_fn=<NllLossBackward0>)
tensor(2.2791, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.1922, grad_fn=<NllLossBackward0>)
tensor(2.1365, grad_fn=<NllLossBackward0>)
tensor(2.0405, grad_fn=<NllLossBackward0>)
tensor(2.4940, grad_fn=<NllLossBackward0>)
tensor(2.1822, grad_fn=<NllLossBackward0>)
tensor(1.9226, grad_fn=<NllLossBackward0>)
tensor(2.1142, grad_fn=<NllLossBackward0>)
tensor(2.3179, grad_fn=<NllLossBackward0>)
tensor(2.1630, grad_fn=<NllLossBackward0>)
tensor(2.1740, grad_fn=<NllLossBackward0>)
tensor(2.2682, grad_fn=<NllLossBackward0>)
tensor(2.1917, grad_fn=<NllLossBackward0>)
tensor(2.1214, grad_fn=<NllLossBackward0>)
tensor(2.1742, grad_fn=<NllLossBackward0>)
tensor(2.0213, grad_fn=<NllLossBackward0>)
tensor(2.1475, grad_fn=<NllLossBackward0>)
tensor(2.1787, grad_fn=<NllLossBackward0>)
tensor(2.3137, grad_fn=<NllLossBackward0>)
tensor(2.3318, grad_fn=<NllLossBackward0>)
tensor(2.1018, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   504: 0.233
tensor(2.0726, grad_fn=<NllLossBackward0>)
tensor(2.4243, grad_fn=<NllLossBackward0>)
tensor(2.1974, grad_fn=<NllLossBackward0>)
tensor(2.0632, grad_fn=<NllLossBackward0>)
tensor(2.0371, grad_fn=<NllLossBackward0>)
tensor(2.1357, grad_fn=<NllLossBackward0>)
tensor(1.8894, grad_fn=<NllLossBackward0>)
tensor(2.2692, grad_fn=<NllLossBackward0>)
tensor(1.9772, grad_fn=<NllLossBackward0>)
tensor(2.0867, grad_fn=<NllLossBackward0>)
tensor(2.3655, grad_fn=<NllLossBackward0>)
tensor(2.1230, grad_fn=<NllLossBackward0>)
tensor(2.1038, grad_fn=<NllLossBackward0>)
tensor(2.0349, grad_fn=<NllLossBackward0>)
tensor(2.0335, grad_fn=<NllLossBackward0>)
tensor(2.0344, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
tensor(2.4129, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.2446, grad_fn=<NllLossBackward0>)
tensor(2.1665, grad_fn=<NllLossBackward0>)
tensor(2.0893, grad_fn=<NllLossBackward0>)
tensor(1.8173, grad_fn=<NllLossBackward0>)
tensor(2.3624, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   528: 0.266
tensor(2.1277, grad_fn=<NllLossBackward0>)
tensor(2.0086, grad_fn=<NllLossBackward0>)
tensor(2.1503, grad_fn=<NllLossBackward0>)
tensor(1.9520, grad_fn=<NllLossBackward0>)
tensor(1.9338, grad_fn=<NllLossBackward0>)
tensor(2.0350, grad_fn=<NllLossBackward0>)
tensor(2.3036, grad_fn=<NllLossBackward0>)
tensor(2.1122, grad_fn=<NllLossBackward0>)
tensor(1.9981, grad_fn=<NllLossBackward0>)
tensor(2.0928, grad_fn=<NllLossBackward0>)
tensor(2.3176, grad_fn=<NllLossBackward0>)
tensor(2.2570, grad_fn=<NllLossBackward0>)
tensor(2.2720, grad_fn=<NllLossBackward0>)
tensor(2.2378, grad_fn=<NllLossBackward0>)
tensor(2.0329, grad_fn=<NllLossBackward0>)
tensor(2.1205, grad_fn=<NllLossBackward0>)
tensor(2.2028, grad_fn=<NllLossBackward0>)
tensor(2.1696, grad_fn=<NllLossBackward0>)
tensor(2.0788, grad_fn=<NllLossBackward0>)
tensor(2.0977, grad_fn=<NllLossBackward0>)
tensor(2.2004, grad_fn=<NllLossBackward0>)
tensor(2.2064, grad_fn=<NllLossBackward0>)
tensor(2.1732, grad_fn=<NllLossBackward0>)
tensor(2.1494, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   552: 0.281
tensor(2.1368, grad_fn=<NllLossBackward0>)
tensor(2.1787, grad_fn=<NllLossBackward0>)
tensor(2.0501, grad_fn=<NllLossBackward0>)
tensor(2.1601, grad_fn=<NllLossBackward0>)
tensor(2.3370, grad_fn=<NllLossBackward0>)
tensor(2.0553, grad_fn=<NllLossBackward0>)
tensor(2.1733, grad_fn=<NllLossBackward0>)
tensor(2.0716, grad_fn=<NllLossBackward0>)
tensor(2.1842, grad_fn=<NllLossBackward0>)
tensor(2.3257, grad_fn=<NllLossBackward0>)
tensor(2.1453, grad_fn=<NllLossBackward0>)
tensor(2.3333, grad_fn=<NllLossBackward0>)
tensor(1.9784, grad_fn=<NllLossBackward0>)
tensor(2.2154, grad_fn=<NllLossBackward0>)
tensor(2.1330, grad_fn=<NllLossBackward0>)
tensor(2.2002, grad_fn=<NllLossBackward0>)
tensor(2.1067, grad_fn=<NllLossBackward0>)
tensor(1.9284, grad_fn=<NllLossBackward0>)
tensor(1.9730, grad_fn=<NllLossBackward0>)
tensor(2.0498, grad_fn=<NllLossBackward0>)
tensor(2.1240, grad_fn=<NllLossBackward0>)
tensor(1.9395, grad_fn=<NllLossBackward0>)
tensor(2.0814, grad_fn=<NllLossBackward0>)
tensor(2.0823, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   576: 0.257
tensor(2.0699, grad_fn=<NllLossBackward0>)
tensor(2.0990, grad_fn=<NllLossBackward0>)
tensor(2.2358, grad_fn=<NllLossBackward0>)
tensor(2.0506, grad_fn=<NllLossBackward0>)
tensor(2.1104, grad_fn=<NllLossBackward0>)
tensor(2.1231, grad_fn=<NllLossBackward0>)
tensor(2.0977, grad_fn=<NllLossBackward0>)
tensor(2.1837, grad_fn=<NllLossBackward0>)
tensor(2.2606, grad_fn=<NllLossBackward0>)
tensor(2.2050, grad_fn=<NllLossBackward0>)
tensor(2.1862, grad_fn=<NllLossBackward0>)
tensor(1.8656, grad_fn=<NllLossBackward0>)
tensor(2.2863, grad_fn=<NllLossBackward0>)
tensor(2.0440, grad_fn=<NllLossBackward0>)
tensor(1.7978, grad_fn=<NllLossBackward0>)
tensor(2.1611, grad_fn=<NllLossBackward0>)
tensor(2.1210, grad_fn=<NllLossBackward0>)
tensor(2.1054, grad_fn=<NllLossBackward0>)
tensor(2.0243, grad_fn=<NllLossBackward0>)
tensor(2.1530, grad_fn=<NllLossBackward0>)
tensor(2.0231, grad_fn=<NllLossBackward0>)
tensor(2.2001, grad_fn=<NllLossBackward0>)
tensor(2.1269, grad_fn=<NllLossBackward0>)
tensor(2.1908, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   600: 0.281
tensor(2.1117, grad_fn=<NllLossBackward0>)
tensor(2.1034, grad_fn=<NllLossBackward0>)
tensor(2.1278, grad_fn=<NllLossBackward0>)
tensor(2.0626, grad_fn=<NllLossBackward0>)
tensor(2.1436, grad_fn=<NllLossBackward0>)
tensor(1.8731, grad_fn=<NllLossBackward0>)
tensor(1.8730, grad_fn=<NllLossBackward0>)
tensor(2.0603, grad_fn=<NllLossBackward0>)
tensor(1.9250, grad_fn=<NllLossBackward0>)
tensor(2.0612, grad_fn=<NllLossBackward0>)
tensor(1.9482, grad_fn=<NllLossBackward0>)
tensor(2.1005, grad_fn=<NllLossBackward0>)
tensor(2.1424, grad_fn=<NllLossBackward0>)
tensor(2.1617, grad_fn=<NllLossBackward0>)
tensor(2.4632, grad_fn=<NllLossBackward0>)
tensor(2.2242, grad_fn=<NllLossBackward0>)
tensor(1.9002, grad_fn=<NllLossBackward0>)
tensor(2.0548, grad_fn=<NllLossBackward0>)
tensor(2.0791, grad_fn=<NllLossBackward0>)
tensor(2.0726, grad_fn=<NllLossBackward0>)
tensor(1.8414, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.5134, grad_fn=<NllLossBackward0>)
tensor(2.1134, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   624: 0.306
tensor(2.1186, grad_fn=<NllLossBackward0>)
tensor(2.1950, grad_fn=<NllLossBackward0>)
tensor(2.1375, grad_fn=<NllLossBackward0>)
tensor(2.0941, grad_fn=<NllLossBackward0>)
tensor(1.8792, grad_fn=<NllLossBackward0>)
tensor(1.9210, grad_fn=<NllLossBackward0>)
tensor(2.3205, grad_fn=<NllLossBackward0>)
tensor(2.2430, grad_fn=<NllLossBackward0>)
tensor(1.9289, grad_fn=<NllLossBackward0>)
tensor(2.2257, grad_fn=<NllLossBackward0>)
tensor(2.0480, grad_fn=<NllLossBackward0>)
tensor(2.0708, grad_fn=<NllLossBackward0>)
tensor(2.1197, grad_fn=<NllLossBackward0>)
tensor(2.1296, grad_fn=<NllLossBackward0>)
tensor(1.9601, grad_fn=<NllLossBackward0>)
tensor(2.1277, grad_fn=<NllLossBackward0>)
tensor(2.0790, grad_fn=<NllLossBackward0>)
tensor(2.0948, grad_fn=<NllLossBackward0>)
tensor(1.8056, grad_fn=<NllLossBackward0>)
tensor(2.1315, grad_fn=<NllLossBackward0>)
tensor(2.0959, grad_fn=<NllLossBackward0>)
tensor(2.2361, grad_fn=<NllLossBackward0>)
tensor(2.0831, grad_fn=<NllLossBackward0>)
tensor(2.1898, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   648: 0.290
tensor(2.0337, grad_fn=<NllLossBackward0>)
tensor(2.1934, grad_fn=<NllLossBackward0>)
tensor(2.1919, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(2.1107, grad_fn=<NllLossBackward0>)
tensor(1.9887, grad_fn=<NllLossBackward0>)
tensor(2.2233, grad_fn=<NllLossBackward0>)
tensor(2.1056, grad_fn=<NllLossBackward0>)
tensor(2.0133, grad_fn=<NllLossBackward0>)
tensor(2.0026, grad_fn=<NllLossBackward0>)
tensor(2.0914, grad_fn=<NllLossBackward0>)
tensor(1.9671, grad_fn=<NllLossBackward0>)
tensor(2.2182, grad_fn=<NllLossBackward0>)
tensor(2.1582, grad_fn=<NllLossBackward0>)
tensor(2.0348, grad_fn=<NllLossBackward0>)
tensor(2.1212, grad_fn=<NllLossBackward0>)
tensor(2.0162, grad_fn=<NllLossBackward0>)
tensor(2.0734, grad_fn=<NllLossBackward0>)
tensor(1.9935, grad_fn=<NllLossBackward0>)
tensor(2.2179, grad_fn=<NllLossBackward0>)
tensor(1.8457, grad_fn=<NllLossBackward0>)
tensor(2.1356, grad_fn=<NllLossBackward0>)
tensor(2.2767, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   672: 0.264
tensor(1.9872, grad_fn=<NllLossBackward0>)
tensor(1.9868, grad_fn=<NllLossBackward0>)
tensor(2.2936, grad_fn=<NllLossBackward0>)
tensor(2.1149, grad_fn=<NllLossBackward0>)
tensor(2.1385, grad_fn=<NllLossBackward0>)
tensor(2.0855, grad_fn=<NllLossBackward0>)
tensor(2.1293, grad_fn=<NllLossBackward0>)
tensor(2.0566, grad_fn=<NllLossBackward0>)
tensor(2.0814, grad_fn=<NllLossBackward0>)
tensor(2.0877, grad_fn=<NllLossBackward0>)
tensor(2.0612, grad_fn=<NllLossBackward0>)
tensor(2.0528, grad_fn=<NllLossBackward0>)
tensor(2.0086, grad_fn=<NllLossBackward0>)
tensor(2.0394, grad_fn=<NllLossBackward0>)
tensor(2.2414, grad_fn=<NllLossBackward0>)
tensor(1.9209, grad_fn=<NllLossBackward0>)
tensor(2.1801, grad_fn=<NllLossBackward0>)
tensor(2.0035, grad_fn=<NllLossBackward0>)
tensor(2.0858, grad_fn=<NllLossBackward0>)
tensor(2.0149, grad_fn=<NllLossBackward0>)
tensor(2.3590, grad_fn=<NllLossBackward0>)
tensor(2.1788, grad_fn=<NllLossBackward0>)
tensor(2.2135, grad_fn=<NllLossBackward0>)
tensor(2.2640, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   696: 0.262
tensor(2.1596, grad_fn=<NllLossBackward0>)
tensor(2.3316, grad_fn=<NllLossBackward0>)
tensor(2.2995, grad_fn=<NllLossBackward0>)
tensor(2.1612, grad_fn=<NllLossBackward0>)
tensor(2.0186, grad_fn=<NllLossBackward0>)
tensor(2.1671, grad_fn=<NllLossBackward0>)
tensor(2.2221, grad_fn=<NllLossBackward0>)
tensor(2.1640, grad_fn=<NllLossBackward0>)
tensor(2.2057, grad_fn=<NllLossBackward0>)
tensor(2.0988, grad_fn=<NllLossBackward0>)
tensor(2.0172, grad_fn=<NllLossBackward0>)
tensor(2.2466, grad_fn=<NllLossBackward0>)
tensor(2.0834, grad_fn=<NllLossBackward0>)
tensor(2.1635, grad_fn=<NllLossBackward0>)
tensor(2.2785, grad_fn=<NllLossBackward0>)
tensor(2.2225, grad_fn=<NllLossBackward0>)
tensor(2.0968, grad_fn=<NllLossBackward0>)
tensor(2.2649, grad_fn=<NllLossBackward0>)
tensor(2.1931, grad_fn=<NllLossBackward0>)
tensor(2.1277, grad_fn=<NllLossBackward0>)
tensor(2.3530, grad_fn=<NllLossBackward0>)
tensor(2.2727, grad_fn=<NllLossBackward0>)
tensor(2.2689, grad_fn=<NllLossBackward0>)
tensor(2.2934, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   720: 0.229
tensor(2.1763, grad_fn=<NllLossBackward0>)
tensor(2.2548, grad_fn=<NllLossBackward0>)
tensor(2.0185, grad_fn=<NllLossBackward0>)
tensor(2.0475, grad_fn=<NllLossBackward0>)
tensor(1.9217, grad_fn=<NllLossBackward0>)
tensor(2.1897, grad_fn=<NllLossBackward0>)
tensor(2.2945, grad_fn=<NllLossBackward0>)
tensor(2.2722, grad_fn=<NllLossBackward0>)
tensor(1.9879, grad_fn=<NllLossBackward0>)
tensor(2.1896, grad_fn=<NllLossBackward0>)
tensor(2.1058, grad_fn=<NllLossBackward0>)
tensor(2.3061, grad_fn=<NllLossBackward0>)
tensor(2.0137, grad_fn=<NllLossBackward0>)
tensor(2.1949, grad_fn=<NllLossBackward0>)
tensor(2.0856, grad_fn=<NllLossBackward0>)
tensor(2.0820, grad_fn=<NllLossBackward0>)
tensor(2.1361, grad_fn=<NllLossBackward0>)
tensor(2.2872, grad_fn=<NllLossBackward0>)
tensor(2.0805, grad_fn=<NllLossBackward0>)
tensor(2.0723, grad_fn=<NllLossBackward0>)
tensor(2.2872, grad_fn=<NllLossBackward0>)
tensor(2.0339, grad_fn=<NllLossBackward0>)
tensor(1.9455, grad_fn=<NllLossBackward0>)
tensor(2.2632, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   744: 0.259
tensor(2.0427, grad_fn=<NllLossBackward0>)
tensor(2.2247, grad_fn=<NllLossBackward0>)
tensor(1.9989, grad_fn=<NllLossBackward0>)
tensor(2.1312, grad_fn=<NllLossBackward0>)
tensor(1.8807, grad_fn=<NllLossBackward0>)
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.1055, grad_fn=<NllLossBackward0>)
tensor(2.2016, grad_fn=<NllLossBackward0>)
tensor(2.0613, grad_fn=<NllLossBackward0>)
tensor(2.1366, grad_fn=<NllLossBackward0>)
tensor(2.2174, grad_fn=<NllLossBackward0>)
tensor(2.1967, grad_fn=<NllLossBackward0>)
tensor(2.1350, grad_fn=<NllLossBackward0>)
tensor(2.2235, grad_fn=<NllLossBackward0>)
tensor(2.3525, grad_fn=<NllLossBackward0>)
tensor(2.0912, grad_fn=<NllLossBackward0>)
tensor(2.1199, grad_fn=<NllLossBackward0>)
tensor(1.8277, grad_fn=<NllLossBackward0>)
tensor(1.9771, grad_fn=<NllLossBackward0>)
tensor(2.2031, grad_fn=<NllLossBackward0>)
tensor(2.0750, grad_fn=<NllLossBackward0>)
tensor(2.2034, grad_fn=<NllLossBackward0>)
tensor(1.9109, grad_fn=<NllLossBackward0>)
tensor(2.0917, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   768: 0.280
tensor(1.9795, grad_fn=<NllLossBackward0>)
tensor(2.1798, grad_fn=<NllLossBackward0>)
tensor(2.1330, grad_fn=<NllLossBackward0>)
tensor(2.0892, grad_fn=<NllLossBackward0>)
tensor(2.0708, grad_fn=<NllLossBackward0>)
tensor(2.1415, grad_fn=<NllLossBackward0>)
tensor(2.2201, grad_fn=<NllLossBackward0>)
tensor(2.1395, grad_fn=<NllLossBackward0>)
tensor(2.0836, grad_fn=<NllLossBackward0>)
tensor(2.0868, grad_fn=<NllLossBackward0>)
tensor(2.3487, grad_fn=<NllLossBackward0>)
tensor(2.2929, grad_fn=<NllLossBackward0>)
tensor(2.0905, grad_fn=<NllLossBackward0>)
tensor(2.1346, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.1030, grad_fn=<NllLossBackward0>)
tensor(1.9664, grad_fn=<NllLossBackward0>)
tensor(2.2265, grad_fn=<NllLossBackward0>)
tensor(2.2414, grad_fn=<NllLossBackward0>)
tensor(2.1417, grad_fn=<NllLossBackward0>)
tensor(2.0563, grad_fn=<NllLossBackward0>)
tensor(1.8791, grad_fn=<NllLossBackward0>)
tensor(2.2678, grad_fn=<NllLossBackward0>)
tensor(2.0500, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   792: 0.247
tensor(1.9854, grad_fn=<NllLossBackward0>)
tensor(2.2275, grad_fn=<NllLossBackward0>)
tensor(2.2345, grad_fn=<NllLossBackward0>)
tensor(2.2065, grad_fn=<NllLossBackward0>)
tensor(2.4473, grad_fn=<NllLossBackward0>)
tensor(2.0888, grad_fn=<NllLossBackward0>)
tensor(1.9198, grad_fn=<NllLossBackward0>)
tensor(2.2105, grad_fn=<NllLossBackward0>)
tensor(2.4313, grad_fn=<NllLossBackward0>)
tensor(2.2643, grad_fn=<NllLossBackward0>)
tensor(2.2946, grad_fn=<NllLossBackward0>)
tensor(2.2895, grad_fn=<NllLossBackward0>)
tensor(1.8509, grad_fn=<NllLossBackward0>)
tensor(2.1073, grad_fn=<NllLossBackward0>)
tensor(2.0228, grad_fn=<NllLossBackward0>)
tensor(2.0884, grad_fn=<NllLossBackward0>)
tensor(2.2305, grad_fn=<NllLossBackward0>)
tensor(1.7723, grad_fn=<NllLossBackward0>)
tensor(2.1148, grad_fn=<NllLossBackward0>)
tensor(2.0300, grad_fn=<NllLossBackward0>)
tensor(2.1328, grad_fn=<NllLossBackward0>)
tensor(2.1422, grad_fn=<NllLossBackward0>)
tensor(2.1179, grad_fn=<NllLossBackward0>)
tensor(2.1087, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   816: 0.252
tensor(2.1950, grad_fn=<NllLossBackward0>)
tensor(2.1672, grad_fn=<NllLossBackward0>)
tensor(2.2130, grad_fn=<NllLossBackward0>)
tensor(2.0258, grad_fn=<NllLossBackward0>)
tensor(1.9631, grad_fn=<NllLossBackward0>)
tensor(2.1406, grad_fn=<NllLossBackward0>)
tensor(1.9066, grad_fn=<NllLossBackward0>)
tensor(2.0067, grad_fn=<NllLossBackward0>)
tensor(2.0614, grad_fn=<NllLossBackward0>)
tensor(2.0521, grad_fn=<NllLossBackward0>)
tensor(2.0231, grad_fn=<NllLossBackward0>)
tensor(2.2075, grad_fn=<NllLossBackward0>)
tensor(2.0930, grad_fn=<NllLossBackward0>)
tensor(2.2388, grad_fn=<NllLossBackward0>)
tensor(2.0228, grad_fn=<NllLossBackward0>)
tensor(2.1525, grad_fn=<NllLossBackward0>)
tensor(1.9863, grad_fn=<NllLossBackward0>)
tensor(2.1620, grad_fn=<NllLossBackward0>)
tensor(2.0375, grad_fn=<NllLossBackward0>)
tensor(2.1196, grad_fn=<NllLossBackward0>)
tensor(1.9330, grad_fn=<NllLossBackward0>)
tensor(2.0854, grad_fn=<NllLossBackward0>)
tensor(2.0509, grad_fn=<NllLossBackward0>)
tensor(2.2945, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   840: 0.253
tensor(2.1061, grad_fn=<NllLossBackward0>)
tensor(2.1535, grad_fn=<NllLossBackward0>)
tensor(2.2195, grad_fn=<NllLossBackward0>)
tensor(2.0938, grad_fn=<NllLossBackward0>)
tensor(2.1220, grad_fn=<NllLossBackward0>)
tensor(2.2452, grad_fn=<NllLossBackward0>)
tensor(1.8693, grad_fn=<NllLossBackward0>)
tensor(2.1202, grad_fn=<NllLossBackward0>)
tensor(2.2744, grad_fn=<NllLossBackward0>)
tensor(2.0077, grad_fn=<NllLossBackward0>)
tensor(2.2218, grad_fn=<NllLossBackward0>)
tensor(1.9527, grad_fn=<NllLossBackward0>)
tensor(1.9719, grad_fn=<NllLossBackward0>)
tensor(1.9003, grad_fn=<NllLossBackward0>)
tensor(2.1684, grad_fn=<NllLossBackward0>)
tensor(1.9960, grad_fn=<NllLossBackward0>)
tensor(1.9677, grad_fn=<NllLossBackward0>)
tensor(2.2255, grad_fn=<NllLossBackward0>)
tensor(2.0107, grad_fn=<NllLossBackward0>)
tensor(2.3910, grad_fn=<NllLossBackward0>)
tensor(2.0372, grad_fn=<NllLossBackward0>)
tensor(2.0331, grad_fn=<NllLossBackward0>)
tensor(2.1745, grad_fn=<NllLossBackward0>)
tensor(2.0476, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   864: 0.280
tensor(2.0226, grad_fn=<NllLossBackward0>)
tensor(2.0083, grad_fn=<NllLossBackward0>)
tensor(2.1714, grad_fn=<NllLossBackward0>)
tensor(2.0808, grad_fn=<NllLossBackward0>)
tensor(1.8593, grad_fn=<NllLossBackward0>)
tensor(2.2646, grad_fn=<NllLossBackward0>)
tensor(2.1698, grad_fn=<NllLossBackward0>)
tensor(2.2033, grad_fn=<NllLossBackward0>)
tensor(2.3846, grad_fn=<NllLossBackward0>)
tensor(2.1879, grad_fn=<NllLossBackward0>)
tensor(2.1457, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.2065, grad_fn=<NllLossBackward0>)
tensor(2.0355, grad_fn=<NllLossBackward0>)
tensor(2.1853, grad_fn=<NllLossBackward0>)
tensor(2.1719, grad_fn=<NllLossBackward0>)
tensor(2.2038, grad_fn=<NllLossBackward0>)
tensor(1.7092, grad_fn=<NllLossBackward0>)
tensor(2.0721, grad_fn=<NllLossBackward0>)
tensor(2.0982, grad_fn=<NllLossBackward0>)
tensor(2.0650, grad_fn=<NllLossBackward0>)
tensor(2.1187, grad_fn=<NllLossBackward0>)
tensor(1.9354, grad_fn=<NllLossBackward0>)
tensor(1.8710, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   888: 0.276
tensor(2.2271, grad_fn=<NllLossBackward0>)
tensor(2.2648, grad_fn=<NllLossBackward0>)
tensor(2.2070, grad_fn=<NllLossBackward0>)
tensor(2.3452, grad_fn=<NllLossBackward0>)
tensor(1.9838, grad_fn=<NllLossBackward0>)
tensor(2.0889, grad_fn=<NllLossBackward0>)
tensor(2.1534, grad_fn=<NllLossBackward0>)
tensor(2.0822, grad_fn=<NllLossBackward0>)
tensor(2.1957, grad_fn=<NllLossBackward0>)
tensor(2.1739, grad_fn=<NllLossBackward0>)
tensor(2.0644, grad_fn=<NllLossBackward0>)
tensor(2.0874, grad_fn=<NllLossBackward0>)
tensor(2.2350, grad_fn=<NllLossBackward0>)
tensor(2.1932, grad_fn=<NllLossBackward0>)
tensor(2.0891, grad_fn=<NllLossBackward0>)
tensor(2.0239, grad_fn=<NllLossBackward0>)
tensor(2.0076, grad_fn=<NllLossBackward0>)
tensor(2.0899, grad_fn=<NllLossBackward0>)
tensor(1.9764, grad_fn=<NllLossBackward0>)
tensor(2.1783, grad_fn=<NllLossBackward0>)
tensor(2.2616, grad_fn=<NllLossBackward0>)
tensor(2.2460, grad_fn=<NllLossBackward0>)
tensor(2.0155, grad_fn=<NllLossBackward0>)
tensor(1.9840, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   912: 0.267
tensor(1.9029, grad_fn=<NllLossBackward0>)
tensor(2.0341, grad_fn=<NllLossBackward0>)
tensor(2.0083, grad_fn=<NllLossBackward0>)
tensor(2.1399, grad_fn=<NllLossBackward0>)
tensor(2.1710, grad_fn=<NllLossBackward0>)
tensor(1.9959, grad_fn=<NllLossBackward0>)
tensor(2.0241, grad_fn=<NllLossBackward0>)
tensor(2.2284, grad_fn=<NllLossBackward0>)
tensor(2.3061, grad_fn=<NllLossBackward0>)
tensor(2.0774, grad_fn=<NllLossBackward0>)
tensor(2.3313, grad_fn=<NllLossBackward0>)
tensor(2.0117, grad_fn=<NllLossBackward0>)
tensor(2.1157, grad_fn=<NllLossBackward0>)
tensor(2.1735, grad_fn=<NllLossBackward0>)
tensor(1.8833, grad_fn=<NllLossBackward0>)
tensor(2.1014, grad_fn=<NllLossBackward0>)
tensor(2.4196, grad_fn=<NllLossBackward0>)
tensor(1.9951, grad_fn=<NllLossBackward0>)
tensor(2.0930, grad_fn=<NllLossBackward0>)
tensor(1.9583, grad_fn=<NllLossBackward0>)
tensor(2.1195, grad_fn=<NllLossBackward0>)
tensor(2.0667, grad_fn=<NllLossBackward0>)
tensor(2.1019, grad_fn=<NllLossBackward0>)
tensor(2.0269, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   936: 0.283
tensor(2.1139, grad_fn=<NllLossBackward0>)
tensor(2.0453, grad_fn=<NllLossBackward0>)
tensor(2.2687, grad_fn=<NllLossBackward0>)
tensor(2.1297, grad_fn=<NllLossBackward0>)
tensor(2.1972, grad_fn=<NllLossBackward0>)
tensor(2.1469, grad_fn=<NllLossBackward0>)
tensor(2.0517, grad_fn=<NllLossBackward0>)
tensor(1.9375, grad_fn=<NllLossBackward0>)
tensor(2.1758, grad_fn=<NllLossBackward0>)
tensor(2.1981, grad_fn=<NllLossBackward0>)
tensor(2.0077, grad_fn=<NllLossBackward0>)
tensor(2.1549, grad_fn=<NllLossBackward0>)
tensor(2.3845, grad_fn=<NllLossBackward0>)
tensor(2.2292, grad_fn=<NllLossBackward0>)
tensor(2.0558, grad_fn=<NllLossBackward0>)
tensor(2.2360, grad_fn=<NllLossBackward0>)
tensor(2.1198, grad_fn=<NllLossBackward0>)
tensor(2.0925, grad_fn=<NllLossBackward0>)
tensor(2.0041, grad_fn=<NllLossBackward0>)
tensor(2.4732, grad_fn=<NllLossBackward0>)
tensor(2.1325, grad_fn=<NllLossBackward0>)
tensor(1.9662, grad_fn=<NllLossBackward0>)
tensor(2.1991, grad_fn=<NllLossBackward0>)
tensor(2.3765, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   960: 0.273
tensor(2.0889, grad_fn=<NllLossBackward0>)
tensor(1.9068, grad_fn=<NllLossBackward0>)
tensor(2.0926, grad_fn=<NllLossBackward0>)
tensor(2.1337, grad_fn=<NllLossBackward0>)
tensor(2.2663, grad_fn=<NllLossBackward0>)
tensor(2.0879, grad_fn=<NllLossBackward0>)
tensor(2.1983, grad_fn=<NllLossBackward0>)
tensor(1.9848, grad_fn=<NllLossBackward0>)
tensor(2.2505, grad_fn=<NllLossBackward0>)
tensor(2.2700, grad_fn=<NllLossBackward0>)
tensor(2.0553, grad_fn=<NllLossBackward0>)
tensor(1.9728, grad_fn=<NllLossBackward0>)
tensor(2.2728, grad_fn=<NllLossBackward0>)
tensor(2.2904, grad_fn=<NllLossBackward0>)
tensor(2.1819, grad_fn=<NllLossBackward0>)
tensor(1.9430, grad_fn=<NllLossBackward0>)
tensor(1.9941, grad_fn=<NllLossBackward0>)
tensor(2.1041, grad_fn=<NllLossBackward0>)
tensor(1.9326, grad_fn=<NllLossBackward0>)
tensor(2.0792, grad_fn=<NllLossBackward0>)
tensor(2.1415, grad_fn=<NllLossBackward0>)
tensor(2.1340, grad_fn=<NllLossBackward0>)
tensor(2.2257, grad_fn=<NllLossBackward0>)
tensor(2.3079, grad_fn=<NllLossBackward0>)
Training loss after mini-batch   984: 0.264
tensor(2.0390, grad_fn=<NllLossBackward0>)
tensor(1.9206, grad_fn=<NllLossBackward0>)
tensor(2.0242, grad_fn=<NllLossBackward0>)
tensor(2.0356, grad_fn=<NllLossBackward0>)
tensor(2.3113, grad_fn=<NllLossBackward0>)
tensor(2.2853, grad_fn=<NllLossBackward0>)
tensor(2.2043, grad_fn=<NllLossBackward0>)
tensor(2.0436, grad_fn=<NllLossBackward0>)
tensor(1.9210, grad_fn=<NllLossBackward0>)
tensor(2.2388, grad_fn=<NllLossBackward0>)
tensor(2.0576, grad_fn=<NllLossBackward0>)
tensor(2.2254, grad_fn=<NllLossBackward0>)
tensor(2.1548, grad_fn=<NllLossBackward0>)
tensor(2.0644, grad_fn=<NllLossBackward0>)
tensor(2.0834, grad_fn=<NllLossBackward0>)
tensor(2.2754, grad_fn=<NllLossBackward0>)
tensor(2.0666, grad_fn=<NllLossBackward0>)
tensor(2.1832, grad_fn=<NllLossBackward0>)
tensor(2.1245, grad_fn=<NllLossBackward0>)
tensor(1.8683, grad_fn=<NllLossBackward0>)
tensor(2.2963, grad_fn=<NllLossBackward0>)
tensor(1.8089, grad_fn=<NllLossBackward0>)
tensor(2.1117, grad_fn=<NllLossBackward0>)
tensor(2.0172, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1008: 0.292
tensor(2.1820, grad_fn=<NllLossBackward0>)
tensor(2.1999, grad_fn=<NllLossBackward0>)
tensor(2.0295, grad_fn=<NllLossBackward0>)
tensor(2.1972, grad_fn=<NllLossBackward0>)
tensor(2.2082, grad_fn=<NllLossBackward0>)
tensor(2.1434, grad_fn=<NllLossBackward0>)
tensor(2.0432, grad_fn=<NllLossBackward0>)
tensor(2.1619, grad_fn=<NllLossBackward0>)
tensor(2.1850, grad_fn=<NllLossBackward0>)
tensor(1.9462, grad_fn=<NllLossBackward0>)
tensor(2.1827, grad_fn=<NllLossBackward0>)
tensor(2.1530, grad_fn=<NllLossBackward0>)
tensor(2.1862, grad_fn=<NllLossBackward0>)
tensor(2.3587, grad_fn=<NllLossBackward0>)
tensor(2.1178, grad_fn=<NllLossBackward0>)
tensor(2.3154, grad_fn=<NllLossBackward0>)
tensor(2.0952, grad_fn=<NllLossBackward0>)
tensor(1.9703, grad_fn=<NllLossBackward0>)
tensor(2.0762, grad_fn=<NllLossBackward0>)
tensor(2.1227, grad_fn=<NllLossBackward0>)
tensor(2.2605, grad_fn=<NllLossBackward0>)
tensor(1.9139, grad_fn=<NllLossBackward0>)
tensor(2.1562, grad_fn=<NllLossBackward0>)
tensor(2.2306, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1032: 0.255
tensor(2.0366, grad_fn=<NllLossBackward0>)
tensor(2.0255, grad_fn=<NllLossBackward0>)
tensor(2.1384, grad_fn=<NllLossBackward0>)
tensor(2.2644, grad_fn=<NllLossBackward0>)
tensor(1.9058, grad_fn=<NllLossBackward0>)
tensor(2.0978, grad_fn=<NllLossBackward0>)
tensor(2.1628, grad_fn=<NllLossBackward0>)
tensor(2.1994, grad_fn=<NllLossBackward0>)
tensor(1.9188, grad_fn=<NllLossBackward0>)
tensor(2.1549, grad_fn=<NllLossBackward0>)
tensor(2.3152, grad_fn=<NllLossBackward0>)
tensor(2.2213, grad_fn=<NllLossBackward0>)
tensor(1.9809, grad_fn=<NllLossBackward0>)
tensor(2.2420, grad_fn=<NllLossBackward0>)
tensor(1.9703, grad_fn=<NllLossBackward0>)
tensor(2.1999, grad_fn=<NllLossBackward0>)
tensor(2.2063, grad_fn=<NllLossBackward0>)
tensor(2.0830, grad_fn=<NllLossBackward0>)
tensor(2.2027, grad_fn=<NllLossBackward0>)
tensor(1.9929, grad_fn=<NllLossBackward0>)
tensor(2.0400, grad_fn=<NllLossBackward0>)
tensor(2.1098, grad_fn=<NllLossBackward0>)
tensor(2.2094, grad_fn=<NllLossBackward0>)
tensor(2.1462, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1056: 0.273
tensor(2.1568, grad_fn=<NllLossBackward0>)
tensor(2.2329, grad_fn=<NllLossBackward0>)
tensor(2.3025, grad_fn=<NllLossBackward0>)
tensor(2.1190, grad_fn=<NllLossBackward0>)
tensor(1.9664, grad_fn=<NllLossBackward0>)
tensor(2.0554, grad_fn=<NllLossBackward0>)
tensor(2.0830, grad_fn=<NllLossBackward0>)
tensor(2.4122, grad_fn=<NllLossBackward0>)
tensor(2.2915, grad_fn=<NllLossBackward0>)
tensor(2.1238, grad_fn=<NllLossBackward0>)
tensor(2.2803, grad_fn=<NllLossBackward0>)
tensor(2.1934, grad_fn=<NllLossBackward0>)
tensor(2.0906, grad_fn=<NllLossBackward0>)
tensor(2.2433, grad_fn=<NllLossBackward0>)
tensor(2.2209, grad_fn=<NllLossBackward0>)
tensor(2.1044, grad_fn=<NllLossBackward0>)
tensor(2.1540, grad_fn=<NllLossBackward0>)
tensor(2.3295, grad_fn=<NllLossBackward0>)
tensor(2.2026, grad_fn=<NllLossBackward0>)
tensor(2.3005, grad_fn=<NllLossBackward0>)
tensor(2.0154, grad_fn=<NllLossBackward0>)
tensor(2.1776, grad_fn=<NllLossBackward0>)
tensor(2.3862, grad_fn=<NllLossBackward0>)
tensor(2.2318, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1080: 0.255
tensor(2.1678, grad_fn=<NllLossBackward0>)
tensor(1.9452, grad_fn=<NllLossBackward0>)
tensor(2.1907, grad_fn=<NllLossBackward0>)
tensor(2.0580, grad_fn=<NllLossBackward0>)
tensor(1.8899, grad_fn=<NllLossBackward0>)
tensor(2.1909, grad_fn=<NllLossBackward0>)
tensor(2.1440, grad_fn=<NllLossBackward0>)
tensor(2.1471, grad_fn=<NllLossBackward0>)
tensor(2.0973, grad_fn=<NllLossBackward0>)
tensor(2.2308, grad_fn=<NllLossBackward0>)
tensor(2.0333, grad_fn=<NllLossBackward0>)
tensor(2.2084, grad_fn=<NllLossBackward0>)
tensor(2.0424, grad_fn=<NllLossBackward0>)
tensor(2.1027, grad_fn=<NllLossBackward0>)
tensor(2.1558, grad_fn=<NllLossBackward0>)
tensor(2.1601, grad_fn=<NllLossBackward0>)
tensor(2.1912, grad_fn=<NllLossBackward0>)
tensor(1.9807, grad_fn=<NllLossBackward0>)
tensor(2.1623, grad_fn=<NllLossBackward0>)
tensor(2.1139, grad_fn=<NllLossBackward0>)
tensor(2.0893, grad_fn=<NllLossBackward0>)
tensor(2.3681, grad_fn=<NllLossBackward0>)
tensor(1.9218, grad_fn=<NllLossBackward0>)
tensor(2.0779, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1104: 0.281
tensor(1.9555, grad_fn=<NllLossBackward0>)
tensor(2.2759, grad_fn=<NllLossBackward0>)
tensor(2.1124, grad_fn=<NllLossBackward0>)
tensor(1.8398, grad_fn=<NllLossBackward0>)
tensor(2.0690, grad_fn=<NllLossBackward0>)
tensor(2.2248, grad_fn=<NllLossBackward0>)
tensor(2.3062, grad_fn=<NllLossBackward0>)
tensor(2.0553, grad_fn=<NllLossBackward0>)
tensor(2.2281, grad_fn=<NllLossBackward0>)
tensor(2.2660, grad_fn=<NllLossBackward0>)
tensor(2.0528, grad_fn=<NllLossBackward0>)
tensor(2.1668, grad_fn=<NllLossBackward0>)
tensor(1.6734, grad_fn=<NllLossBackward0>)
tensor(2.0421, grad_fn=<NllLossBackward0>)
tensor(2.1411, grad_fn=<NllLossBackward0>)
tensor(2.1408, grad_fn=<NllLossBackward0>)
tensor(2.2500, grad_fn=<NllLossBackward0>)
tensor(2.2859, grad_fn=<NllLossBackward0>)
tensor(1.9545, grad_fn=<NllLossBackward0>)
tensor(2.2869, grad_fn=<NllLossBackward0>)
tensor(2.0119, grad_fn=<NllLossBackward0>)
tensor(2.0989, grad_fn=<NllLossBackward0>)
tensor(2.4122, grad_fn=<NllLossBackward0>)
tensor(1.9573, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1128: 0.260
tensor(2.1760, grad_fn=<NllLossBackward0>)
tensor(2.2043, grad_fn=<NllLossBackward0>)
tensor(2.2146, grad_fn=<NllLossBackward0>)
tensor(1.9638, grad_fn=<NllLossBackward0>)
tensor(2.0499, grad_fn=<NllLossBackward0>)
tensor(2.0211, grad_fn=<NllLossBackward0>)
tensor(2.1774, grad_fn=<NllLossBackward0>)
tensor(2.1488, grad_fn=<NllLossBackward0>)
tensor(2.2275, grad_fn=<NllLossBackward0>)
tensor(2.0593, grad_fn=<NllLossBackward0>)
tensor(1.9979, grad_fn=<NllLossBackward0>)
tensor(1.9678, grad_fn=<NllLossBackward0>)
tensor(2.1030, grad_fn=<NllLossBackward0>)
tensor(2.1370, grad_fn=<NllLossBackward0>)
tensor(2.1263, grad_fn=<NllLossBackward0>)
tensor(2.0946, grad_fn=<NllLossBackward0>)
tensor(2.2275, grad_fn=<NllLossBackward0>)
tensor(1.9038, grad_fn=<NllLossBackward0>)
tensor(1.9721, grad_fn=<NllLossBackward0>)
tensor(2.0474, grad_fn=<NllLossBackward0>)
tensor(1.9506, grad_fn=<NllLossBackward0>)
tensor(2.0642, grad_fn=<NllLossBackward0>)
tensor(2.0883, grad_fn=<NllLossBackward0>)
tensor(2.2409, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1152: 0.280
tensor(2.1425, grad_fn=<NllLossBackward0>)
tensor(2.0723, grad_fn=<NllLossBackward0>)
tensor(2.1494, grad_fn=<NllLossBackward0>)
tensor(2.2614, grad_fn=<NllLossBackward0>)
tensor(2.1107, grad_fn=<NllLossBackward0>)
tensor(2.0092, grad_fn=<NllLossBackward0>)
tensor(2.3477, grad_fn=<NllLossBackward0>)
tensor(1.9823, grad_fn=<NllLossBackward0>)
tensor(2.1282, grad_fn=<NllLossBackward0>)
tensor(2.1464, grad_fn=<NllLossBackward0>)
tensor(1.9869, grad_fn=<NllLossBackward0>)
tensor(1.9345, grad_fn=<NllLossBackward0>)
tensor(2.3170, grad_fn=<NllLossBackward0>)
tensor(2.1534, grad_fn=<NllLossBackward0>)
tensor(2.1821, grad_fn=<NllLossBackward0>)
tensor(2.3122, grad_fn=<NllLossBackward0>)
tensor(2.2827, grad_fn=<NllLossBackward0>)
tensor(2.1643, grad_fn=<NllLossBackward0>)
tensor(2.1100, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.1072, grad_fn=<NllLossBackward0>)
tensor(2.2066, grad_fn=<NllLossBackward0>)
tensor(2.2288, grad_fn=<NllLossBackward0>)
tensor(2.0538, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1176: 0.238
tensor(2.1122, grad_fn=<NllLossBackward0>)
tensor(2.0756, grad_fn=<NllLossBackward0>)
tensor(2.0181, grad_fn=<NllLossBackward0>)
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(1.9599, grad_fn=<NllLossBackward0>)
tensor(2.1189, grad_fn=<NllLossBackward0>)
tensor(2.1072, grad_fn=<NllLossBackward0>)
tensor(2.0575, grad_fn=<NllLossBackward0>)
tensor(2.1634, grad_fn=<NllLossBackward0>)
tensor(2.1551, grad_fn=<NllLossBackward0>)
tensor(2.2135, grad_fn=<NllLossBackward0>)
tensor(2.2722, grad_fn=<NllLossBackward0>)
tensor(2.2870, grad_fn=<NllLossBackward0>)
tensor(2.0491, grad_fn=<NllLossBackward0>)
tensor(2.1787, grad_fn=<NllLossBackward0>)
tensor(1.9398, grad_fn=<NllLossBackward0>)
tensor(2.0139, grad_fn=<NllLossBackward0>)
tensor(2.2364, grad_fn=<NllLossBackward0>)
tensor(2.1089, grad_fn=<NllLossBackward0>)
tensor(2.0275, grad_fn=<NllLossBackward0>)
tensor(1.9290, grad_fn=<NllLossBackward0>)
tensor(2.1781, grad_fn=<NllLossBackward0>)
tensor(2.2160, grad_fn=<NllLossBackward0>)
tensor(1.9037, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1200: 0.290
tensor(2.0029, grad_fn=<NllLossBackward0>)
tensor(2.2028, grad_fn=<NllLossBackward0>)
tensor(2.2750, grad_fn=<NllLossBackward0>)
tensor(2.1099, grad_fn=<NllLossBackward0>)
tensor(1.9869, grad_fn=<NllLossBackward0>)
tensor(2.1691, grad_fn=<NllLossBackward0>)
tensor(2.0158, grad_fn=<NllLossBackward0>)
tensor(1.8608, grad_fn=<NllLossBackward0>)
tensor(2.2022, grad_fn=<NllLossBackward0>)
tensor(1.8880, grad_fn=<NllLossBackward0>)
tensor(2.2075, grad_fn=<NllLossBackward0>)
tensor(2.0856, grad_fn=<NllLossBackward0>)
tensor(2.2234, grad_fn=<NllLossBackward0>)
tensor(2.0299, grad_fn=<NllLossBackward0>)
tensor(1.8502, grad_fn=<NllLossBackward0>)
tensor(2.0675, grad_fn=<NllLossBackward0>)
tensor(1.8629, grad_fn=<NllLossBackward0>)
tensor(1.9194, grad_fn=<NllLossBackward0>)
tensor(2.1621, grad_fn=<NllLossBackward0>)
tensor(2.1656, grad_fn=<NllLossBackward0>)
tensor(2.3594, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(1.7719, grad_fn=<NllLossBackward0>)
tensor(2.0141, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1224: 0.299
tensor(2.1722, grad_fn=<NllLossBackward0>)
tensor(2.0161, grad_fn=<NllLossBackward0>)
tensor(1.7380, grad_fn=<NllLossBackward0>)
tensor(2.1864, grad_fn=<NllLossBackward0>)
tensor(2.0501, grad_fn=<NllLossBackward0>)
tensor(1.9689, grad_fn=<NllLossBackward0>)
tensor(2.1412, grad_fn=<NllLossBackward0>)
tensor(2.1291, grad_fn=<NllLossBackward0>)
tensor(1.9778, grad_fn=<NllLossBackward0>)
tensor(2.0527, grad_fn=<NllLossBackward0>)
tensor(2.0788, grad_fn=<NllLossBackward0>)
tensor(2.2295, grad_fn=<NllLossBackward0>)
tensor(1.8460, grad_fn=<NllLossBackward0>)
tensor(1.9148, grad_fn=<NllLossBackward0>)
tensor(2.0549, grad_fn=<NllLossBackward0>)
tensor(1.9836, grad_fn=<NllLossBackward0>)
tensor(2.5262, grad_fn=<NllLossBackward0>)
tensor(2.2730, grad_fn=<NllLossBackward0>)
tensor(2.0181, grad_fn=<NllLossBackward0>)
tensor(1.9169, grad_fn=<NllLossBackward0>)
tensor(2.1289, grad_fn=<NllLossBackward0>)
tensor(2.1666, grad_fn=<NllLossBackward0>)
tensor(2.1278, grad_fn=<NllLossBackward0>)
tensor(2.0319, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1248: 0.245
tensor(2.0474, grad_fn=<NllLossBackward0>)
tensor(2.3594, grad_fn=<NllLossBackward0>)
tensor(2.2098, grad_fn=<NllLossBackward0>)
tensor(2.1685, grad_fn=<NllLossBackward0>)
tensor(2.1535, grad_fn=<NllLossBackward0>)
tensor(2.2216, grad_fn=<NllLossBackward0>)
tensor(2.3665, grad_fn=<NllLossBackward0>)
tensor(2.3262, grad_fn=<NllLossBackward0>)
tensor(2.0831, grad_fn=<NllLossBackward0>)
tensor(2.0574, grad_fn=<NllLossBackward0>)
tensor(2.1535, grad_fn=<NllLossBackward0>)
tensor(2.0593, grad_fn=<NllLossBackward0>)
tensor(2.1117, grad_fn=<NllLossBackward0>)
tensor(2.0363, grad_fn=<NllLossBackward0>)
tensor(2.3667, grad_fn=<NllLossBackward0>)
tensor(2.0008, grad_fn=<NllLossBackward0>)
tensor(2.2380, grad_fn=<NllLossBackward0>)
tensor(2.2497, grad_fn=<NllLossBackward0>)
tensor(2.0412, grad_fn=<NllLossBackward0>)
tensor(2.0787, grad_fn=<NllLossBackward0>)
tensor(2.1575, grad_fn=<NllLossBackward0>)
tensor(2.0646, grad_fn=<NllLossBackward0>)
tensor(2.2398, grad_fn=<NllLossBackward0>)
tensor(2.0661, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1272: 0.245
tensor(1.9763, grad_fn=<NllLossBackward0>)
tensor(2.1982, grad_fn=<NllLossBackward0>)
tensor(1.8458, grad_fn=<NllLossBackward0>)
tensor(2.0865, grad_fn=<NllLossBackward0>)
tensor(2.1915, grad_fn=<NllLossBackward0>)
tensor(2.1661, grad_fn=<NllLossBackward0>)
tensor(2.1681, grad_fn=<NllLossBackward0>)
tensor(2.4125, grad_fn=<NllLossBackward0>)
tensor(2.1627, grad_fn=<NllLossBackward0>)
tensor(1.9844, grad_fn=<NllLossBackward0>)
tensor(2.3461, grad_fn=<NllLossBackward0>)
tensor(2.0079, grad_fn=<NllLossBackward0>)
tensor(1.9992, grad_fn=<NllLossBackward0>)
tensor(2.4201, grad_fn=<NllLossBackward0>)
tensor(2.1678, grad_fn=<NllLossBackward0>)
tensor(2.3566, grad_fn=<NllLossBackward0>)
tensor(2.3145, grad_fn=<NllLossBackward0>)
tensor(2.0740, grad_fn=<NllLossBackward0>)
tensor(2.1049, grad_fn=<NllLossBackward0>)
tensor(2.2080, grad_fn=<NllLossBackward0>)
tensor(1.9248, grad_fn=<NllLossBackward0>)
tensor(2.2152, grad_fn=<NllLossBackward0>)
tensor(2.0510, grad_fn=<NllLossBackward0>)
tensor(2.1659, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1296: 0.226
tensor(2.2331, grad_fn=<NllLossBackward0>)
tensor(2.0765, grad_fn=<NllLossBackward0>)
tensor(2.0480, grad_fn=<NllLossBackward0>)
tensor(2.1272, grad_fn=<NllLossBackward0>)
tensor(1.8754, grad_fn=<NllLossBackward0>)
tensor(2.2236, grad_fn=<NllLossBackward0>)
tensor(2.2155, grad_fn=<NllLossBackward0>)
tensor(2.2067, grad_fn=<NllLossBackward0>)
tensor(1.8983, grad_fn=<NllLossBackward0>)
tensor(2.0376, grad_fn=<NllLossBackward0>)
tensor(2.3277, grad_fn=<NllLossBackward0>)
tensor(2.1747, grad_fn=<NllLossBackward0>)
tensor(1.9470, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(1.9241, grad_fn=<NllLossBackward0>)
tensor(2.2032, grad_fn=<NllLossBackward0>)
tensor(2.2755, grad_fn=<NllLossBackward0>)
tensor(2.3440, grad_fn=<NllLossBackward0>)
tensor(2.2014, grad_fn=<NllLossBackward0>)
tensor(2.1975, grad_fn=<NllLossBackward0>)
tensor(2.4633, grad_fn=<NllLossBackward0>)
tensor(2.2993, grad_fn=<NllLossBackward0>)
tensor(2.0843, grad_fn=<NllLossBackward0>)
tensor(2.1777, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1320: 0.226
tensor(2.1620, grad_fn=<NllLossBackward0>)
tensor(2.0240, grad_fn=<NllLossBackward0>)
tensor(2.2177, grad_fn=<NllLossBackward0>)
tensor(2.1421, grad_fn=<NllLossBackward0>)
tensor(2.2498, grad_fn=<NllLossBackward0>)
tensor(2.0406, grad_fn=<NllLossBackward0>)
tensor(2.2598, grad_fn=<NllLossBackward0>)
tensor(2.1736, grad_fn=<NllLossBackward0>)
tensor(2.3179, grad_fn=<NllLossBackward0>)
tensor(2.1785, grad_fn=<NllLossBackward0>)
tensor(2.2270, grad_fn=<NllLossBackward0>)
tensor(2.0670, grad_fn=<NllLossBackward0>)
tensor(2.2914, grad_fn=<NllLossBackward0>)
tensor(2.1121, grad_fn=<NllLossBackward0>)
tensor(2.0695, grad_fn=<NllLossBackward0>)
tensor(1.9647, grad_fn=<NllLossBackward0>)
tensor(2.2323, grad_fn=<NllLossBackward0>)
tensor(2.0356, grad_fn=<NllLossBackward0>)
tensor(2.0603, grad_fn=<NllLossBackward0>)
tensor(2.3440, grad_fn=<NllLossBackward0>)
tensor(2.0625, grad_fn=<NllLossBackward0>)
tensor(2.1205, grad_fn=<NllLossBackward0>)
tensor(2.1612, grad_fn=<NllLossBackward0>)
tensor(2.0323, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1344: 0.250
tensor(2.0131, grad_fn=<NllLossBackward0>)
tensor(2.1955, grad_fn=<NllLossBackward0>)
tensor(1.9703, grad_fn=<NllLossBackward0>)
tensor(1.9786, grad_fn=<NllLossBackward0>)
tensor(2.1087, grad_fn=<NllLossBackward0>)
tensor(2.1811, grad_fn=<NllLossBackward0>)
tensor(2.5990, grad_fn=<NllLossBackward0>)
tensor(2.0054, grad_fn=<NllLossBackward0>)
tensor(2.1406, grad_fn=<NllLossBackward0>)
tensor(1.9862, grad_fn=<NllLossBackward0>)
tensor(2.2176, grad_fn=<NllLossBackward0>)
tensor(2.2904, grad_fn=<NllLossBackward0>)
tensor(1.8869, grad_fn=<NllLossBackward0>)
tensor(2.1703, grad_fn=<NllLossBackward0>)
tensor(2.1061, grad_fn=<NllLossBackward0>)
tensor(2.0904, grad_fn=<NllLossBackward0>)
tensor(2.0914, grad_fn=<NllLossBackward0>)
tensor(2.3626, grad_fn=<NllLossBackward0>)
tensor(2.3833, grad_fn=<NllLossBackward0>)
tensor(2.0733, grad_fn=<NllLossBackward0>)
tensor(2.1492, grad_fn=<NllLossBackward0>)
tensor(2.1714, grad_fn=<NllLossBackward0>)
tensor(2.0296, grad_fn=<NllLossBackward0>)
tensor(2.1193, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1368: 0.252
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(1.9508, grad_fn=<NllLossBackward0>)
tensor(2.0880, grad_fn=<NllLossBackward0>)
tensor(1.9634, grad_fn=<NllLossBackward0>)
tensor(2.0006, grad_fn=<NllLossBackward0>)
tensor(2.1366, grad_fn=<NllLossBackward0>)
tensor(2.2727, grad_fn=<NllLossBackward0>)
tensor(2.2061, grad_fn=<NllLossBackward0>)
tensor(1.9392, grad_fn=<NllLossBackward0>)
tensor(2.1689, grad_fn=<NllLossBackward0>)
tensor(1.9555, grad_fn=<NllLossBackward0>)
tensor(2.1482, grad_fn=<NllLossBackward0>)
tensor(2.0553, grad_fn=<NllLossBackward0>)
tensor(1.9391, grad_fn=<NllLossBackward0>)
tensor(2.1838, grad_fn=<NllLossBackward0>)
tensor(2.2702, grad_fn=<NllLossBackward0>)
tensor(2.1890, grad_fn=<NllLossBackward0>)
tensor(2.0527, grad_fn=<NllLossBackward0>)
tensor(1.9367, grad_fn=<NllLossBackward0>)
tensor(1.8654, grad_fn=<NllLossBackward0>)
tensor(2.0663, grad_fn=<NllLossBackward0>)
tensor(2.0836, grad_fn=<NllLossBackward0>)
tensor(2.1659, grad_fn=<NllLossBackward0>)
tensor(2.1456, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1392: 0.283
tensor(2.0365, grad_fn=<NllLossBackward0>)
tensor(2.2031, grad_fn=<NllLossBackward0>)
tensor(2.0065, grad_fn=<NllLossBackward0>)
tensor(2.0593, grad_fn=<NllLossBackward0>)
tensor(1.9535, grad_fn=<NllLossBackward0>)
tensor(2.2483, grad_fn=<NllLossBackward0>)
tensor(1.9209, grad_fn=<NllLossBackward0>)
tensor(2.1416, grad_fn=<NllLossBackward0>)
tensor(2.0505, grad_fn=<NllLossBackward0>)
tensor(1.9802, grad_fn=<NllLossBackward0>)
tensor(2.2595, grad_fn=<NllLossBackward0>)
tensor(2.1558, grad_fn=<NllLossBackward0>)
tensor(2.1945, grad_fn=<NllLossBackward0>)
tensor(2.0432, grad_fn=<NllLossBackward0>)
tensor(2.1489, grad_fn=<NllLossBackward0>)
tensor(2.1709, grad_fn=<NllLossBackward0>)
tensor(2.0239, grad_fn=<NllLossBackward0>)
tensor(2.2021, grad_fn=<NllLossBackward0>)
tensor(2.1708, grad_fn=<NllLossBackward0>)
tensor(2.0921, grad_fn=<NllLossBackward0>)
tensor(2.0693, grad_fn=<NllLossBackward0>)
tensor(1.9601, grad_fn=<NllLossBackward0>)
tensor(2.1218, grad_fn=<NllLossBackward0>)
tensor(2.0906, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1416: 0.276
tensor(2.0988, grad_fn=<NllLossBackward0>)
tensor(2.0722, grad_fn=<NllLossBackward0>)
tensor(2.0082, grad_fn=<NllLossBackward0>)
tensor(1.9752, grad_fn=<NllLossBackward0>)
tensor(1.8949, grad_fn=<NllLossBackward0>)
tensor(2.0348, grad_fn=<NllLossBackward0>)
tensor(2.2986, grad_fn=<NllLossBackward0>)
tensor(2.0477, grad_fn=<NllLossBackward0>)
tensor(2.0259, grad_fn=<NllLossBackward0>)
tensor(2.0352, grad_fn=<NllLossBackward0>)
tensor(1.9628, grad_fn=<NllLossBackward0>)
tensor(2.1186, grad_fn=<NllLossBackward0>)
tensor(2.0220, grad_fn=<NllLossBackward0>)
tensor(2.1224, grad_fn=<NllLossBackward0>)
tensor(2.1868, grad_fn=<NllLossBackward0>)
tensor(2.1041, grad_fn=<NllLossBackward0>)
tensor(2.0333, grad_fn=<NllLossBackward0>)
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.2221, grad_fn=<NllLossBackward0>)
tensor(2.0352, grad_fn=<NllLossBackward0>)
tensor(2.1015, grad_fn=<NllLossBackward0>)
tensor(2.0922, grad_fn=<NllLossBackward0>)
tensor(2.1542, grad_fn=<NllLossBackward0>)
tensor(2.1424, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1440: 0.321
tensor(2.1097, grad_fn=<NllLossBackward0>)
tensor(1.9477, grad_fn=<NllLossBackward0>)
tensor(2.1002, grad_fn=<NllLossBackward0>)
tensor(2.0976, grad_fn=<NllLossBackward0>)
tensor(2.2675, grad_fn=<NllLossBackward0>)
tensor(2.2926, grad_fn=<NllLossBackward0>)
tensor(2.1276, grad_fn=<NllLossBackward0>)
tensor(2.0794, grad_fn=<NllLossBackward0>)
tensor(2.2594, grad_fn=<NllLossBackward0>)
tensor(1.9914, grad_fn=<NllLossBackward0>)
tensor(2.0908, grad_fn=<NllLossBackward0>)
tensor(2.0104, grad_fn=<NllLossBackward0>)
tensor(2.0917, grad_fn=<NllLossBackward0>)
tensor(2.1155, grad_fn=<NllLossBackward0>)
tensor(1.9802, grad_fn=<NllLossBackward0>)
tensor(2.0099, grad_fn=<NllLossBackward0>)
tensor(2.0201, grad_fn=<NllLossBackward0>)
tensor(2.1480, grad_fn=<NllLossBackward0>)
tensor(2.3564, grad_fn=<NllLossBackward0>)
tensor(2.2552, grad_fn=<NllLossBackward0>)
tensor(1.8975, grad_fn=<NllLossBackward0>)
tensor(2.0789, grad_fn=<NllLossBackward0>)
tensor(2.0028, grad_fn=<NllLossBackward0>)
tensor(2.1015, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1464: 0.274
tensor(2.1328, grad_fn=<NllLossBackward0>)
tensor(2.1203, grad_fn=<NllLossBackward0>)
tensor(2.1631, grad_fn=<NllLossBackward0>)
tensor(1.9881, grad_fn=<NllLossBackward0>)
tensor(1.8335, grad_fn=<NllLossBackward0>)
tensor(2.4836, grad_fn=<NllLossBackward0>)
tensor(2.1962, grad_fn=<NllLossBackward0>)
tensor(2.1681, grad_fn=<NllLossBackward0>)
tensor(1.9505, grad_fn=<NllLossBackward0>)
tensor(2.0163, grad_fn=<NllLossBackward0>)
tensor(2.2334, grad_fn=<NllLossBackward0>)
tensor(1.7370, grad_fn=<NllLossBackward0>)
tensor(2.1406, grad_fn=<NllLossBackward0>)
tensor(2.1917, grad_fn=<NllLossBackward0>)
tensor(2.0590, grad_fn=<NllLossBackward0>)
tensor(2.1415, grad_fn=<NllLossBackward0>)
tensor(2.2219, grad_fn=<NllLossBackward0>)
tensor(2.2790, grad_fn=<NllLossBackward0>)
tensor(2.0842, grad_fn=<NllLossBackward0>)
tensor(2.0804, grad_fn=<NllLossBackward0>)
tensor(1.9708, grad_fn=<NllLossBackward0>)
tensor(2.0793, grad_fn=<NllLossBackward0>)
tensor(2.2807, grad_fn=<NllLossBackward0>)
tensor(2.0065, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1488: 0.257
tensor(2.1616, grad_fn=<NllLossBackward0>)
tensor(2.0180, grad_fn=<NllLossBackward0>)
tensor(2.0811, grad_fn=<NllLossBackward0>)
tensor(2.1885, grad_fn=<NllLossBackward0>)
tensor(2.1769, grad_fn=<NllLossBackward0>)
tensor(2.0952, grad_fn=<NllLossBackward0>)
tensor(2.1906, grad_fn=<NllLossBackward0>)
tensor(2.0919, grad_fn=<NllLossBackward0>)
tensor(2.1637, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.0397, grad_fn=<NllLossBackward0>)
tensor(2.0183, grad_fn=<NllLossBackward0>)
tensor(2.3916, grad_fn=<NllLossBackward0>)
tensor(1.9991, grad_fn=<NllLossBackward0>)
tensor(2.1475, grad_fn=<NllLossBackward0>)
tensor(2.2546, grad_fn=<NllLossBackward0>)
tensor(2.1177, grad_fn=<NllLossBackward0>)
tensor(1.9995, grad_fn=<NllLossBackward0>)
tensor(2.0468, grad_fn=<NllLossBackward0>)
tensor(2.0841, grad_fn=<NllLossBackward0>)
tensor(2.1227, grad_fn=<NllLossBackward0>)
tensor(2.0387, grad_fn=<NllLossBackward0>)
tensor(2.0376, grad_fn=<NllLossBackward0>)
tensor(1.9766, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1512: 0.280
tensor(2.1423, grad_fn=<NllLossBackward0>)
tensor(2.0987, grad_fn=<NllLossBackward0>)
tensor(2.1331, grad_fn=<NllLossBackward0>)
tensor(1.9773, grad_fn=<NllLossBackward0>)
tensor(1.8481, grad_fn=<NllLossBackward0>)
tensor(2.0860, grad_fn=<NllLossBackward0>)
tensor(2.2997, grad_fn=<NllLossBackward0>)
tensor(1.9970, grad_fn=<NllLossBackward0>)
tensor(2.2534, grad_fn=<NllLossBackward0>)
tensor(1.8847, grad_fn=<NllLossBackward0>)
tensor(2.2042, grad_fn=<NllLossBackward0>)
tensor(2.1094, grad_fn=<NllLossBackward0>)
tensor(2.0727, grad_fn=<NllLossBackward0>)
tensor(1.9596, grad_fn=<NllLossBackward0>)
tensor(2.2957, grad_fn=<NllLossBackward0>)
tensor(2.1453, grad_fn=<NllLossBackward0>)
tensor(2.0682, grad_fn=<NllLossBackward0>)
tensor(1.9988, grad_fn=<NllLossBackward0>)
tensor(2.0289, grad_fn=<NllLossBackward0>)
tensor(1.9105, grad_fn=<NllLossBackward0>)
tensor(2.0558, grad_fn=<NllLossBackward0>)
tensor(2.1732, grad_fn=<NllLossBackward0>)
tensor(1.9361, grad_fn=<NllLossBackward0>)
tensor(2.1632, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1536: 0.274
tensor(1.9957, grad_fn=<NllLossBackward0>)
tensor(2.1127, grad_fn=<NllLossBackward0>)
tensor(2.2075, grad_fn=<NllLossBackward0>)
tensor(2.1792, grad_fn=<NllLossBackward0>)
tensor(2.0920, grad_fn=<NllLossBackward0>)
tensor(2.2695, grad_fn=<NllLossBackward0>)
tensor(2.1150, grad_fn=<NllLossBackward0>)
tensor(1.9752, grad_fn=<NllLossBackward0>)
tensor(2.1849, grad_fn=<NllLossBackward0>)
tensor(2.4232, grad_fn=<NllLossBackward0>)
tensor(2.0844, grad_fn=<NllLossBackward0>)
tensor(2.3983, grad_fn=<NllLossBackward0>)
tensor(2.0412, grad_fn=<NllLossBackward0>)
tensor(2.0367, grad_fn=<NllLossBackward0>)
tensor(2.1978, grad_fn=<NllLossBackward0>)
tensor(2.0724, grad_fn=<NllLossBackward0>)
tensor(2.0249, grad_fn=<NllLossBackward0>)
tensor(2.0905, grad_fn=<NllLossBackward0>)
tensor(2.1963, grad_fn=<NllLossBackward0>)
tensor(2.0961, grad_fn=<NllLossBackward0>)
tensor(2.0426, grad_fn=<NllLossBackward0>)
tensor(1.8915, grad_fn=<NllLossBackward0>)
tensor(2.2402, grad_fn=<NllLossBackward0>)
tensor(2.1733, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1560: 0.264
tensor(2.2828, grad_fn=<NllLossBackward0>)
tensor(2.1093, grad_fn=<NllLossBackward0>)
tensor(1.9725, grad_fn=<NllLossBackward0>)
tensor(2.0565, grad_fn=<NllLossBackward0>)
tensor(1.9201, grad_fn=<NllLossBackward0>)
tensor(2.0675, grad_fn=<NllLossBackward0>)
tensor(2.1377, grad_fn=<NllLossBackward0>)
tensor(2.2410, grad_fn=<NllLossBackward0>)
tensor(2.1937, grad_fn=<NllLossBackward0>)
tensor(2.3031, grad_fn=<NllLossBackward0>)
tensor(2.1375, grad_fn=<NllLossBackward0>)
tensor(1.9901, grad_fn=<NllLossBackward0>)
tensor(2.0575, grad_fn=<NllLossBackward0>)
tensor(1.9578, grad_fn=<NllLossBackward0>)
tensor(2.3212, grad_fn=<NllLossBackward0>)
tensor(1.9779, grad_fn=<NllLossBackward0>)
tensor(2.1619, grad_fn=<NllLossBackward0>)
tensor(1.9994, grad_fn=<NllLossBackward0>)
tensor(1.8952, grad_fn=<NllLossBackward0>)
tensor(1.9512, grad_fn=<NllLossBackward0>)
tensor(2.0880, grad_fn=<NllLossBackward0>)
tensor(2.0000, grad_fn=<NllLossBackward0>)
tensor(2.1187, grad_fn=<NllLossBackward0>)
tensor(2.2959, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1584: 0.252
tensor(2.1613, grad_fn=<NllLossBackward0>)
tensor(2.0748, grad_fn=<NllLossBackward0>)
tensor(1.8577, grad_fn=<NllLossBackward0>)
tensor(2.2567, grad_fn=<NllLossBackward0>)
tensor(1.9100, grad_fn=<NllLossBackward0>)
tensor(2.3256, grad_fn=<NllLossBackward0>)
tensor(2.1161, grad_fn=<NllLossBackward0>)
tensor(2.1984, grad_fn=<NllLossBackward0>)
tensor(1.8997, grad_fn=<NllLossBackward0>)
tensor(2.1571, grad_fn=<NllLossBackward0>)
tensor(2.1580, grad_fn=<NllLossBackward0>)
tensor(2.4491, grad_fn=<NllLossBackward0>)
tensor(2.2520, grad_fn=<NllLossBackward0>)
tensor(2.1563, grad_fn=<NllLossBackward0>)
tensor(2.2007, grad_fn=<NllLossBackward0>)
tensor(2.1640, grad_fn=<NllLossBackward0>)
tensor(2.0887, grad_fn=<NllLossBackward0>)
tensor(1.8592, grad_fn=<NllLossBackward0>)
tensor(2.4506, grad_fn=<NllLossBackward0>)
tensor(1.9933, grad_fn=<NllLossBackward0>)
tensor(2.1966, grad_fn=<NllLossBackward0>)
tensor(2.3083, grad_fn=<NllLossBackward0>)
tensor(2.0420, grad_fn=<NllLossBackward0>)
tensor(2.1336, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1608: 0.271
tensor(2.1561, grad_fn=<NllLossBackward0>)
tensor(2.1641, grad_fn=<NllLossBackward0>)
tensor(2.1669, grad_fn=<NllLossBackward0>)
tensor(2.1499, grad_fn=<NllLossBackward0>)
tensor(1.9256, grad_fn=<NllLossBackward0>)
tensor(2.2456, grad_fn=<NllLossBackward0>)
tensor(2.0715, grad_fn=<NllLossBackward0>)
tensor(2.3837, grad_fn=<NllLossBackward0>)
tensor(2.0501, grad_fn=<NllLossBackward0>)
tensor(2.2784, grad_fn=<NllLossBackward0>)
tensor(2.1563, grad_fn=<NllLossBackward0>)
tensor(2.0224, grad_fn=<NllLossBackward0>)
tensor(2.0512, grad_fn=<NllLossBackward0>)
tensor(2.1277, grad_fn=<NllLossBackward0>)
tensor(2.0024, grad_fn=<NllLossBackward0>)
tensor(2.0952, grad_fn=<NllLossBackward0>)
tensor(2.1346, grad_fn=<NllLossBackward0>)
tensor(2.0860, grad_fn=<NllLossBackward0>)
tensor(2.2663, grad_fn=<NllLossBackward0>)
tensor(2.0785, grad_fn=<NllLossBackward0>)
tensor(2.1603, grad_fn=<NllLossBackward0>)
tensor(2.0213, grad_fn=<NllLossBackward0>)
tensor(2.0749, grad_fn=<NllLossBackward0>)
tensor(2.2417, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1632: 0.257
tensor(2.0350, grad_fn=<NllLossBackward0>)
tensor(2.1474, grad_fn=<NllLossBackward0>)
tensor(1.9922, grad_fn=<NllLossBackward0>)
tensor(2.2156, grad_fn=<NllLossBackward0>)
tensor(1.9715, grad_fn=<NllLossBackward0>)
tensor(2.1803, grad_fn=<NllLossBackward0>)
tensor(2.3344, grad_fn=<NllLossBackward0>)
tensor(2.3742, grad_fn=<NllLossBackward0>)
tensor(2.1581, grad_fn=<NllLossBackward0>)
tensor(1.7098, grad_fn=<NllLossBackward0>)
tensor(2.0792, grad_fn=<NllLossBackward0>)
tensor(2.2463, grad_fn=<NllLossBackward0>)
tensor(2.0433, grad_fn=<NllLossBackward0>)
tensor(1.9710, grad_fn=<NllLossBackward0>)
tensor(2.2053, grad_fn=<NllLossBackward0>)
tensor(2.1250, grad_fn=<NllLossBackward0>)
tensor(1.8299, grad_fn=<NllLossBackward0>)
tensor(2.1598, grad_fn=<NllLossBackward0>)
tensor(2.0324, grad_fn=<NllLossBackward0>)
tensor(2.4138, grad_fn=<NllLossBackward0>)
tensor(2.1606, grad_fn=<NllLossBackward0>)
tensor(2.2809, grad_fn=<NllLossBackward0>)
tensor(2.1009, grad_fn=<NllLossBackward0>)
tensor(2.3088, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1656: 0.245
tensor(2.1888, grad_fn=<NllLossBackward0>)
tensor(1.8495, grad_fn=<NllLossBackward0>)
tensor(2.2075, grad_fn=<NllLossBackward0>)
tensor(2.2419, grad_fn=<NllLossBackward0>)
tensor(2.2229, grad_fn=<NllLossBackward0>)
tensor(2.2655, grad_fn=<NllLossBackward0>)
tensor(2.1875, grad_fn=<NllLossBackward0>)
tensor(2.0525, grad_fn=<NllLossBackward0>)
tensor(1.9936, grad_fn=<NllLossBackward0>)
tensor(2.0788, grad_fn=<NllLossBackward0>)
tensor(2.0372, grad_fn=<NllLossBackward0>)
tensor(2.0771, grad_fn=<NllLossBackward0>)
tensor(2.0124, grad_fn=<NllLossBackward0>)
tensor(2.0432, grad_fn=<NllLossBackward0>)
tensor(2.1338, grad_fn=<NllLossBackward0>)
tensor(2.2402, grad_fn=<NllLossBackward0>)
tensor(2.0765, grad_fn=<NllLossBackward0>)
tensor(2.3847, grad_fn=<NllLossBackward0>)
tensor(1.9574, grad_fn=<NllLossBackward0>)
tensor(2.1173, grad_fn=<NllLossBackward0>)
tensor(2.1074, grad_fn=<NllLossBackward0>)
tensor(2.1858, grad_fn=<NllLossBackward0>)
tensor(2.1518, grad_fn=<NllLossBackward0>)
tensor(1.9801, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1680: 0.259
tensor(1.8742, grad_fn=<NllLossBackward0>)
tensor(2.1214, grad_fn=<NllLossBackward0>)
tensor(1.9139, grad_fn=<NllLossBackward0>)
tensor(2.1638, grad_fn=<NllLossBackward0>)
tensor(2.0816, grad_fn=<NllLossBackward0>)
tensor(2.2238, grad_fn=<NllLossBackward0>)
tensor(2.1635, grad_fn=<NllLossBackward0>)
tensor(1.8351, grad_fn=<NllLossBackward0>)
tensor(1.9916, grad_fn=<NllLossBackward0>)
tensor(2.1904, grad_fn=<NllLossBackward0>)
tensor(2.1734, grad_fn=<NllLossBackward0>)
tensor(2.0284, grad_fn=<NllLossBackward0>)
tensor(1.9631, grad_fn=<NllLossBackward0>)
tensor(2.3422, grad_fn=<NllLossBackward0>)
tensor(2.1776, grad_fn=<NllLossBackward0>)
tensor(2.0245, grad_fn=<NllLossBackward0>)
tensor(2.3004, grad_fn=<NllLossBackward0>)
tensor(2.0850, grad_fn=<NllLossBackward0>)
tensor(1.9594, grad_fn=<NllLossBackward0>)
tensor(2.1255, grad_fn=<NllLossBackward0>)
tensor(2.0238, grad_fn=<NllLossBackward0>)
tensor(2.1159, grad_fn=<NllLossBackward0>)
tensor(1.9782, grad_fn=<NllLossBackward0>)
tensor(1.9724, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1704: 0.293
tensor(2.0379, grad_fn=<NllLossBackward0>)
tensor(2.3133, grad_fn=<NllLossBackward0>)
tensor(2.2710, grad_fn=<NllLossBackward0>)
tensor(2.2098, grad_fn=<NllLossBackward0>)
tensor(1.9229, grad_fn=<NllLossBackward0>)
tensor(1.8512, grad_fn=<NllLossBackward0>)
tensor(2.1491, grad_fn=<NllLossBackward0>)
tensor(2.0364, grad_fn=<NllLossBackward0>)
tensor(2.1746, grad_fn=<NllLossBackward0>)
tensor(1.9081, grad_fn=<NllLossBackward0>)
tensor(2.0289, grad_fn=<NllLossBackward0>)
tensor(2.2171, grad_fn=<NllLossBackward0>)
tensor(1.8395, grad_fn=<NllLossBackward0>)
tensor(2.1097, grad_fn=<NllLossBackward0>)
tensor(2.2652, grad_fn=<NllLossBackward0>)
tensor(2.0672, grad_fn=<NllLossBackward0>)
tensor(2.1532, grad_fn=<NllLossBackward0>)
tensor(2.1425, grad_fn=<NllLossBackward0>)
tensor(2.0185, grad_fn=<NllLossBackward0>)
tensor(2.0570, grad_fn=<NllLossBackward0>)
tensor(2.2149, grad_fn=<NllLossBackward0>)
tensor(1.9409, grad_fn=<NllLossBackward0>)
tensor(2.1608, grad_fn=<NllLossBackward0>)
tensor(2.0752, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1728: 0.276
tensor(2.2573, grad_fn=<NllLossBackward0>)
tensor(2.0673, grad_fn=<NllLossBackward0>)
tensor(2.0908, grad_fn=<NllLossBackward0>)
tensor(2.0279, grad_fn=<NllLossBackward0>)
tensor(2.2108, grad_fn=<NllLossBackward0>)
tensor(2.0362, grad_fn=<NllLossBackward0>)
tensor(1.9702, grad_fn=<NllLossBackward0>)
tensor(1.9579, grad_fn=<NllLossBackward0>)
tensor(2.2719, grad_fn=<NllLossBackward0>)
tensor(2.1645, grad_fn=<NllLossBackward0>)
tensor(2.0186, grad_fn=<NllLossBackward0>)
tensor(2.0944, grad_fn=<NllLossBackward0>)
tensor(2.0241, grad_fn=<NllLossBackward0>)
tensor(1.8065, grad_fn=<NllLossBackward0>)
tensor(2.3657, grad_fn=<NllLossBackward0>)
tensor(2.1086, grad_fn=<NllLossBackward0>)
tensor(2.1949, grad_fn=<NllLossBackward0>)
tensor(1.8725, grad_fn=<NllLossBackward0>)
tensor(2.0228, grad_fn=<NllLossBackward0>)
tensor(2.3171, grad_fn=<NllLossBackward0>)
tensor(2.1275, grad_fn=<NllLossBackward0>)
tensor(2.1191, grad_fn=<NllLossBackward0>)
tensor(2.0519, grad_fn=<NllLossBackward0>)
tensor(1.9967, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1752: 0.271
tensor(2.0809, grad_fn=<NllLossBackward0>)
tensor(2.1880, grad_fn=<NllLossBackward0>)
tensor(2.1109, grad_fn=<NllLossBackward0>)
tensor(2.1312, grad_fn=<NllLossBackward0>)
tensor(2.2694, grad_fn=<NllLossBackward0>)
tensor(2.0091, grad_fn=<NllLossBackward0>)
tensor(2.0222, grad_fn=<NllLossBackward0>)
tensor(2.1740, grad_fn=<NllLossBackward0>)
tensor(1.9614, grad_fn=<NllLossBackward0>)
tensor(2.0008, grad_fn=<NllLossBackward0>)
tensor(2.1338, grad_fn=<NllLossBackward0>)
tensor(2.2804, grad_fn=<NllLossBackward0>)
tensor(1.7955, grad_fn=<NllLossBackward0>)
tensor(2.0911, grad_fn=<NllLossBackward0>)
tensor(2.2215, grad_fn=<NllLossBackward0>)
tensor(2.0228, grad_fn=<NllLossBackward0>)
tensor(1.9429, grad_fn=<NllLossBackward0>)
tensor(2.1733, grad_fn=<NllLossBackward0>)
tensor(2.1489, grad_fn=<NllLossBackward0>)
tensor(2.0327, grad_fn=<NllLossBackward0>)
tensor(2.1597, grad_fn=<NllLossBackward0>)
tensor(2.0892, grad_fn=<NllLossBackward0>)
tensor(2.0965, grad_fn=<NllLossBackward0>)
tensor(2.0713, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1776: 0.248
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.3494, grad_fn=<NllLossBackward0>)
tensor(2.3955, grad_fn=<NllLossBackward0>)
tensor(2.1537, grad_fn=<NllLossBackward0>)
tensor(1.8687, grad_fn=<NllLossBackward0>)
tensor(2.1345, grad_fn=<NllLossBackward0>)
tensor(2.2386, grad_fn=<NllLossBackward0>)
tensor(2.1161, grad_fn=<NllLossBackward0>)
tensor(2.1751, grad_fn=<NllLossBackward0>)
tensor(2.1906, grad_fn=<NllLossBackward0>)
tensor(2.1419, grad_fn=<NllLossBackward0>)
tensor(2.0586, grad_fn=<NllLossBackward0>)
tensor(2.0916, grad_fn=<NllLossBackward0>)
tensor(2.0472, grad_fn=<NllLossBackward0>)
tensor(2.0281, grad_fn=<NllLossBackward0>)
tensor(2.1365, grad_fn=<NllLossBackward0>)
tensor(2.1766, grad_fn=<NllLossBackward0>)
tensor(1.9299, grad_fn=<NllLossBackward0>)
tensor(1.8732, grad_fn=<NllLossBackward0>)
tensor(2.1358, grad_fn=<NllLossBackward0>)
tensor(2.1951, grad_fn=<NllLossBackward0>)
tensor(2.2939, grad_fn=<NllLossBackward0>)
tensor(2.1851, grad_fn=<NllLossBackward0>)
tensor(1.9049, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1800: 0.262
tensor(2.0449, grad_fn=<NllLossBackward0>)
tensor(2.0667, grad_fn=<NllLossBackward0>)
tensor(2.2150, grad_fn=<NllLossBackward0>)
tensor(2.1352, grad_fn=<NllLossBackward0>)
tensor(2.1643, grad_fn=<NllLossBackward0>)
tensor(1.9489, grad_fn=<NllLossBackward0>)
tensor(2.0768, grad_fn=<NllLossBackward0>)
tensor(2.2885, grad_fn=<NllLossBackward0>)
tensor(2.3303, grad_fn=<NllLossBackward0>)
tensor(2.2376, grad_fn=<NllLossBackward0>)
tensor(2.3127, grad_fn=<NllLossBackward0>)
tensor(2.0652, grad_fn=<NllLossBackward0>)
tensor(2.1857, grad_fn=<NllLossBackward0>)
tensor(2.0522, grad_fn=<NllLossBackward0>)
tensor(2.1757, grad_fn=<NllLossBackward0>)
tensor(2.1360, grad_fn=<NllLossBackward0>)
tensor(2.3278, grad_fn=<NllLossBackward0>)
tensor(2.1338, grad_fn=<NllLossBackward0>)
tensor(2.1716, grad_fn=<NllLossBackward0>)
tensor(1.8293, grad_fn=<NllLossBackward0>)
tensor(2.0005, grad_fn=<NllLossBackward0>)
tensor(2.0726, grad_fn=<NllLossBackward0>)
tensor(1.9444, grad_fn=<NllLossBackward0>)
tensor(2.0259, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1824: 0.276
tensor(2.0197, grad_fn=<NllLossBackward0>)
tensor(2.0731, grad_fn=<NllLossBackward0>)
tensor(2.3316, grad_fn=<NllLossBackward0>)
tensor(1.9780, grad_fn=<NllLossBackward0>)
tensor(2.1500, grad_fn=<NllLossBackward0>)
tensor(2.1528, grad_fn=<NllLossBackward0>)
tensor(2.0060, grad_fn=<NllLossBackward0>)
tensor(2.1327, grad_fn=<NllLossBackward0>)
tensor(2.0623, grad_fn=<NllLossBackward0>)
tensor(2.1035, grad_fn=<NllLossBackward0>)
tensor(2.2056, grad_fn=<NllLossBackward0>)
tensor(2.2048, grad_fn=<NllLossBackward0>)
tensor(2.0838, grad_fn=<NllLossBackward0>)
tensor(1.9832, grad_fn=<NllLossBackward0>)
tensor(2.0182, grad_fn=<NllLossBackward0>)
tensor(2.2141, grad_fn=<NllLossBackward0>)
tensor(2.0244, grad_fn=<NllLossBackward0>)
tensor(2.0934, grad_fn=<NllLossBackward0>)
tensor(2.2681, grad_fn=<NllLossBackward0>)
tensor(2.1679, grad_fn=<NllLossBackward0>)
tensor(2.1569, grad_fn=<NllLossBackward0>)
tensor(1.9518, grad_fn=<NllLossBackward0>)
tensor(2.2304, grad_fn=<NllLossBackward0>)
tensor(1.9826, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1848: 0.269
tensor(1.8824, grad_fn=<NllLossBackward0>)
tensor(1.9934, grad_fn=<NllLossBackward0>)
tensor(2.1925, grad_fn=<NllLossBackward0>)
tensor(2.2401, grad_fn=<NllLossBackward0>)
tensor(1.9731, grad_fn=<NllLossBackward0>)
tensor(2.0546, grad_fn=<NllLossBackward0>)
tensor(2.0857, grad_fn=<NllLossBackward0>)
tensor(2.0233, grad_fn=<NllLossBackward0>)
tensor(1.9161, grad_fn=<NllLossBackward0>)
tensor(2.0359, grad_fn=<NllLossBackward0>)
tensor(1.9473, grad_fn=<NllLossBackward0>)
tensor(2.0699, grad_fn=<NllLossBackward0>)
tensor(2.1987, grad_fn=<NllLossBackward0>)
tensor(1.9307, grad_fn=<NllLossBackward0>)
tensor(2.0905, grad_fn=<NllLossBackward0>)
tensor(2.1301, grad_fn=<NllLossBackward0>)
tensor(2.1033, grad_fn=<NllLossBackward0>)
tensor(2.0314, grad_fn=<NllLossBackward0>)
tensor(2.0585, grad_fn=<NllLossBackward0>)
tensor(2.1060, grad_fn=<NllLossBackward0>)
tensor(2.1846, grad_fn=<NllLossBackward0>)
tensor(2.2691, grad_fn=<NllLossBackward0>)
tensor(2.1668, grad_fn=<NllLossBackward0>)
tensor(2.2110, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1872: 0.307
tensor(2.1991, grad_fn=<NllLossBackward0>)
tensor(2.1417, grad_fn=<NllLossBackward0>)
tensor(2.0353, grad_fn=<NllLossBackward0>)
tensor(2.2446, grad_fn=<NllLossBackward0>)
tensor(1.9573, grad_fn=<NllLossBackward0>)
tensor(2.1168, grad_fn=<NllLossBackward0>)
tensor(2.0464, grad_fn=<NllLossBackward0>)
tensor(2.1659, grad_fn=<NllLossBackward0>)
tensor(2.0183, grad_fn=<NllLossBackward0>)
tensor(2.2562, grad_fn=<NllLossBackward0>)
tensor(2.0581, grad_fn=<NllLossBackward0>)
tensor(2.1859, grad_fn=<NllLossBackward0>)
tensor(2.1280, grad_fn=<NllLossBackward0>)
tensor(2.0437, grad_fn=<NllLossBackward0>)
tensor(1.8286, grad_fn=<NllLossBackward0>)
tensor(2.1164, grad_fn=<NllLossBackward0>)
tensor(2.0098, grad_fn=<NllLossBackward0>)
tensor(1.8362, grad_fn=<NllLossBackward0>)
tensor(2.1862, grad_fn=<NllLossBackward0>)
tensor(2.1951, grad_fn=<NllLossBackward0>)
tensor(2.1961, grad_fn=<NllLossBackward0>)
tensor(1.9838, grad_fn=<NllLossBackward0>)
tensor(2.1887, grad_fn=<NllLossBackward0>)
tensor(1.9712, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1896: 0.278
tensor(2.2123, grad_fn=<NllLossBackward0>)
tensor(1.9153, grad_fn=<NllLossBackward0>)
tensor(2.1703, grad_fn=<NllLossBackward0>)
tensor(2.2442, grad_fn=<NllLossBackward0>)
tensor(2.0320, grad_fn=<NllLossBackward0>)
tensor(1.9324, grad_fn=<NllLossBackward0>)
tensor(2.0336, grad_fn=<NllLossBackward0>)
tensor(1.9927, grad_fn=<NllLossBackward0>)
tensor(2.2521, grad_fn=<NllLossBackward0>)
tensor(2.0714, grad_fn=<NllLossBackward0>)
tensor(2.1622, grad_fn=<NllLossBackward0>)
tensor(2.0057, grad_fn=<NllLossBackward0>)
tensor(2.2447, grad_fn=<NllLossBackward0>)
tensor(2.1075, grad_fn=<NllLossBackward0>)
tensor(2.2282, grad_fn=<NllLossBackward0>)
tensor(2.2719, grad_fn=<NllLossBackward0>)
tensor(2.0382, grad_fn=<NllLossBackward0>)
tensor(2.0305, grad_fn=<NllLossBackward0>)
tensor(1.8054, grad_fn=<NllLossBackward0>)
tensor(2.2178, grad_fn=<NllLossBackward0>)
tensor(2.3838, grad_fn=<NllLossBackward0>)
tensor(2.2389, grad_fn=<NllLossBackward0>)
tensor(2.2026, grad_fn=<NllLossBackward0>)
tensor(2.0537, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1920: 0.283
tensor(1.9423, grad_fn=<NllLossBackward0>)
tensor(2.1599, grad_fn=<NllLossBackward0>)
tensor(1.9467, grad_fn=<NllLossBackward0>)
tensor(2.1588, grad_fn=<NllLossBackward0>)
tensor(1.9024, grad_fn=<NllLossBackward0>)
tensor(2.1508, grad_fn=<NllLossBackward0>)
tensor(2.2753, grad_fn=<NllLossBackward0>)
tensor(2.2181, grad_fn=<NllLossBackward0>)
tensor(2.3020, grad_fn=<NllLossBackward0>)
tensor(2.0827, grad_fn=<NllLossBackward0>)
tensor(1.9429, grad_fn=<NllLossBackward0>)
tensor(2.0994, grad_fn=<NllLossBackward0>)
tensor(2.0727, grad_fn=<NllLossBackward0>)
tensor(2.2607, grad_fn=<NllLossBackward0>)
tensor(2.1750, grad_fn=<NllLossBackward0>)
tensor(2.4353, grad_fn=<NllLossBackward0>)
tensor(2.0345, grad_fn=<NllLossBackward0>)
tensor(1.9836, grad_fn=<NllLossBackward0>)
tensor(2.4625, grad_fn=<NllLossBackward0>)
tensor(1.9794, grad_fn=<NllLossBackward0>)
tensor(2.0638, grad_fn=<NllLossBackward0>)
tensor(1.9555, grad_fn=<NllLossBackward0>)
tensor(2.1698, grad_fn=<NllLossBackward0>)
tensor(2.2655, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1944: 0.260
tensor(2.2247, grad_fn=<NllLossBackward0>)
tensor(1.8039, grad_fn=<NllLossBackward0>)
tensor(1.8448, grad_fn=<NllLossBackward0>)
tensor(2.0443, grad_fn=<NllLossBackward0>)
tensor(2.0156, grad_fn=<NllLossBackward0>)
tensor(2.3104, grad_fn=<NllLossBackward0>)
tensor(2.2094, grad_fn=<NllLossBackward0>)
tensor(2.2575, grad_fn=<NllLossBackward0>)
tensor(2.1242, grad_fn=<NllLossBackward0>)
tensor(2.0997, grad_fn=<NllLossBackward0>)
tensor(2.3814, grad_fn=<NllLossBackward0>)
tensor(1.8395, grad_fn=<NllLossBackward0>)
tensor(2.0435, grad_fn=<NllLossBackward0>)
tensor(1.9514, grad_fn=<NllLossBackward0>)
tensor(2.0944, grad_fn=<NllLossBackward0>)
tensor(2.0407, grad_fn=<NllLossBackward0>)
tensor(2.1720, grad_fn=<NllLossBackward0>)
tensor(2.2111, grad_fn=<NllLossBackward0>)
tensor(2.1742, grad_fn=<NllLossBackward0>)
tensor(2.0951, grad_fn=<NllLossBackward0>)
tensor(1.9928, grad_fn=<NllLossBackward0>)
tensor(2.0322, grad_fn=<NllLossBackward0>)
tensor(2.1231, grad_fn=<NllLossBackward0>)
tensor(1.9431, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1968: 0.253
tensor(2.1682, grad_fn=<NllLossBackward0>)
tensor(2.2979, grad_fn=<NllLossBackward0>)
tensor(1.9594, grad_fn=<NllLossBackward0>)
tensor(2.0248, grad_fn=<NllLossBackward0>)
tensor(2.1496, grad_fn=<NllLossBackward0>)
tensor(2.0689, grad_fn=<NllLossBackward0>)
tensor(2.2603, grad_fn=<NllLossBackward0>)
tensor(2.2747, grad_fn=<NllLossBackward0>)
tensor(1.8979, grad_fn=<NllLossBackward0>)
tensor(2.1595, grad_fn=<NllLossBackward0>)
tensor(2.1002, grad_fn=<NllLossBackward0>)
tensor(2.0239, grad_fn=<NllLossBackward0>)
tensor(1.9399, grad_fn=<NllLossBackward0>)
tensor(2.1768, grad_fn=<NllLossBackward0>)
tensor(2.0139, grad_fn=<NllLossBackward0>)
tensor(2.0220, grad_fn=<NllLossBackward0>)
tensor(2.1279, grad_fn=<NllLossBackward0>)
tensor(2.0007, grad_fn=<NllLossBackward0>)
tensor(2.0846, grad_fn=<NllLossBackward0>)
tensor(2.0668, grad_fn=<NllLossBackward0>)
tensor(2.0712, grad_fn=<NllLossBackward0>)
tensor(2.4710, grad_fn=<NllLossBackward0>)
tensor(1.8491, grad_fn=<NllLossBackward0>)
tensor(2.0374, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  1992: 0.262
tensor(2.1012, grad_fn=<NllLossBackward0>)
tensor(2.2510, grad_fn=<NllLossBackward0>)
tensor(2.3378, grad_fn=<NllLossBackward0>)
tensor(2.0280, grad_fn=<NllLossBackward0>)
tensor(2.1403, grad_fn=<NllLossBackward0>)
tensor(2.1174, grad_fn=<NllLossBackward0>)
tensor(2.1238, grad_fn=<NllLossBackward0>)
tensor(2.2201, grad_fn=<NllLossBackward0>)
tensor(2.3075, grad_fn=<NllLossBackward0>)
tensor(2.1197, grad_fn=<NllLossBackward0>)
tensor(2.1258, grad_fn=<NllLossBackward0>)
tensor(2.2383, grad_fn=<NllLossBackward0>)
tensor(2.3057, grad_fn=<NllLossBackward0>)
tensor(2.1641, grad_fn=<NllLossBackward0>)
tensor(2.1899, grad_fn=<NllLossBackward0>)
tensor(2.0184, grad_fn=<NllLossBackward0>)
tensor(1.9392, grad_fn=<NllLossBackward0>)
tensor(2.1691, grad_fn=<NllLossBackward0>)
tensor(2.0380, grad_fn=<NllLossBackward0>)
tensor(2.0947, grad_fn=<NllLossBackward0>)
tensor(2.0928, grad_fn=<NllLossBackward0>)
tensor(2.2501, grad_fn=<NllLossBackward0>)
tensor(2.2865, grad_fn=<NllLossBackward0>)
tensor(2.3014, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2016: 0.248
tensor(2.1163, grad_fn=<NllLossBackward0>)
tensor(2.0379, grad_fn=<NllLossBackward0>)
tensor(2.0501, grad_fn=<NllLossBackward0>)
tensor(2.0527, grad_fn=<NllLossBackward0>)
tensor(1.9900, grad_fn=<NllLossBackward0>)
tensor(2.1877, grad_fn=<NllLossBackward0>)
tensor(2.0599, grad_fn=<NllLossBackward0>)
tensor(2.2126, grad_fn=<NllLossBackward0>)
tensor(2.2386, grad_fn=<NllLossBackward0>)
tensor(2.3158, grad_fn=<NllLossBackward0>)
tensor(2.0922, grad_fn=<NllLossBackward0>)
tensor(1.8892, grad_fn=<NllLossBackward0>)
tensor(1.9853, grad_fn=<NllLossBackward0>)
tensor(1.9046, grad_fn=<NllLossBackward0>)
tensor(1.9611, grad_fn=<NllLossBackward0>)
tensor(2.0096, grad_fn=<NllLossBackward0>)
tensor(2.2009, grad_fn=<NllLossBackward0>)
tensor(2.2106, grad_fn=<NllLossBackward0>)
tensor(2.0371, grad_fn=<NllLossBackward0>)
tensor(1.8583, grad_fn=<NllLossBackward0>)
tensor(2.0442, grad_fn=<NllLossBackward0>)
tensor(1.9231, grad_fn=<NllLossBackward0>)
tensor(2.0583, grad_fn=<NllLossBackward0>)
tensor(2.1397, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2040: 0.252
tensor(1.9146, grad_fn=<NllLossBackward0>)
tensor(2.1562, grad_fn=<NllLossBackward0>)
tensor(2.2491, grad_fn=<NllLossBackward0>)
tensor(1.9960, grad_fn=<NllLossBackward0>)
tensor(1.8145, grad_fn=<NllLossBackward0>)
tensor(2.2400, grad_fn=<NllLossBackward0>)
tensor(1.9323, grad_fn=<NllLossBackward0>)
tensor(2.0831, grad_fn=<NllLossBackward0>)
tensor(2.0567, grad_fn=<NllLossBackward0>)
tensor(2.0387, grad_fn=<NllLossBackward0>)
tensor(1.8194, grad_fn=<NllLossBackward0>)
tensor(2.0420, grad_fn=<NllLossBackward0>)
tensor(1.9514, grad_fn=<NllLossBackward0>)
tensor(2.1799, grad_fn=<NllLossBackward0>)
tensor(1.9429, grad_fn=<NllLossBackward0>)
tensor(2.3878, grad_fn=<NllLossBackward0>)
tensor(2.0392, grad_fn=<NllLossBackward0>)
tensor(1.9856, grad_fn=<NllLossBackward0>)
tensor(2.0334, grad_fn=<NllLossBackward0>)
tensor(1.7770, grad_fn=<NllLossBackward0>)
tensor(2.2879, grad_fn=<NllLossBackward0>)
tensor(2.1911, grad_fn=<NllLossBackward0>)
tensor(1.9726, grad_fn=<NllLossBackward0>)
tensor(2.1312, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2064: 0.283
tensor(2.1827, grad_fn=<NllLossBackward0>)
tensor(2.3100, grad_fn=<NllLossBackward0>)
tensor(2.1829, grad_fn=<NllLossBackward0>)
tensor(2.1883, grad_fn=<NllLossBackward0>)
tensor(1.9350, grad_fn=<NllLossBackward0>)
tensor(2.0222, grad_fn=<NllLossBackward0>)
tensor(2.0416, grad_fn=<NllLossBackward0>)
tensor(2.1875, grad_fn=<NllLossBackward0>)
tensor(2.2023, grad_fn=<NllLossBackward0>)
tensor(2.0722, grad_fn=<NllLossBackward0>)
tensor(2.1710, grad_fn=<NllLossBackward0>)
tensor(1.9745, grad_fn=<NllLossBackward0>)
tensor(1.9667, grad_fn=<NllLossBackward0>)
tensor(2.0474, grad_fn=<NllLossBackward0>)
tensor(2.3408, grad_fn=<NllLossBackward0>)
tensor(2.2847, grad_fn=<NllLossBackward0>)
tensor(2.1009, grad_fn=<NllLossBackward0>)
tensor(2.1318, grad_fn=<NllLossBackward0>)
tensor(1.9245, grad_fn=<NllLossBackward0>)
tensor(2.0679, grad_fn=<NllLossBackward0>)
tensor(2.0253, grad_fn=<NllLossBackward0>)
tensor(2.2796, grad_fn=<NllLossBackward0>)
tensor(2.1520, grad_fn=<NllLossBackward0>)
tensor(2.1141, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2088: 0.271
tensor(2.0783, grad_fn=<NllLossBackward0>)
tensor(2.0772, grad_fn=<NllLossBackward0>)
tensor(2.1249, grad_fn=<NllLossBackward0>)
tensor(2.2617, grad_fn=<NllLossBackward0>)
tensor(2.0941, grad_fn=<NllLossBackward0>)
tensor(2.1865, grad_fn=<NllLossBackward0>)
tensor(2.1510, grad_fn=<NllLossBackward0>)
tensor(1.9494, grad_fn=<NllLossBackward0>)
tensor(2.1143, grad_fn=<NllLossBackward0>)
tensor(2.0209, grad_fn=<NllLossBackward0>)
tensor(1.9978, grad_fn=<NllLossBackward0>)
tensor(2.1279, grad_fn=<NllLossBackward0>)
tensor(2.1723, grad_fn=<NllLossBackward0>)
tensor(2.0210, grad_fn=<NllLossBackward0>)
tensor(2.0315, grad_fn=<NllLossBackward0>)
tensor(1.9032, grad_fn=<NllLossBackward0>)
tensor(2.0697, grad_fn=<NllLossBackward0>)
tensor(2.1919, grad_fn=<NllLossBackward0>)
tensor(2.0284, grad_fn=<NllLossBackward0>)
tensor(2.1521, grad_fn=<NllLossBackward0>)
tensor(2.0483, grad_fn=<NllLossBackward0>)
tensor(2.1500, grad_fn=<NllLossBackward0>)
tensor(2.0389, grad_fn=<NllLossBackward0>)
tensor(2.0140, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2112: 0.288
tensor(1.9852, grad_fn=<NllLossBackward0>)
tensor(2.0829, grad_fn=<NllLossBackward0>)
tensor(2.0185, grad_fn=<NllLossBackward0>)
tensor(1.8421, grad_fn=<NllLossBackward0>)
tensor(2.0082, grad_fn=<NllLossBackward0>)
tensor(2.2241, grad_fn=<NllLossBackward0>)
tensor(2.1812, grad_fn=<NllLossBackward0>)
tensor(2.0704, grad_fn=<NllLossBackward0>)
tensor(1.9301, grad_fn=<NllLossBackward0>)
tensor(2.0164, grad_fn=<NllLossBackward0>)
tensor(2.0468, grad_fn=<NllLossBackward0>)
tensor(1.9409, grad_fn=<NllLossBackward0>)
tensor(1.9087, grad_fn=<NllLossBackward0>)
tensor(1.9361, grad_fn=<NllLossBackward0>)
tensor(2.0992, grad_fn=<NllLossBackward0>)
tensor(1.8259, grad_fn=<NllLossBackward0>)
tensor(2.0849, grad_fn=<NllLossBackward0>)
tensor(2.0064, grad_fn=<NllLossBackward0>)
tensor(2.0805, grad_fn=<NllLossBackward0>)
tensor(1.8133, grad_fn=<NllLossBackward0>)
tensor(2.1271, grad_fn=<NllLossBackward0>)
tensor(2.1861, grad_fn=<NllLossBackward0>)
tensor(1.9505, grad_fn=<NllLossBackward0>)
tensor(2.2557, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2136: 0.318
tensor(2.1852, grad_fn=<NllLossBackward0>)
tensor(2.2911, grad_fn=<NllLossBackward0>)
tensor(2.1617, grad_fn=<NllLossBackward0>)
tensor(2.1301, grad_fn=<NllLossBackward0>)
tensor(1.9392, grad_fn=<NllLossBackward0>)
tensor(1.8366, grad_fn=<NllLossBackward0>)
tensor(2.2572, grad_fn=<NllLossBackward0>)
tensor(1.9657, grad_fn=<NllLossBackward0>)
tensor(2.2119, grad_fn=<NllLossBackward0>)
tensor(2.1151, grad_fn=<NllLossBackward0>)
tensor(1.9272, grad_fn=<NllLossBackward0>)
tensor(1.8759, grad_fn=<NllLossBackward0>)
tensor(2.2703, grad_fn=<NllLossBackward0>)
tensor(1.8834, grad_fn=<NllLossBackward0>)
tensor(2.1721, grad_fn=<NllLossBackward0>)
tensor(1.9804, grad_fn=<NllLossBackward0>)
tensor(2.0613, grad_fn=<NllLossBackward0>)
tensor(2.1358, grad_fn=<NllLossBackward0>)
tensor(2.0848, grad_fn=<NllLossBackward0>)
tensor(2.1357, grad_fn=<NllLossBackward0>)
tensor(2.0655, grad_fn=<NllLossBackward0>)
tensor(2.1120, grad_fn=<NllLossBackward0>)
tensor(2.1423, grad_fn=<NllLossBackward0>)
tensor(2.0880, grad_fn=<NllLossBackward0>)
Training loss after mini-batch  2160: 0.255
tensor(2.3131, grad_fn=<NllLossBackward0>)
